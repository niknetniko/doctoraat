%! Author = niko
%! Date = 5/10/2023



@article{shute_focus_2008,
    title = {Focus on {Formative} {Feedback}},
    volume = {78},
    issn = {0034-6543},
    url = {https://journals.sagepub.com/doi/10.3102/0034654307313795},
    doi = {10.3102/0034654307313795},
    number = {1},
    journal = {Rev. Educ. Res.},
    author = {Shute, Valerie J},
    month = mar,
    year = {2008},
    pages = {153--189}
}

@misc{cs_splice_peml_working_group_programming_2021,
    title = {Programming {Exercise} {Markup} {Language}},
    url = {https://cssplice.github.io/peml/},
    urldate = {2021-10-21},
    author = {{CS SPLICE PEML Working Group}},
    month = apr,
    year = {2021},
}

@article{edwards_developing_2008,
    title = {Developing a common format for sharing programming assignments},
    volume = {40},
    issn = {0097-8418},
    url = {https://dl.acm.org/doi/10.1145/1473195.1473240},
    doi = {10.1145/1473195.1473240},
    number = {4},
    journal = {SIGCSE Bull.},
    author = {Edwards, Stephen H and Börstler, Jürgen and Cassel, Lillian N and Hall, Mark S and Hollingsworth, Joseph},
    month = nov,
    year = {2008},
    pages = {167--182}
}

@misc{ward_json_2021,
    title = {{JSON} {Lines}},
    url = {https://jsonlines.org/},
    urldate = {2021-09-08},
    author = {Ward, Ian},
    month = aug,
    year = {2021},
}

@inproceedings{queiros_pexil_2011,
    title = {Pexil: {Programming} exercises interoperability language},
    url = {https://recipp.ipp.pt/handle/10400.22/4748},
    author = {Queirós, Ricardo and Leal, José Paulo},
    year = {2011},
    pages = {37--48},
}

@article{verhoeff_programming_2008,
    title = {Programming {Task} {Packages}: {Peach} {Exchange}},
    url = {https://ioinformatics.org/journal/INFOL019.pdf},
    journal = {Olympiads in Informatics},
    author = {Verhoeff, Tom},
    year = {2008},
    pages = {192},
}

@inproceedings{paiva_yet_2020,
    title = {Yet {Another} {Programming} {Exercises} {Interoperability} {Language} ({Short} {Paper})},
    url = {https://drops.dagstuhl.de/opus/volltexte/2020/13027/},
    author = {Paiva, José Carlos and Queirós, Ricardo and Leal, José Paulo and Swacha, Jakub},
    year = {2020},
    booktitle = {9th Symposium on Languages, Applications and Technologies (SLATE 2020)},
    pages = {14:1--14:8},
    series = {OpenAccess Series in Informatics (OASIcs)},
    isbn = {978-3-95977-165-8},
    issn = {2190-6807},
    volume = {83},
    editor = {Alberto Sim{\~o}es and Pedro Rangel Henriques and Ricardo Queir{\'o}s},
    doi = {10.4230/OASIcs.SLATE.2020.14},
}

@article{le_operationalizing_2013,
    title = {Operationalizing the {Continuum} between {Well}-{Defined} and {Ill}-{Defined} {Problems} for {Educational} {Technology}},
    volume = {6},
    issn = {1939-1382},
    url = {https://ieeexplore.ieee.org/document/6497037},
    doi = {10.1109/TLT.2013.16},
    number = {3},
    journal = {IEEE Trans. Learn. Technol.},
    author = {Le, Nguyen-Thinh and Loll, Frank and Pinkwart, Niels},
    month = jul,
    year = {2013},
    pages = {258--270},
}

@inproceedings{simoes_nature_2020,
    title = {On the nature of programming exercises},
    url = {https://drops.dagstuhl.de/opus/volltexte/2020/12311/},
    doi = {10.4230/OASICS.ICPEC.2020.24},
    author = {Simões, Alberto and Queirós, Ricardo},
    year = {2020},
    booktitle = {First International Computer Programming Education Conference (ICPEC 2020)},
    pages = {24:1--24:9},
    series = {OpenAccess Series in Informatics (OASIcs)},
    isbn = {978-3-95977-153-5},
    issn = {2190-6807},
    volume = {81},
    editor = {Ricardo Queir{\'o}s and Filipe Portela and M{\'a}rio Pinto and Alberto Sim{\~o}es},
}

@article{queiros_babeloextensible_2013,
    title = {{BabeLO}—{An} {Extensible} {Converter} of {Programming} {Exercises} {Formats}},
    volume = {6},
    issn = {1939-1382},
    url = {https://ieeexplore.ieee.org/document/6331493},
    doi = {10.1109/TLT.2012.21},
    number = {1},
    journal = {IEEE Trans. Learn. Technol.},
    author = {Queirós, Ricardo and Leal, Jose Paulo},
    month = jan,
    year = {2013},
    pages = {38--45},
}

@article{keuning_systematic_2018,
    title = {A {Systematic} {Literature} {Review} of {Automated} {Feedback} {Generation} for {Programming} {Exercises}},
    volume = {19},
    url = {https://dl.acm.org/doi/10.1145/3231711},
    doi = {10.1145/3231711},
    number = {1},
    journal = {ACM Trans. Comput. Educ.},
    author = {Keuning, Hieke and Jeuring, Johan and Heeren, Bastiaan},
    month = sep,
    year = {2018},
    pages = {1--43},
}

@article{wasik_survey_2018,
    title = {A {Survey} on {Online} {Judge} {Systems} and {Their} {Applications}},
    volume = {51},
    issn = {0360-0300},
    url = {https://dl.acm.org/doi/10.1145/3143560},
    doi = {10.1145/3143560},
    number = {1},
    journal = {ACM Comput. Surv.},
    author = {Wasik, Szymon and Antczak, Maciej and Badura, Jan and Laskowski, Artur and Sternal, Tomasz},
    month = jan,
    year = {2018},
    pages = {1--34},
}

@article{hao_towards_2021,
    title = {Towards understanding the effective design of automated formative feedback for programming assignments},
    issn = {0899-3408, 1744-5175},
    url = {https://www.tandfonline.com/doi/full/10.1080/08993408.2020.1860408},
    doi = {10.1080/08993408.2020.1860408},
    journal = {Computer Science Education},
    author = {Hao, Qiang and Smith IV, David H. and Ding, Lu and Ko, Amy and Ottaway, Camille and Wilson, Jack and Arakawa, Kai H. and Turcan, Alistair and Poehlman, Timothy and Greer, Tyler},
    month = jan,
    year = {2021},
    pages = {1--23},
}

@inproceedings{zavala_use_2018,
    title = {On the {Use} of {Semantic}-{Based} {AIG} to {Automatically} {Generate} {Programming} {Exercises}},
    isbn = {978-1-4503-5103-4},
    url = {https://dl.acm.org/doi/10.1145/3159450.3159608},
    doi = {10.1145/3159450.3159608},
    booktitle = {Proceedings of the 49th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
    author = {Zavala, Laura and Mendoza, Benito},
    month = feb,
    year = {2018},
    pages = {14--19},
}

@inproceedings{pirttinen_crowdsourcing_2018,
    title = {Crowdsourcing programming assignments with {CrowdSorcerer}},
    isbn = {978-1-4503-5707-4},
    url = {https://dl.acm.org/doi/10.1145/3197091.3197117},
    doi = {10.1145/3197091.3197117},
    booktitle = {Proceedings of the 23rd {Annual} {ACM} {Conference} on {Innovation} and {Technology} in {Computer} {Science} {Education}},
    author = {Pirttinen, Nea and Kangas, Vilma and Nikkarinen, Irene and Nygren, Henrik and Leinonen, Juho and Hellas, Arto},
    month = jul,
    year = {2018},
    pages = {326--331},
}

@article{camp_generation_2017,
    title = {Generation {CS}: the growth of computer science},
    volume = {8},
    issn = {2153-2184, 2153-2192},
    url = {https://dl.acm.org/doi/10.1145/3084362},
    doi = {10.1145/3084362},
    number = {2},
    journal = {ACM Inroads},
    author = {Camp, Tracy and Adrion, W. Richards and Bizot, Betsy and Davidson, Susan and Hall, Mary and Hambrusch, Susanne and Walker, Ellen and Zweben, Stuart},
    month = may,
    year = {2017},
    pages = {44--50},
}

@inproceedings{sax_examining_2017,
    address = {Seattle Washington USA},
    title = {Examining the {Enrollment} {Growth}: {Non}-{CS} {Majors} in {CS1} {Courses}},
    isbn = {978-1-4503-4698-6},
    url = {https://dl.acm.org/doi/10.1145/3017680.3017781},
    doi = {10.1145/3017680.3017781},
    booktitle = {Proceedings of the 2017 {ACM} {SIGCSE} {Technical} {Symposium} on {Computer} {Science} {Education}},
    author = {Sax, Linda J. and Lehman, Kathleen J. and Zavala, Christina},
    month = mar,
    year = {2017},
    pages = {513--518},
}

@inproceedings{staubitz_towards_2017,
    address = {Hong Kong},
    title = {Towards a repository for open auto-gradable programming exercises},
    isbn = {978-1-5386-0900-2},
    url = {http://ieeexplore.ieee.org/document/8252306/},
    doi = {10.1109/TALE.2017.8252306},
    booktitle = {2017 {IEEE} 6th {International} {Conference} on {Teaching}, {Assessment}, and {Learning} for {Engineering} ({TALE})},
    author = {Staubitz, Thomas and Teusner, Ralf and Meinel, Christoph},
    month = dec,
    year = {2017},
    pages = {66--73},
}

@article{orrell_feedback_2006,
    title = {Feedback on learning achievement: rhetoric and reality},
    volume = {11},
    issn = {1356-2517, 1470-1294},
    url = {http://www.tandfonline.com/doi/abs/10.1080/13562510600874235},
    doi = {10.1080/13562510600874235},
    number = {4},
    journal = {Teaching in Higher Education},
    author = {Orrell, Janice},
    month = oct,
    year = {2006},
    pages = {441--456},
}

@misc{zakas_eslint_nodate,
    title = {{ESLint}},
    url = {https://eslint.org/},
    urldate = {2017-06-17},
    author = {Zakas, Nicholas C. and Mills, Brandon and Djermanovic, Milos},
}

@inproceedings{luxton-reilly_introductory_2018,
    title = {Introductory programming: a systematic literature review},
    isbn = {978-1-4503-6223-8},
    url = {https://dl.acm.org/doi/10.1145/3293881.3295779},
    doi = {10.1145/3293881.3295779},
    booktitle = {Proceedings {Companion} of the 23rd {Annual} {ACM} {Conference} on {Innovation} and {Technology} in {Computer} {Science} {Education}},
    author = {Luxton-Reilly, Andrew and {Simon} and Albluwi, Ibrahim and Becker, Brett A. and Giannakos, Michail and Kumar, Amruth N. and Ott, Linda and Paterson, James and Scott, Michael James and Sheard, Judy and Szabo, Claudia},
    month = jul,
    year = {2018},
    pages = {55--106},
}

@inproceedings{edwards_using_2004,
    title = {Using software testing to move students from trial-and-error to reflection-in-action},
    isbn = {978-1-58113-798-9},
    url = {http://portal.acm.org/citation.cfm?doid=971300.971312},
    doi = {10.1145/971300.971312},
    booktitle = {Proceedings of the 35th {SIGCSE} technical symposium on {Computer} science education  - {SIGCSE} '04},
    author = {Edwards, Stephen H.},
    year = {2004},
    pages = {26},
}

@inproceedings{gulwani_feedback_2014,
    address = {Hong Kong China},
    title = {Feedback generation for performance problems in introductory programming assignments},
    isbn = {978-1-4503-3056-5},
    url = {https://dl.acm.org/doi/10.1145/2635868.2635912},
    doi = {10.1145/2635868.2635912},
    booktitle = {Proceedings of the 22nd {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
    author = {Gulwani, Sumit and Radiček, Ivan and Zuleger, Florian},
    month = nov,
    year = {2014},
    pages = {41--51},
}

@inproceedings{tang_data-driven_2016,
    address = {Arequipa Peru},
    title = {Data-{Driven} {Test} {Case} {Generation} for {Automated} {Programming} {Assessment}},
    isbn = {978-1-4503-4231-5},
    url = {https://dl.acm.org/doi/10.1145/2899415.2899423},
    doi = {10.1145/2899415.2899423},
    booktitle = {Proceedings of the 2016 {ACM} {Conference} on {Innovation} and {Technology} in {Computer} {Science} {Education}},
    author = {Tang, Terry and Smith, Rebecca and Rixner, Scott and Warren, Joe},
    month = jul,
    year = {2016},
    pages = {260--265},
}

@incollection{kosiuczenko_sipe_2018,
    address = {Cham},
    title = {{SIPE}: {A} {Domain}-{Specific} {Language} for {Specifying} {Interactive} {Programming} {Exercises}},
    volume = {733},
    isbn = {978-3-319-65207-8 978-3-319-65208-5},
    url = {http://link.springer.com/10.1007/978-3-319-65208-5_2},
    booktitle = {Towards a {Synergistic} {Combination} of {Research} and {Practice} in {Software} {Engineering}},
    author = {Swacha, Jakub},
    editor = {Kosiuczenko, Piotr and Madeyski, Lech},
    year = {2018},
    doi = {10.1007/978-3-319-65208-5\_2},
    pages = {15--29},
}

@article{strickroth_proforma_2015,
    title = {{ProFormA}: {An} {XML}-based exchange format for programming tasks},
    volume = {11},
    issn = {1860-7470},
    url = {http://nbn-resolving.de/urn:nbn:de:0009-5-41389},
    number = {1},
    journal = {eleed},
    author = {Strickroth, Sven and Striewe, Michael and Müller, Oliver and Priss, Uta and Becker, Sebastian and Rod, Oliver and Garmann, Robert and Bott, Oliver J. and Pinkwart, Niels},
    year = {2015},
}

@misc{wastl_advent_2020,
    title = {Advent of {Code}},
    url = {https://adventofcode.com/},
    author = {Wastl, Eric},
    year = {2020},
}

@inproceedings{campos_multinational_2012,
    title = {A multinational case study on using diverse feedback types applied to introductory programming learning},
    isbn = {978-1-4673-1352-0 978-1-4673-1353-7 978-1-4673-1351-3},
    url = {http://ieeexplore.ieee.org/document/6462412/},
    doi = {10.1109/FIE.2012.6462412},
    booktitle = {2012 {Frontiers} in {Education} {Conference} {Proceedings}},
    author = {Campos, Dirson S. and Mendes, Antonio J. and Marcelino, Maria J. and Ferreira, Deller J. and Alves, Lenice M.},
    month = oct,
    year = {2012},
    pages = {1--6},
}

@article{cheang_automated_2003,
    title = {On automated grading of programming assignments in an academic institution},
    volume = {41},
    issn = {03601315},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S0360131503000307},
    doi = {10.1016/S0360-1315(03)00030-7},
    number = {2},
    journal = {Computers \& Education},
    author = {Cheang, Brenda and Kurnia, Andy and Lim, Andrew and Oon, Wee-Chong},
    month = sep,
    year = {2003},
    pages = {121--131},
}

@misc{van_petegem_dodona_2022,
    title = {Dodona: learn to code with a virtual co-teacher that supports active learning},
    url = {http://arxiv.org/abs/2210.10719},
    abstract = {Dodona (dodona.ugent.be) is an intelligent tutoring system for computer programming. It bridges the gap between assessment and learning by providing real-time data and feedback to help students learn better, teachers teach better and educational technology become more effective. We demonstrate how Dodona can be used as a virtual co-teacher to stimulate active learning and support challenge-based education in open and collaborative learning environments. We also highlight some of the opportunities (automated feedback, learning analytics, educational data mining) and challenges (scalable feedback, open internet exams, plagiarism) we faced in practice. Dodona is free for use and has more than 36 thousand registered users across many educational and research institutes, of which 15 thousand new users registered last year. Lowering the barriers for such a broad adoption was achieved by following best practices and extensible approaches for software development, authentication, content management, assessment, security and interoperability, and by adopting a holistic view on computer-assisted learning and teaching that spans all aspects of managing courses that involve programming assignments. The source code of Dodona is available on GitHub under the permissive MIT open-source license.},
    author = {Van Petegem, Charlotte and Maertens, Rien and Strijbol, Niko and Van Renterghem, Jorg and Van der Jeugt, Felix and De Wever, Bram and Dawyndt, Peter and Mesuere, Bart},
    month = oct,
    year = {2022},
}

@article{paiva_automated_2022,
    title = {Automated {Assessment} in {Computer} {Science} {Education}: {A} {State}-of-the-{Art} {Review}},
    volume = {22},
    issn = {1946-6226, 1946-6226},
    url = {https://dl.acm.org/doi/10.1145/3513140},
    doi = {10.1145/3513140},
    number = {3},
    journal = {ACM Transactions on Computing Education},
    author = {Paiva, José Carlos and Leal, José Paulo and Figueira, \'{A}lvaro},
    month = sep,
    year = {2022},
    pages = {1--40},
}

@techreport{wright_json_2022,
    type = {Internet-{Draft}},
    title = {{JSON} {Schema}: {A} {Media} {Type} for {Describing} {JSON} {Documents}},
    url = {https://datatracker.ietf.org/doc/draft-bhutton-json-schema/01/},
    number = {draft-bhutton-json-schema-01},
    institution = {Internet Engineering Task Force},
    author = {Wright, Austin and Andrews, Henry and Hutton, Ben and Dennis, Greg},
    month = jun,
    year = {2022},
}

@inproceedings{claessen_quickcheck_2000,
    title = {{QuickCheck}: a lightweight tool for random testing of {Haskell} programs},
    isbn = {978-1-58113-202-1},
    shorttitle = {{QuickCheck}},
    url = {https://dl.acm.org/doi/10.1145/351240.351266},
    doi = {10.1145/351240.351266},
    language = {en},
    urldate = {2023-04-12},
    booktitle = {Proceedings of the fifth {ACM} {SIGPLAN} international conference on {Functional} programming},
    publisher = {ACM},
    author = {Claessen, Koen and Hughes, John},
    month = sep,
    year = {2000},
    pages = {268--279},
    file = {Volledige Tekst:/home/niko/Zotero/storage/FEANIFPL/Claessen en Hughes - 2000 - QuickCheck a lightweight tool for random testing .pdf:application/pdf},
}

@online{bayer_mako_2020,
    title = {Mako},
    url = {https://www.makotemplates.org/},
    author = {Bayer, Michael and Dairiki, Geoffrey T and Jenvey, Philip and Peckam, David and Ronacher, Armin and Bangert, Ben and Trofatter, Ben},
    month = mar,
    year = {2020},
}

@book{meszaros_xunit_2007,
    title = {{xUnit} {Test} {Patterns}: {Refactoring} {Test} {Code}},
    isbn = {978-0-13-279746-7},
    publisher = {Pearson Education},
    author = {Meszaros, Gerard},
    month = may,
    year = {2007},
}

@inproceedings{bez_uri_2014,
    title = {{URI} {Online} {Judge} {Academic}: {A} tool for algorithms and programming classes},
    doi = {10.1109/iccse.2014.6926445},
    author = {Bez, Jean Luca and Tonin, Neilor A and Rodegheri, Paulo R},
    year = {2014},
    booktitle = ICCSE,
    pages={149-152}
}

@article{petit_jutgeorg_2018,
    title = {Jutge.org: {Characteristics} and {Experiences}},
    volume = {11},
    issn = {1939-1382},
    doi = {10.1109/TLT.2017.2723389},
    number = {3},
    journal = IEEE_J_TLT,
    author = {Petit, Jordi and Roura, Salvador and Carmona, Josep and Cortadella, Jordi and Duch, Jordi and Gimnez, Omer and Mani, Anaga and Mas, Jan and Rodrguez-Carbonell, Enric and Rubio, Enric and de San Pedro, Enric and Venkataramani, Divya},
    month = jul,
    year = {2018},
    keywords = {Programming profession, Algorithm design and analysis, computer programming, Computers, Data mining, Education, educational data mining, educational games, Electronic mail, Innovative online learning systems, learning analytics, online programming judges},
    pages = {321--333},
}

@inproceedings{gusukuma_pedal_2020,
    title = {Pedal: {An} {Infrastructure} for {Automated} {Feedback} {Systems}},
    isbn = {978-1-4503-6793-6},
    doi = {10.1145/3328778.3366913},
    booktitle = ACM_SIGCSE_20,
    author = {Gusukuma, Luke and Bart, Austin Cory and Kafura, Dennis},
    month = feb,
    year = {2020},
    pages = {1061--1067},
}

@article{striewe_architecture_2016,
    title = {An architecture for modular grading and feedback generation for complex exercises},
    volume = {129},
    issn = {01676423},
    doi = {10.1016/j.scico.2016.02.009},
    journal = EL_SOC,
    author = {Striewe, Michael},
    month = nov,
    year = {2016},
    pages = {35--47},
}

@electronic{noauthor_icpc_2020,
    title = {{ICPC} {Fact} {Sheet}},
    url = {https://icpc.global/worldfinals/pdf/Factsheet.pdf},
    publisher = {ICPC},
    month = jul,
    year = {2020},
}

@inproceedings{bissyande_popularity_2013,
    title = {Popularity, {Interoperability}, and {Impact} of {Programming} {Languages} in 100,000 {Open} {Source} {Projects}},
    isbn = {978-0-7695-4986-6},
    doi = {10.1109/COMPSAC.2013.55},
    urldate = {2022-03-22},
    booktitle = IEEE_COMPSAC,
    author = {Bissyande, Tegawende F. and Thung, Ferdian and Lo, David and Jiang, Lingxiao and Reveillere, Laurent},
    month = jul,
    year = {2013},
    pages = {303--312},
}


@techreport{rfc7464,
    author = {Nicolas Williams},
    title = {JavaScript Object Notation (JSON) Text Sequences},
    howpublished = {Internet Requests for Comments},
    type = {RFC},
    number = 7464,
    year = {2015},
    month = {2},
    issn = {2070-1721},
    publisher = {RFC Editor},
    institution = {RFC Editor},
    url = {https://www.rfc-editor.org/rfc/rfc7464.html}
}

@book{ammann_introduction_2016,
    edition = {2},
    title = {Introduction to {Software} {Testing}},
    isbn = {978-1-107-17201-2},
    url = {https://www.cambridge.org/highereducation/books/introduction-to-software-testing/95E57CCADEA697EC8594F03729F47311},
    abstract = {This extensively classroom-tested text takes an innovative approach to explaining software testing that defines it as the process of applying a few precise, general-purpose criteria to a structure or model of the software. The book incorporates cutting-edge developments, including techniques to test modern types of software such as OO, web applications, and embedded software. This revised second edition significantly expands coverage of the basics, thoroughly discussing test automaton frameworks, and it adds new, improved examples and numerous exercises. The theory of coverage criteria is carefully and cleanly explained to help students understand concepts before delving into practical applications, while extensive use of the JUnit test framework gives students practical experience in a test framework popular in the industry. Exercises, meanwhile, feature specifically tailored tools that allow students to check their own work. The book's website also offers an instructor's manual, PowerPoint slides, testing tools for students, and example software programs in Java.},
    publisher = {Cambridge University Press},
    author = {Ammann, Paul and Offutt, Jeff},
    month = dec,
    year = {2016},
    doi = {10.1017/9781316771273},
    keywords = {softwareengineering},
    file = {Ammann en Offutt - 2016 - Introduction to Software Testing.pdf:/home/niko/Zotero/storage/VN5QAMJC/Ammann en Offutt - 2016 - Introduction to Software Testing.pdf:application/pdf},
}

@inproceedings{romli_automatic_2010,
    address = {Kuala Lumpur, Malaysia},
    title = {Automatic programming assessment and test data generation a review on its approaches},
    isbn = {978-1-4244-6715-0},
    url = {http://ieeexplore.ieee.org/document/5561488/},
    doi = {10.1109/ITSIM.2010.5561488},
    urldate = {2023-09-13},
    booktitle = {2010 {International} {Symposium} on {Information} {Technology}},
    publisher = {IEEE},
    author = {Romli, Rohaida and Sulaiman, Shahida and Zamli, Kamal Zuhairi},
    month = jun,
    year = {2010},
    pages = {1186--1192},
    file = {Romli e.a. - 2010 - Automatic programming assessment and test data gen.pdf:/home/niko/Zotero/storage/CXZIIIUC/Romli e.a. - 2010 - Automatic programming assessment and test data gen.pdf:application/pdf},
}

@inproceedings{pieterse_automated_2013,
    address = {Arnhem, Nederland},
    title = {Automated {Assessment} of {Programming} {Assignments}},
    url = {https://dl.acm.org/doi/10.5555/2541917.2541921},
    abstract = {This is a position paper in which I argue that massive open online programming courses can benefit by the application of automated assessment of programming assignments. I gathered success factors and identified concerns related to automatic assessment through the analysis of experiences other researchers have reported when designing and using automated assessment of programming assignments and interpret their potential applicability in the context of massive open online courses (MOOCs). In this paper I explain the design of our own assessment software and discuss our experience of using it in relation to the above-mentioned factors and concerns. My reflection on this experience can inform MOOC designers when having to make decisions regarding the use of automatic assessment of programming assignments.},
    urldate = {2023-09-13},
    booktitle = {Proceedings of the 3rd {Computer} {Science} {Education} {Research} {Conference} on {Computer} {Science} {Education} {Research}},
    publisher = {Open Universiteit Heerlen},
    author = {Pieterse, Vreda},
    month = apr,
    year = {2013},
    keywords = {Assessment software, automatic assessment, MOOC},
    pages = {45--56},
    file = {Full Text PDF:/home/niko/Zotero/storage/GDG623TW/Pieterse - 2013 - Automated Assessment of Programming Assignments.pdf:application/pdf},
}

@book{winters_software_2020,
    title = {Software {Engineering} at {Google}: {Lessons} {Learned} from {Programming} {Over} {Time}},
    isbn = {978-1-4920-8276-7},
    shorttitle = {Software {Engineering} at {Google}},
    url = {https://www.oreilly.com/library/view/software-engineering-at/9781492082781/},
    abstract = {Today, software engineers need to know not only how to program effectively but also how to develop proper engineering practices to make their codebase sustainable and healthy. This book emphasizes this difference between programming and software engineering.How can software engineers manage a living codebase that evolves and responds to changing requirements and demands over the length of its life? Based on their experience at Google, software engineers Titus Winters and Hyrum Wright, along with technical writer Tom Manshreck, present a candid and insightful look at how some of the world{\textquoteright}s leading practitioners construct and maintain software. This book covers Google{\textquoteright}s unique engineering culture, processes, and tools and how these aspects contribute to the effectiveness of an engineering organization.You{\textquoteright}ll explore three fundamental principles that software organizations should keep in mind when designing, architecting, writing, and maintaining code:How time affects the sustainability of software and how to make your code resilient over timeHow scale affects the viability of software practices within an engineering organizationWhat trade-offs a typical engineer needs to make when evaluating design and development decisions},
    language = {en},
    publisher = {O'Reilly Media},
    author = {Winters, Titus and Manshreck, Tom and Wright, Hyrum},
    month = feb,
    year = {2020},
    note = {Google-Books-ID: V3TTDwAAQBAJ},
    keywords = {Computers / Software Development \& Engineering / Project Management, Computers / Software Development \& Engineering / Quality Assurance \& Testing, Computers / Software Development \& Engineering / Systems Analysis \& Design, Computers / Software Development \& Engineering / Tools, Computers / Systems Architecture / General},
    file = {Winters e.a. - 2020 - Software Engineering at Google Lessons Learned fr.pdf:/home/niko/Zotero/storage/5URZL92K/Winters e.a. - 2020 - Software Engineering at Google Lessons Learned fr.pdf:application/pdf},
}

@misc{pan_software_1999,
    title = {Software reliability},
    url = {https://users.ece.cmu.edu/~koopman/des_s99/sw_reliability/presentation.pdf},
    author = {Pan, Jiantao},
    year = {1999},
    file = {Pan - 1999 - Software reliability.pdf:/home/niko/Zotero/storage/RR3AESMY/Pan - 1999 - Software reliability.pdf:application/pdf},
}

@book{hetzel_complete_1988,
    address = {USA},
    edition = {2nd},
    title = {The complete guide to software testing},
    isbn = {978-0-89435-242-3},
    url = {https://dl.acm.org/doi/book/10.5555/42384},
    abstract = {In this resource, the author first develops the concepts and principles of testing. Then he presents detailed discussions of testing techniques, methodologies and management perspectives to understand the material and adapt it to your environment.},
    publisher = {QED Information Sciences},
    author = {Hetzel, Bill},
    month = apr,
    year = {1988},
    file = {Hetzel - 1988 - The complete guide to software testing.pdf:/home/niko/Zotero/storage/EGQII4VK/Hetzel - 1988 - The complete guide to software testing.pdf:application/pdf},
}

@inproceedings{staubitz_towards_2015,
    address = {Zhuhai, China},
    title = {Towards practical programming exercises and automated assessment in {Massive} {Open} {Online} {Courses}},
    url = {https://ieeexplore.ieee.org/abstract/document/7386010},
    doi = {10.1109/TALE.2015.7386010},
    abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon presenting the prospect of free high class education to everybody. They bear a tremendous potential for teaching programming to a large and diverse audience. The typical MOOC components, such as video lectures, reading material, and easily assessable quizzes, however, are not sufficient for proper programming education. To learn programming, participants need an option to work on practical programming exercises and to solve actual programming tasks. It is crucial that the participants receive proper feedback on their work in a timely manner. Without a tool for automated assessment of programming assignments, the teaching teams would be restricted to offer optional ungraded exercises only. The paper at hand sketches scenarios how practical programming exercises could be provided and examines the landscape of potentially helpful tools in this context. Automated assessment has a long record in the history of computer science education. We give an overview of existing tools in this field and also explore the question what can and/or should be assessed.},
    booktitle = {2015 {IEEE} {International} {Conference} on {Teaching}, {Assessment}, and {Learning} for {Engineering} ({TALE})},
    publisher = {IEEE},
    author = {Staubitz, Thomas and Klement, Hauke and Renz, Jan and Teusner, Ralf and Meinel, Christoph},
    month = dec,
    year = {2015},
    keywords = {Programming profession, Programming, Education, MOOC, Assessment, Automated Assessment, Browsers, Context, Games, Massive Open Online Courses, Servers},
    pages = {23--30},
    file = {IEEE Xplore Abstract Record:/home/niko/Zotero/storage/PTGJCP2Q/7386010.html:text/html;IEEE Xplore Full Text PDF:/home/niko/Zotero/storage/ECWP7FH4/Staubitz e.a. - 2015 - Towards practical programming exercises and automa.pdf:application/pdf},
}

@inproceedings{souza_systematic_2016,
    address = {Dallas, TX, USA},
    title = {A {Systematic} {Literature} {Review} of {Assessment} {Tools} for {Programming} {Assignments}},
    url = {https://ieeexplore.ieee.org/abstract/document/7474479},
    doi = {10.1109/CSEET.2016.48},
    abstract = {The benefits of using assessment tools for programming assignments have been widely discussed in computing education. However, as both researchers and instructors are unaware of the characteristics of existing tools, they are either not used or are reimplemented. This paper presents the results of a study conducted to collect and evaluate evidence about tools that assist in the assessment of programming assignments. To achieve our goal, we performed a systematic literature review since it provides an objective procedure for identifying the quantity of existing research related to a research question. The results identified subjects in the development of new assessment tools that researchers could better investigate and characteristics of assessment tools that could help instructors make selections for their programming courses.},
    booktitle = {2016 {IEEE} 29th {International} {Conference} on {Software} {Engineering} {Education} and {Training} ({CSEET})},
    publisher = {IEEE},
    author = {Souza, Draylson M. and Felizardo, Katia Romero and Barbosa, Ellen Francine},
    month = apr,
    year = {2016},
    note = {ISSN: 2377-570X},
    keywords = {Programming profession, Data mining, Education, Assessment tools, Bibliographies, Databases, Mapping study, Programming assignments, Systematics},
    pages = {147--156},
    file = {IEEE Xplore Abstract Record:/home/niko/Zotero/storage/9UUKNN44/7474479.html:text/html;IEEE Xplore Full Text PDF:/home/niko/Zotero/storage/E3XDQ474/Souza e.a. - 2016 - A Systematic Literature Review of Assessment Tools.pdf:application/pdf},
}

@inproceedings{wilcox_testing_2016,
    address = {Memphis Tennessee USA},
    title = {Testing {Strategies} for the {Automated} {Grading} of {Student} {Programs}},
    isbn = {978-1-4503-3685-7},
    url = {https://dl.acm.org/doi/10.1145/2839509.2844616},
    doi = {10.1145/2839509.2844616},
    abstract = {Enrollments in introductory computer science courses are growing rapidly, thereby taxing scarce teaching resources and motivating the increased use of automated tools for program grading. Such tools commonly rely on regression testing methods from industry. However, the goals of automated grading differ from those of testing for software production. In academia, a primary motivation for testing is to provide timely and accurate feedback to students so that they can understand and fix defects in their programs. Testing strategies for program grading are therefore distinct from those of traditional software testing. This paper enumerates and describes a number of testing strategies that improve the quality of feedback for different types of programming assignments.},
    language = {en},
    urldate = {2023-09-13},
    booktitle = {Proceedings of the 47th {ACM} {Technical} {Symposium} on {Computing} {Science} {Education}},
    publisher = {ACM},
    author = {Wilcox, Chris},
    month = feb,
    year = {2016},
    pages = {437--442},
    file = {Wilcox - 2016 - Testing Strategies for the Automated Grading of St.pdf:/home/niko/Zotero/storage/H7JUI635/Wilcox - 2016 - Testing Strategies for the Automated Grading of St.pdf:application/pdf},
}

@article{berssanette_active_2021,
    title = {Active {Learning} in the {Context} of the {Teaching}/{Learning} of {Computer} {Programming}: {A} {Systematic} {Review}},
    volume = {20},
    issn = {1547-9714, 1539-3585},
    shorttitle = {Active {Learning} in the {Context} of the {Teaching}/{Learning} of {Computer} {Programming}},
    url = {https://www.informingscience.org/Publications/4767},
    doi = {10.28945/4767},
    abstract = {Aim/Purpose: This paper presents the results of a systematic literature review that sought to identify the studies that relate the different pedagogical techniques by which active learning is developed in the context of the teaching/learning of computer programming, with the objective to characterize the approaches, the pedagogical techniques used, the application, the contributions, and difficulties of implementation reported by these studies.

Background: The literature has shown that teachers in teaching programming have been less successful than they should and need to be, so dropout and failure rates for students remain high. In this sense, much has been discussed about the possibilities and limitations of using the active learning pedagogical techniques in this context.

Methodology: For this review, an analysis from all studies mentioning active learning in the context of the teaching/learning of computer programming published between 2014 and 2019 was performed, retrieved in WOS, SCOPUS, ScienceDirect, and ACM Digital Library. The selection of studies was based on a set of criteria established to guide the selection process, including alignment with the research questions and evaluating the quality of studies.

Contribution: This study contributes to an overview of the current scenario, characterizing the research studies that associate the different pedagogical techniques of active learning in the context of the teaching/learning of computer programming.

Findings: The results showed that the studies{\textquoteright} approaches usually occur by intervention/pedagogical experiment or by the development of a tool, instrument or methodology. The lipped classroom methodology has obtained a notable prominence in research. The use of active learning pedagogical techniques results in greater acceptance or positive feedback from students, increasing their satisfaction or motivation to improve the learning experience, learning outcomes, or student performance. However, they require a greater effort/work by the teacher to plan and/or execute the teaching/learning process. It should be highlighted that the contributions observed for the teaching/learning process of computer programming derive from investigations mainly concentrated in the university context, aiming to observe if these contributions can be reproduced in other education levels. The contributions observed in the studies regarding the uses of pedagogical techniques of active learning in the context of computer programming indicate that their use can contribute significantly to the teaching/learning process, showing it to be a viable alternative and consistent with the reduction of the failures in the learning of programming.

Recommendations for Practitioners: Considering that over the years the teaching/learning process of computer programming has been a challenge for students, based on the findings of this research, we recommend that teachers consider restructuring their traditional practices of teaching computer programming, making use of pedagogical techniques of active learning to obtain better learning results of their students.

Recommendation for Researchers: We recommend that fellow scholars consider investigating how the difficulties inherent to teachers related to the teaching/learning process of programming may relate to difficulties concerning students and content, especially with regard to traditional teaching practices.

Impact on Society: This study adds to previous systematic reviews of the literature, specifically studies that relate active learning to the context of teaching/learning of programming. It is hoped that the findings of this article can support other research that addresses the topic, enabling its development and deepening, through the developed basis from which active learning researchers can work.

Future Research: Future studies may investigate the benefits of using different pedagogical techniques for active learning and the costs related to the higher cognitive burden imposed by these techniques for learning computer programming.},
    language = {en},
    urldate = {2023-09-13},
    journal = {Journal of Information Technology Education: Research},
    author = {Berssanette, Jo{\~a}o Henrique and de Francisco, Antonio Carlos},
    year = {2021},
    pages = {201--220},
    file = {Henrique Berssanette en Carlos De Francisco - 2021 - Active Learning in the Context of the TeachingLea.pdf:/home/niko/Zotero/storage/D5PP5Z8K/Henrique Berssanette en Carlos De Francisco - 2021 - Active Learning in the Context of the TeachingLea.pdf:application/pdf},
}

@inproceedings{caiza_programming_2013,
    address = {Valencia, Spain},
    title = {Programming assignments automatic grading: review of tools and implementations},
    isbn = {978-84-616-2661-8},
    url = {https://library.iated.org/view/CAIZA2013PRO},
    abstract = {Automatic grading of programming assignments is an important topic in academic research. It aims at improving the level of feedback given to students and optimizing the professor{\textquoteright}s time. Its importance is more remarkable as the amount and complexity of assignments increases. Several studies have reported the development of software tools to support this process. They usually consider particular deployment scenarios and specific requirements of the interested institution. However, the quantity and diversity of these tools makes it difficult to get a quick and accurate idea of their features.

This paper reviews an ample set of tools for automatic grading of programming assignments. The review includes a description of every tool selected and their key features. Among others, the key features analyzed include the programming language used to build the tool, the programming languages supported for grading, the criteria applied in the evaluation process, the work mode (as a plugin, as an independent tool, etc.), the logical and deployment architectures, and the communications technology used. Then, implementations and operation results are described with quantitative and qualitative indicators to understand how successful the tools were. Quantitative indicators include number of courses, students, tasks, submissions considered for tests, and acceptance percentage after tests. Qualitative indicators include motivation, support, and skills improvement. A comparative analysis among the tools is shown, and as result a set of common gaps detected is provided. The lack of normalized evaluation criteria for assignments is identified as a key gap in the reviewed tools. Thus, an evaluation metrics frame to grade programming assignments is proposed.

The results indicate that many of the analyzed features highly depend on the current technology infrastructure that supports the teaching process. Therefore, they are a limiting factor in reusing the tools in new implementation cases. Another fact is the inability to support new programming languages, which is limited by tools{\textquoteright} updates. On metrics for evaluation process, the set of analyzed tools showed much diversity and inflexibility.

Knowing which implementation features are always specific and particular independently of the project, and which others could be common will be helpful before the implementation and operation of a tool. Considering how much flexibility could be attained in the evaluation process will be helpful to design a new tool, which will be used not only in particular cases, and to define the automation level of the evaluation process.},
    language = {en},
    urldate = {2023-09-13},
    booktitle = {{INTED2013} {Proceedings}},
    author = {Caiza, Julio C. and del Alamo, Jos{\'e} Mar{\'i}a},
    year = {2013},
    note = {Conference Name: 7th International Technology, Education and Development Conference
ISBN: 9788461626618
Meeting Name: 7th International Technology, Education and Development Conference
Place: Valencia, Spain
Publisher: IATED},
    pages = {5691--5700},
    file = {Caiza en Alamo - 2013 - PROGRAMMING ASSIGNMENTS AUTOMATIC GRADING REVIEW .pdf:/home/niko/Zotero/storage/XGYXDCLP/Caiza en Alamo - 2013 - PROGRAMMING ASSIGNMENTS AUTOMATIC GRADING REVIEW .pdf:application/pdf},
}

@article{higgins_coursemarker_2003,
    title = {The {CourseMarker} {CBA} {System}: {Improvements} over {Ceilidh}},
    volume = {8},
    issn = {1573-7608},
    shorttitle = {The {CourseMarker} {CBA} {System}},
    url = {https://link.springer.com/article/10.1023/A:1026364126982},
    doi = {10.1023/A:1026364126982},
    abstract = {This document reports on the results of re-designing and re-implementing the Ceilidh courseware system. It highlights the limitations identified in the thirteen years of Ceilidh's use at the University of Nottingham. It also illustrates how most of these limitations have been resolved by re-designing Ceilidh's architecture and improving various aspects of the marking and administrating processes. The new system, entitled CourseMarker, offers enhanced functionality by adding useful features that have long been needed by Ceilidh's community. The paper concludes with an evaluation of the changes and a brief report on the experience of CourseMarker's use over the last three years. Finally, recent developments and future directions are discussed.},
    language = {en},
    number = {3},
    urldate = {2023-09-13},
    journal = {Education and Information Technologies},
    author = {Higgins, Colin and Hegazy, Tarek and Symeonidis, Pavlos and Tsintsifas, Athanasios},
    month = sep,
    year = {2003},
    keywords = {automatic assessment of programming coursework, free response Computer Based Assessment (CBA)},
    pages = {287--304},
    file = {Full Text PDF:/home/niko/Zotero/storage/YJIZXLUK/Higgins e.a. - 2003 - The CourseMarker CBA System Improvements over Cei.pdf:application/pdf},
}

@article{luck_secure_1999,
    title = {A secure on-line submission system},
    volume = {29},
    copyright = {Copyright {\textcopyright} 1999 John Wiley \& Sons, Ltd.},
    issn = {1097-024X},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-024X%2819990710%2929%3A8%3C721%3A%3AAID-SPE257%3E3.0.CO%3B2-0},
    doi = {10.1002/(SICI)1097-024X(19990710)29:8<721::AID-SPE257>3.0.CO;2-0},
    abstract = {As student numbers on computer science courses continue to increase, the corresponding demands placed on teaching staff in terms of assessment grow ever stronger. In particular, the submission and assessment of practical work on large programming courses can present very significant problems. In response to this, we have developed a networked suite of software utilities that allow on-line submission, testing and marking of coursework. It has been developed and used over the course of five years, and has evolved into a mature tool that has greatly reduced the administrative time spent managing the processes of submission and assessment. In this paper, we describe the software and its implementation, and discuss the issues involved in its construction. Copyright {\textcopyright} 1999 John Wiley \& Sons, Ltd.},
    language = {en},
    number = {8},
    urldate = {2023-09-13},
    journal = {Software: Practice and Experience},
    author = {Luck, Michael and Joy, Mike},
    month = jul,
    year = {1999},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-024X\%2819990710\%2929\%3A8\%3C721\%3A\%3AAID-SPE257\%3E3.0.CO\%3B2-0},
    keywords = {assessment, course management, coursework, security, submission, testing},
    pages = {721--740},
    file = {Full Text PDF:/home/niko/Zotero/storage/CI7CXFHU/Luck en Joy - 1999 - A secure on-line submission system.pdf:application/pdf},
}

@article{hattie_power_2007,
    title = {The {Power} of {Feedback}},
    volume = {77},
    issn = {0034-6543},
    url = {https://journals.sagepub.com/doi/full/10.3102/003465430298487},
    doi = {10.3102/003465430298487},
    abstract = {Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.},
    language = {en},
    number = {1},
    urldate = {2023-09-13},
    journal = {Review of Educational Research},
    author = {Hattie, John and Timperley, Helen},
    month = mar,
    year = {2007},
    note = {Publisher: American Educational Research Association},
    pages = {81--112},
    file = {SAGE PDF Full Text:/home/niko/Zotero/storage/67PLU6YB/Hattie en Timperley - 2007 - The Power of Feedback.pdf:application/pdf},
}

@article{timmis_rethinking_2016,
    title = {Rethinking assessment in a digital age: opportunities, challenges and risks},
    volume = {42},
    copyright = {{\textcopyright} 2015 British Educational Research Association},
    issn = {1469-3518},
    shorttitle = {Rethinking assessment in a digital age},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/berj.3215},
    doi = {10.1002/berj.3215},
    abstract = {While it is frequently argued that assessment sits at the heart of the learning process, in practice assessment often remains narrowly focused on qualifications and reporting achievements, driven by institutional and societal aspirations and tensions such as accountability and economic well being. Yet, the need for assessment to account for the knowledge, skills, dispositions and attitudes necessary to equip young people for a changing and increasingly digital world is also increasingly acknowledged. Based on our recent research review, this article critically examines the role of technology enhanced assessment (or TEA). We argue that while technology offers many potentially creative opportunities for innovation and for rethinking assessment purposes, there are also numerous risks and challenges. In particular we highlight ethical concerns over social exclusion and new forms of digital dividedness and the increasing risks associated with big data and the rise of learning analytics. Finally, we note that much research and innovation happens in silos, where policy, research and practice on assessment, technology enhanced assessment and ethical and political concerns are not linked up. We conclude that there needs to be a much more wide-ranging, critical and nuanced discussion in educational and policy circles so that debates about the potential of technology can be linked to improving assessment in the light of the range of social and political challenges that such progress presents. We end with some critical questions for policy, practice and research communities, which we offer as a starting point for future thinking and ways forward.},
    language = {en},
    number = {3},
    urldate = {2023-09-13},
    journal = {British Educational Research Journal},
    author = {Timmis, Sue and Broadfoot, Patricia and Sutherland, Rosamund and Oldfield, Alison},
    year = {2016},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/berj.3215},
    keywords = {learning analytics, collaboration, digital literacies, e-assessment, ethics, formative/summative, inclusion},
    pages = {454--476},
    file = {Full Text PDF:/home/niko/Zotero/storage/NVAUKC4J/Timmis e.a. - 2016 - Rethinking assessment in a digital age opportunit.pdf:application/pdf},
}

@article{maertens_dolos_2022,
    title = {Dolos: {Language}-agnostic plagiarism detection in source code},
    volume = {38},
    copyright = {{\textcopyright} 2022 John Wiley \& Sons Ltd},
    issn = {1365-2729},
    shorttitle = {Dolos},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jcal.12662},
    doi = {10.1111/jcal.12662},
    abstract = {Background Learning to code is increasingly embedded in secondary and higher education curricula, where solving programming exercises plays an important role in the learning process and in formative and summative assessment. Unfortunately, students admit that copying code from each other is a common practice and teachers indicate they rarely use plagiarism detection tools. Objectives We want to lower the barrier for teachers to detect plagiarism by introducing a new source code plagiarism detection tool (Dolos) that is powered by state-of-the art similarity detection algorithms, offers interactive visualizations, and uses generic parser models to support a broad range of programming languages. Methods Dolos is compared with state-of-the-art plagiarism detection tools in a benchmark based on a standardized dataset. We describe our experience with integrating Dolos in a programming course with a strong focus on online learning and the impact of transitioning to remote assessment during the COVID-19 pandemic. Results and Conclusions Dolos outperforms other plagiarism detection tools in detecting potential cases of plagiarism and is a valuable tool for preventing and detecting plagiarism in online learning environments. It is available under the permissive MIT open-source license at https://dolos.ugent.be. Implications Dolos lowers barriers for teachers to discover, prove and prevent plagiarism in programming courses. This helps to enable a shift towards open and online learning and assessment environments, and opens up interesting avenues for more effective learning and better assessment.},
    language = {en},
    number = {4},
    urldate = {2023-09-13},
    journal = {Journal of Computer Assisted Learning},
    author = {Maertens, Rien and Van Petegem, Charlotte and Strijbol, Niko and Baeyens, Toon and Jacobs, Arne Carla and Dawyndt, Peter and Mesuere, Bart},
    year = {2022},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/jcal.12662},
    keywords = {academic dishonesty, cheating, data visualization, online learning, plagiarism, programming language, remote assessment, source code},
    pages = {1046--1061},
    file = {Full Text PDF:/home/niko/Zotero/storage/YUHC9WB4/Maertens e.a. - 2022 - Dolos Language-agnostic plagiarism detection in s.pdf:application/pdf},
}

@inproceedings{mishra_programming_2023,
    address = {Toronto ON Canada},
    title = {The {Programming} {Exercise} {Markup} {Language}: {Towards} {Reducing} the {Effort} {Needed} to {Use} {Automated} {Grading} {Tools}},
    isbn = {978-1-4503-9431-4},
    shorttitle = {The {Programming} {Exercise} {Markup} {Language}},
    url = {https://dl.acm.org/doi/10.1145/3545945.3569734},
    doi = {10.1145/3545945.3569734},
    language = {en},
    urldate = {2023-09-13},
    booktitle = {Proceedings of the 54th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
    publisher = {ACM},
    author = {Mishra, Divyansh S. and Edwards, Stephen H.},
    month = mar,
    year = {2023},
    pages = {395--401},
    file = {Volledige Tekst:/home/niko/Zotero/storage/9AIV6N65/Mishra en Edwards - 2023 - The Programming Exercise Markup Language Towards .pdf:application/pdf},
}

@article{wilkinson_fair_2016,
    title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
    volume = {3},
    copyright = {2016 The Author(s)},
    issn = {2052-4463},
    url = {https://www.nature.com/articles/sdata201618},
    doi = {10.1038/sdata.2016.18},
    abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders{\textemdash}representing academia, industry, funding agencies, and scholarly publishers{\textemdash}have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
    language = {en},
    number = {1},
    urldate = {2023-09-13},
    journal = {Scientific Data},
    author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc{\`e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and {\textquoteright}t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
    month = mar,
    year = {2016},
    note = {Number: 1
Publisher: Nature Publishing Group},
    keywords = {Publication characteristics, Research data},
    pages = {160018},
    file = {Full Text PDF:/home/niko/Zotero/storage/VLNMR78N/Wilkinson e.a. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf:application/pdf},
}

@article{ala-mutka_survey_2005,
    title = {A {Survey} of {Automated} {Assessment} {Approaches} for {Programming} {Assignments}},
    volume = {15},
    issn = {0899-3408},
    url = {https://doi.org/10.1080/08993400500150747},
    doi = {10.1080/08993400500150747},
    abstract = {Practical programming is one of the basic skills pursued in computer science education. On programming courses, the coursework consists of programming assignments that need to be assessed from different points of view. Since the submitted assignments are executable programs with a formal structure, some features can be assessed automatically. The basic requirement for automated assessment is the numerical measurability of assessment targets, but semiautomatic approaches can overcome this restriction. Recognizing automatically assessable features can help teachers to create educational models, where automatic tools let teachers concentrate their work on the learning issues that need student-teacher interaction the most. Several automatic tools for both static and dynamic assessment of computer programs have been reported in the literature. This article promotes these issues by surveying several automatic approaches for assessing programming assignments. Not all the existing tools will be covered, simply because of the vast number of them. The article concentrates on bringing forward different assessment techniques and approaches to give an interested reader starting points for finding further information in the area. Automatic assessment tools can be used to help teachers in grading tasks as well as to support students' working process with automatic feedback. Common advantages of automation are the speed, availability, consistency and objectivity of assessment. However, automatic tools emphasize the need for careful pedagogical design of the assignment and assessment settings. To effectively share the knowledge and good assessment solutions already developed, better interoperability and portability of the tools is needed.},
    number = {2},
    urldate = {2023-09-13},
    journal = {Computer Science Education},
    author = {Ala-Mutka, Kirsti M.},
    month = jun,
    year = {2005},
    note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/08993400500150747},
    pages = {83--102},
    file = {Full Text PDF:/home/niko/Zotero/storage/CJ9HXSVC/Ala-Mutka - 2005 - A Survey of Automated Assessment Approaches for Pr.pdf:application/pdf},
}

@inproceedings{ihantola_review_2010,
    address = {Koli Finland},
    title = {Review of recent systems for automatic assessment of programming assignments},
    isbn = {978-1-4503-0520-4},
    url = {https://dl.acm.org/doi/10.1145/1930464.1930480},
    doi = {10.1145/1930464.1930480},
    language = {en},
    urldate = {2023-09-13},
    booktitle = {Proceedings of the 10th {Koli} {Calling} {International} {Conference} on {Computing} {Education} {Research}},
    publisher = {ACM},
    author = {Ihantola, Petri and Ahoniemi, Tuukka and Karavirta, Ville and Sepp{\"a}l{\"a}, Otto},
    month = oct,
    year = {2010},
    pages = {86--93},
    file = {Ihantola e.a. - 2010 - Review of recent systems for automatic assessment .pdf:/home/niko/Zotero/storage/YVY9MMX3/Ihantola e.a. - 2010 - Review of recent systems for automatic assessment .pdf:application/pdf},
}

@article{murphy_analysis_2017,
    title = {An {Analysis} of {Introductory} {Programming} {Courses} at {UK} {Universities}},
    volume = {1},
    issn = {2473-7321},
    url = {https://programming-journal.org/2017/1/18/},
    doi = {10.22152/programming-journal.org/2017/1/18},
    abstract = {Context: In the context of exploring the art, science and engineering of programming, the question of which programming languages should ...},
    language = {en},
    number = {2},
    urldate = {2023-09-13},
    journal = {The Art, Science, and Engineering of Programming},
    author = {Murphy, Ellen and Crick, Tom and Davenport, James H.},
    month = apr,
    year = {2017},
    pages = {18:1--18:23},
    file = {Full Text PDF:/home/niko/Zotero/storage/9AZZBR2R/Murphy e.a. - 2017 - An Analysis of Introductory Programming Courses at.pdf:application/pdf},
}

@article{douce_automatic_2005,
    title = {Automatic test-based assessment of programming: {A} review},
    volume = {5},
    issn = {1531-4278, 1531-4278},
    shorttitle = {Automatic test-based assessment of programming},
    url = {https://dl.acm.org/doi/10.1145/1163405.1163409},
    doi = {10.1145/1163405.1163409},
    abstract = {Systems that automatically assess student programming assignments have been designed and used for over forty years. Systems that objectively test and mark student programming work were developed simultaneously with programming assessment in the computer science curriculum. This article reviews a number of influential automatic assessment systems, including descriptions of the earliest systems, and presents some of the most recent developments. The final sections explore a number of directions automated assessment systems may take, presenting current developments alongside a number of important emerging e-learning specifications.},
    language = {en},
    number = {3},
    urldate = {2023-09-13},
    journal = {Journal on Educational Resources in Computing},
    author = {Douce, Christopher and Livingstone, David and Orwell, James},
    month = sep,
    year = {2005},
    pages = {4},
    file = {Douce e.a. - 2005 - Automatic test-based assessment of programming A .pdf:/home/niko/Zotero/storage/FS2ZW3RE/Douce e.a. - 2005 - Automatic test-based assessment of programming A .pdf:application/pdf},
}

@article{ullah_effect_2018,
    title = {The effect of automatic assessment on novice programming: {Strengths} and limitations of existing systems},
    volume = {26},
    copyright = {{\textcopyright} 2018 Wiley Periodicals, Inc.},
    issn = {1099-0542},
    shorttitle = {The effect of automatic assessment on novice programming},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cae.21974},
    doi = {10.1002/cae.21974},
    abstract = {Computer programming is always of high concern for students in introductory programming courses. High rates of failure occur every semester due to lack of adequate skills in programming. No student can become a programmer overnight because such learning requires proper guidance as well as consistent practice with the programming exercises. The role of instructors in the development of students' learning skills is crucial in order to provide feedback on their errors and improve their knowledge accordingly. On the other hand, due to the large number of students, instructors are also overloading themselves to focus on each individual student's errors. To address these issues, researchers have developed numerous Automatic Assessment (AA) systems that not only evaluate the students' programs but also provide instant feedback on their errors as well as abridge the workload of the instructors. Due to the large pool of existing systems, it is difficult to cover each and every system in one study. Therefore, this paper provides a comprehensive overview of some of the existing systems based on the three-analysis approaches: dynamic, static, and hybrid. Moreover, this paper aims to discuss the strengths and limitations of these systems and suggests some potential recommendations regarding the AA specifications for novice programming, which may help in standardizing these systems.},
    language = {en},
    number = {6},
    urldate = {2023-09-13},
    journal = {Computer Applications in Engineering Education},
    author = {Ullah, Zahid and Lajis, Adidah and Jamjoom, Mona and Altalhi, Abdulrahman and Al-Ghamdi, Abdullah and Saleem, Farrukh},
    year = {2018},
    note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cae.21974},
    keywords = {automatic assessment, dynamic, novice programming, static, system},
    pages = {2328--2341},
    file = {Full Text PDF:/home/niko/Zotero/storage/9RUURTJI/Ullah e.a. - 2018 - The effect of automatic assessment on novice progr.pdf:application/pdf},
}

@phdthesis{khorram_testing_2022,
    type = {Theses},
    title = {A testing framework for executable domain-specific languages},
    url = {https://theses.hal.science/tel-03977604},
    school = {Ecole nationale sup{\'e}rieure Mines-T{\'e}l{\'e}com Atlantique},
    author = {Khorram, Faezeh},
    month = dec,
    year = {2022},
    note = {Issue: 2022IMTA0332},
    keywords = {Amplification des tests, D{\'e}bogage des tests, Executable Domain Specific Language (xDSL), Ing{\'e}nierie dirig{\'e}e par les mod{\`e}les (IDM), Langage de mod{\'e}lisation d{\'e}di{\'e} (LMD), Mesure de la qualit{\'e} des tests, Model testing, Model-Driven Engineering (MDE), Test amplification, Test debugging, Test quality measurement, Tests de mod{\`e}les},
}

@article{runeson_survey_2006,
    title = {A survey of unit testing practices},
    volume = {23},
    issn = {0740-7459},
    url = {http://ieeexplore.ieee.org/document/1657935/},
    doi = {10.1109/MS.2006.91},
    number = {4},
    urldate = {2023-09-13},
    journal = {IEEE Software},
    author = {Runeson, Per},
    month = jul,
    year = {2006},
    pages = {22--29},
    file = {Runeson - 2006 - A survey of unit testing practices.pdf:/home/niko/Zotero/storage/GJHX6T3J/Runeson - 2006 - A survey of unit testing practices.pdf:application/pdf},
}

@article{ellsworth_quiver_2004,
    title = {The {Quiver} system},
    volume = {36},
    issn = {0097-8418},
    url = {https://dl.acm.org/doi/10.1145/1028174.971374},
    doi = {10.1145/1028174.971374},
    abstract = {The Quiver (QUIz VERification) System is an Internet server for building, maintaining, and administering programming quizzes. It is similar to the online judges used for programming contests but differs in that it targets the classroom use of programming quizzes as a teaching aid and evaluation tool. It can provide very detailed feedback regarding quiz behavior so that the student can debug her program. This system is developed as part of the grant "Intra-Curriculum Software Engineering Education" funded by the National Science Foundation (DUE 0127439).},
    language = {en},
    number = {1},
    urldate = {2023-09-13},
    journal = {ACM SIGCSE Bulletin},
    author = {Ellsworth, Christopher C. and Fenwick, James B. and Kurtz, Barry L.},
    month = mar,
    year = {2004},
    pages = {205--209},
    file = {Ellsworth e.a. - 2004 - The Quiver system.pdf:/home/niko/Zotero/storage/W29N25AL/Ellsworth e.a. - 2004 - The Quiver system.pdf:application/pdf},
}

@inproceedings{bettini_environment_2004,
    address = {Joensuu, Finland},
    title = {An environment for self-assessing java programming skills in undergraduate first programming courses},
    isbn = {978-0-7695-2181-7},
    url = {http://ieeexplore.ieee.org/document/1357395/},
    doi = {10.1109/ICALT.2004.1357395},
    urldate = {2023-09-13},
    booktitle = {{IEEE} {International} {Conference} on {Advanced} {Learning} {Technologies}, 2004. {Proceedings}.},
    publisher = {IEEE},
    author = {Bettini, Lorenzo and Crescenzi, Pilu and Innocenti, Gaia and Loreti, Michele and Cecchi, Leonardo},
    year = {2004},
    pages = {161--165},
    file = {Bettini e.a. - 2004 - An environment for self-assessing java programming.pdf:/home/niko/Zotero/storage/G63BTHVL/Bettini e.a. - 2004 - An environment for self-assessing java programming.pdf:application/pdf},
}

@misc{pan_software_1999-1,
    title = {Software {Testing}},
    url = {https://users.ece.cmu.edu/~koopman/des_s99/sw_testing/},
    abstract = {Software testing is any activity aimed at evaluating an attribute or capability of a program or system and determining that it meets its required results. [Hetzel88] Although crucial to software quality and widely deployed by programmers and testers, software testing still remains an art, due to limited understanding of the principles of software. The difficulty in software testing stems from the complexity of software: we can not completely test a program with moderate complexity. Testing is more than just debugging. The purpose of testing can be quality assurance, verification and validation, or reliability estimation. Testing can be used as a generic metric as well. Correctness testing and reliability testing are two major areas of testing. Software testing is a trade-off between budget, time and quality.},
    language = {en},
    publisher = {Dependable Embedded Systems},
    author = {Pan, Jiantao},
    year = {1999},
    file = {httpwww.ece.cmu.edu~koopmandes_s99sw_testing.pdf:/home/niko/Zotero/storage/FCJ332S5/httpwww.ece.cmu.edu~koopmandes_s99sw_testing.pdf:application/pdf},
}

@inproceedings{agrawal_survey_2022,
    title = {A survey on grading format of automated grading tools for programming assignments},
    url = {http://arxiv.org/abs/2212.01714},
    doi = {10.21125/iceri.2022.1912},
    abstract = {The prevalence of online platforms and studies has generated the demand for automated grading tools, and as a result, there are plenty in the market. Such tools are developed to grade coding assignments quickly, accurately, and effortlessly. Since there are varieties of tools available to cater to the diverse options of programming languages and concepts, it is overwhelming for any instructor to decide which one suits one's requirements. There are several surveys studying the tools and giving insights into how they function and what they support. However other than knowing the functionality, it is important for an instructor to know how the assignments are graded and what is the format of the test cases. This is crucial since the instructor has to design the grading format and therefore requires a learning curve. This survey studies and evaluates the automated grading tools based on their evaluation format. This in turn helps a reader in deciding which tool to choose and provides an insight into what are the assessment settings and approaches used in grading the coding assignment in any specific grading tool.},
    urldate = {2023-09-13},
    author = {Agrawal, Aditi and Reed, Benjamin},
    month = nov,
    year = {2022},
    note = {arXiv:2212.01714 [cs]},
    keywords = {Computer Science - Computers and Society},
    pages = {7506--7514},
    file = {arXiv Fulltext PDF:/home/niko/Zotero/storage/ZYT2ZQ6B/Agrawal en Reed - 2022 - A survey on grading format of automated grading to.pdf:application/pdf;arXiv.org Snapshot:/home/niko/Zotero/storage/5H9PYVBA/2212.html:text/html},
}

@inproceedings{nayak_automated_2022,
    address = {Coimbatore, India},
    title = {Automated {Assessment} {Tools} for grading of programming {Assignments}: {A} review},
    isbn = {978-1-66548-035-2},
    shorttitle = {Automated {Assessment} {Tools} for grading of programming {Assignments}},
    url = {https://ieeexplore.ieee.org/document/9740769/},
    doi = {10.1109/ICCCI54379.2022.9740769},
    urldate = {2023-09-13},
    booktitle = {2022 {International} {Conference} on {Computer} {Communication} and {Informatics} ({ICCCI})},
    publisher = {IEEE},
    author = {Nayak, Sidhidatri and Agarwal, Reshu and Khatri, Sunil Kumar},
    month = jan,
    year = {2022},
    pages = {1--4},
    file = {Nayak e.a. - 2022 - Automated Assessment Tools for grading of programm.pdf:/home/niko/Zotero/storage/GRPPNQHT/Nayak e.a. - 2022 - Automated Assessment Tools for grading of programm.pdf:application/pdf},
}

@article{strijbol_testededucational_2023,
    title = {{TESTed}{\textemdash}{An} educational testing framework with language-agnostic test suites for programming exercises},
    volume = {22},
    issn = {2352-7110},
    doi = {10.1016/j.softx.2023.101404},
    abstract = {In educational contexts, automated assessment tools (AAT) are commonly used to provide formative feedback on programming exercises. However, designing exercises for AAT remains a laborious task or imposes limitations on the exercises. Most AAT use either output comparison, where the generated output is compared against an expected output, or unit testing, where the tool has access to the code of the submission under test. While output comparison has the advantage of being programming language independent, the testing capabilities are limited to the output. Conversely, unit testing can generate more granular feedback, but is tightly coupled with the programming language of the submission. In this paper, we introduce TESTed, which enables the best of both worlds: combining the granular feedback of unit testing with the programming language independence of output comparison. Educators can save time by designing exercises that can be used across programming languages. Finally, we report on using TESTed in educational practice.},
    journal = {SoftwareX},
    author = {Strijbol, Niko and Van Petegem, Charlotte and Maertens, Rien and Sels, Boris and Scholliers, Christophe and Dawyndt, Peter and Mesuere, Bart},
    month = may,
    year = {2023},
    keywords = {Programming, Automated assessment tools, Educational software testing, Feedback},
    pages = {101404},
}

@misc{ben-kiki_yaml_2021,
    title = {{YAML} {Ain}{\textquoteright}t {Markup} {Language} ({YAML}{\texttrademark}) version 1.2},
    url = {https://yaml.org/spec/1.2.2/},
    author = {Ben-Kiki, Oren and M{\"u}ller, Tina and d{\"o}t Net, Ingy and Antoniou, Pantelis and Aro, Eemeli and Smith, Thomas and Evans, Clark C.},
    month = oct,
    year = {2021},
}

@article{truong_learning_2005,
    title = {Learning to program through the web},
    volume = {37},
    issn = {0097-8418},
    url = {https://dl.acm.org/doi/10.1145/1151954.1067452},
    doi = {10.1145/1151954.1067452},
    abstract = {Computer-based tutoring systems which assist students in solving introductory programming problems have significant potential for improving the quality of programming education and reducing the instructor's work load. The innovative Environment for Learning to Program (ELP) provides an interactive web-based environment for teaching programming to first year Information Technology students at Queensland University of Technology (QUT). ELP allows students to undertake programming exercises by "filling in the gaps" of a partial computer program presented in a web page and to receive guidance in getting their programs to compile and run. Feedback on quality and correctness is provided through a program analysis framework. Students are given the opportunity to produce working programs at the early stages of their course without the need to familiarize themselves with a complex program development environment.},
    language = {en},
    number = {3},
    urldate = {2023-09-13},
    journal = {ACM SIGCSE Bulletin},
    author = {Truong, Nghi and Bancroft, Peter and Roe, Paul},
    month = sep,
    year = {2005},
    pages = {9--13},
    file = {Truong e.a. - 2005 - Learning to program through the web.pdf:/home/niko/Zotero/storage/DVLWSWX9/Truong e.a. - 2005 - Learning to program through the web.pdf:application/pdf},
}

@article{booker_cracking_2019,
    title = {Cracking the problem with 33},
    volume = {5},
    issn = {2363-9555},
    url = {https://doi.org/10.1007/s40993-019-0162-1},
    doi = {10.1007/s40993-019-0162-1},
    abstract = {Inspired by the Numberphile video {\textquotedblleft}The uncracked problem with 33{\textquotedblright} by Browning and Brady Haran (https://youtu.be/wymmCdLdPvM), we investigate solutions to \$\$x{\textasciicircum}3+y{\textasciicircum}3+z{\textasciicircum}3=k\$\$for a few small values of k. We find the first known solutions for \$\$k=33\$\$and \$\$k=795\$\$.},
    language = {en},
    number = {3},
    urldate = {2023-09-13},
    journal = {Research in Number Theory},
    author = {Booker, Andrew R.},
    month = jul,
    year = {2019},
    keywords = {Diophantine equations, Hasse principle, Sums of three cubes},
    pages = {26},
    file = {Full Text PDF:/home/niko/Zotero/storage/NCFFI3TE/Booker - 2019 - Cracking the problem with 33.pdf:application/pdf},
}

@inproceedings{fonte_flexible_2013,
    address = {Dagstuhl, Germany},
    series = {{OpenAccess} {Series} in {Informatics} ({OASIcs})},
    title = {A {Flexible} {Dynamic} {System} for {Automatic} {Grading} of {Programming} {Exercises}},
    volume = {29},
    isbn = {978-3-939897-52-1},
    url = {http://drops.dagstuhl.de/opus/volltexte/2013/4034},
    doi = {10.4230/OASIcs.SLATE.2013.129},
    urldate = {2023-09-14},
    booktitle = {2nd {Symposium} on {Languages}, {Applications} and {Technologies}},
    publisher = {Schloss Dagstuhl{\textendash}Leibniz-Zentrum fuer Informatik},
    author = {Fonte, Daniela and Cruz, Daniela da and Gan{\c c}arski, Alda Lopes and Henriques, Pedro Rangel},
    editor = {Leal, Jos{\'e} Paulo and Rocha, Ricardo and Sim{\~o}es, Alberto},
    year = {2013},
    note = {ISSN: 2190-6807},
    keywords = {Automatic Grading Systems, Domain Specific Languages, DSL, Dynamic Analysis},
    pages = {129--144},
    file = {Full Text PDF:/home/niko/Zotero/storage/8QAT7HRY/Fonte e.a. - 2013 - A Flexible Dynamic System for Automatic Grading of.pdf:application/pdf},
}

@inproceedings{enstrom_five_2011,
    address = {Rapid City, SD, USA},
    title = {Five years with kattis {\textemdash} {Using} an automated assessment system in teaching},
    isbn = {978-1-61284-469-5 978-1-61284-468-8 978-1-61284-467-1},
    url = {http://ieeexplore.ieee.org/document/6142931/},
    doi = {10.1109/FIE.2011.6142931},
    urldate = {2023-09-14},
    booktitle = {2011 {Frontiers} in {Education} {Conference} ({FIE})},
    publisher = {IEEE},
    author = {Enstrom, Emma and Kreitz, Gunnar and Niemela, Fredrik and Soderman, Pehr and Kann, Viggo},
    month = oct,
    year = {2011},
    pages = {T3J--1--T3J--6},
    file = {Enstrom e.a. - 2011 - Five years with kattis &#x2014\; Using an automated.pdf:/home/niko/Zotero/storage/EWFVGRVC/Enstrom e.a. - 2011 - Five years with kattis &#x2014\; Using an automated.pdf:application/pdf},
}

@inproceedings{sarsa_speeding_2022,
    address = {Dublin Ireland},
    title = {Speeding {Up} {Automated} {Assessment} of {Programming} {Exercises}},
    isbn = {978-1-4503-9742-1},
    url = {https://dl.acm.org/doi/10.1145/3555009.3555013},
    doi = {10.1145/3555009.3555013},
    language = {en},
    urldate = {2023-09-14},
    booktitle = {The {United} {Kingdom} and {Ireland} {Computing} {Education} {Research} ({UKICER}) {Conference}},
    publisher = {ACM},
    author = {Sarsa, Sami and Leinonen, Juho and Koutcheme, Charles and Hellas, Arto},
    month = sep,
    year = {2022},
    pages = {1--7},
    file = {Volledige Tekst:/home/niko/Zotero/storage/WSK8HXPP/Sarsa e.a. - 2022 - Speeding Up Automated Assessment of Programming Ex.pdf:application/pdf},
}

@inproceedings{peveler_comparing_2019,
    address = {Minneapolis MN USA},
    title = {Comparing {Jailed} {Sandboxes} vs {Containers} {Within} an {Autograding} {System}},
    isbn = {978-1-4503-5890-3},
    url = {https://dl.acm.org/doi/10.1145/3287324.3287507},
    doi = {10.1145/3287324.3287507},
    language = {en},
    urldate = {2023-09-14},
    booktitle = {Proceedings of the 50th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
    publisher = {ACM},
    author = {Peveler, Matthew and Maicus, Evan and Cutler, Barbara},
    month = feb,
    year = {2019},
    pages = {139--145},
    file = {Peveler e.a. - 2019 - Comparing Jailed Sandboxes vs Containers Within an.pdf:/home/niko/Zotero/storage/R3RQCELJ/Peveler e.a. - 2019 - Comparing Jailed Sandboxes vs Containers Within an.pdf:application/pdf},
}

@book{iso_isoiecieee_1998,
    address = {pub-ISO:adr},
    title = {{ISO}/{IEC}/{IEEE} 9945:2009: information},
    isbn = {????},
    url = {http://webstore.ansi.org/ansidocstore/product.asp?sku=ISO%2FIEC+14882%2D1998;                  http://webstore.ansi.org/ansidocstore/product.asp?sku=ISO%2FIEC+14882%3A1998;                  http://www.iso.ch/cate/d25845.html;                  https://webstore.ansi.org/},
    publisher = {pub-ISO},
    author = {{ISO}},
    month = sep,
    year = {1998},
    lccn = {????},
}

@misc{schlueter_tap14_2022,
    title = {{TAP14} - {The} {Test} {Anything} {Protocol} v14},
    url = {https://testanything.org/tap-version-14-specification.html},
    author = {Schlueter, Isaac Z. and Layman, Matt and Timmermans, Leon and Kinoshita, Bruno P. and Granum, Chad},
    year = {2022},
}

@misc{sutherland_sums_2019,
    address = {Waterloo},
    title = {Sums of three cubes},
    url = {https://math.mit.edu/~drew/Waterloo2019.pdf},
    author = {Sutherland, Andrew V. and Booker, Andrew},
    month = sep,
    year = {2019},
    file = {Volledige Tekst:/home/niko/Zotero/storage/E2KP7E9B/Sutherland en Booker - 2019 - Sums of three cubes.pdf:application/pdf},
}

@incollection{beck_simple_1997,
    address = {Cambridge},
    title = {Simple {Smalltalk} {Testing}},
    isbn = {978-0-511-57497-9},
    url = {https://www.cambridge.org/core/books/abs/kent-becks-guide-to-better-smalltalk/simple-smalltalk-testing/0D2F14E0129D5EF29E85D796A5B845FC},
    urldate = {2023-12-19},
    booktitle = {Kent {Beck}'s {Guide} to {Better} {Smalltalk}: {A} {Sorted} {Collection}},
    publisher = {Cambridge University Press},
    author = {Beck, Kent},
    year = {1997},
    doi = {10.1017/CBO9780511574979},
    pages = {277--288},
}

@inproceedings{hidalgo-cespedes_evaluation_2023,
    address = {La Paz, Bolivia},
    title = {Evaluation of an {Online} {Judge} for {Concurrent} {Programming} {Learning}},
    isbn = {9798350318876},
    url = {https://ieeexplore.ieee.org/document/10346201/},
    doi = {10.1109/CLEI60451.2023.10346201},
    urldate = {2024-02-13},
    booktitle = {2023 {XLIX} {Latin} {American} {Computer} {Conference} ({CLEI})},
    publisher = {IEEE},
    author = {Hidalgo-C{\'e}spedes, Jeisson},
    month = oct,
    year = {2023},
    pages = {1--9},
    file = {Volledige Tekst:/home/niko/Zotero/storage/HJXFI2XW/Hidalgo-C{\'e}spedes - 2023 - Evaluation of an Online Judge for Concurrent Progr.pdf:application/pdf},
}

@book{bass_software_2021,
    edition = {4th edition},
    title = {Software {Architecture} in {Practice}, 4th {Edition}},
    isbn = {978-0-13-688567-2},
    abstract = {The Definitive, Practical, Proven Guide to Architecting Modern Software--Now Fully Updated Now with nine new chapters, Software Architecture in Practice, Fourth Edition, thoroughly explains what software architecture is, why it's important, and how to design, instantiate, analyze, evolve, and manage it in disciplined and effective ways. Three renowned software architects cover the entire lifecycle, presenting practical guidance, expert methods, and tested models for use in any project, no matter how complex. You'll learn how to use architecture to address accelerating growth in requirements, system size, and abstraction, and to manage emergent quality attributes as systems are dynamically combined in new ways. With insights for utilizing architecture to optimize key quality attributes--including performance, modifiability, security, availability, interoperability, testability, usability, deployability, and more--this guide explains how to manage and refine existing architectures, transform them to solve new problems, and build reusable architectures that become strategic business assets. Discover how architecture influences (and is influenced by) technical environments, project lifecycles, business profiles, and your own practices Leverage proven patterns, interfaces, and practices for optimizing quality through architecture Architect for mobility, the cloud, machine learning, and quantum computing Design for increasingly crucial attributes such as energy efficiency and safety Scale systems by discovering architecturally significant influences, using DevOps and deployment pipelines, and managing architecture debt Understand architecture's role in the organization, so you can deliver more value},
    language = {eng},
    publisher = {Addison-Wesley Professional},
    author = {Bass, Len and Clements, Paul and Kazman, Rick},
    year = {2021},
    note = {OCLC: 1251808773},
    file = {Bass e.a. - 2021 - Software Architecture in Practice, 4th Edition.pdf:/home/niko/Zotero/storage/3AGGDVKE/Bass e.a. - 2021 - Software Architecture in Practice, 4th Edition.pdf:application/pdf},
}

@article{messer_automated_2024,
    title = {Automated {Grading} and {Feedback} {Tools} for {Programming} {Education}: {A} {Systematic} {Review}},
    volume = {24},
    issn = {1946-6226},
    shorttitle = {Automated {Grading} and {Feedback} {Tools} for {Programming} {Education}},
    url = {https://dl.acm.org/doi/10.1145/3636515},
    doi = {10.1145/3636515},
    abstract = {We conducted a systematic literature review on automated grading and feedback tools for programming education. We analysed 121 research papers from 2017 to 2021 inclusive and categorised them based on skills assessed, approach, language paradigm, degree of automation, and evaluation techniques. Most papers assess the correctness of assignments in object-oriented languages. Typically, these tools use a dynamic technique, primarily unit testing, to provide grades and feedback to the students or static analysis techniques to compare a submission with a reference solution or with a set of correct student submissions. However, these techniques{\textquoteright} feedback is often limited to whether the unit tests have passed or failed, the expected and actual output, or how they differ from the reference solution. Furthermore, few tools assess the maintainability, readability, or documentation of the source code, with most using static analysis techniques, such as code quality metrics, in conjunction with grading correctness. Additionally, we found that most tools offered fully automated assessment to allow for near-instantaneous feedback and multiple resubmissions, which can increase student satisfaction and provide them with more opportunities to succeed. In terms of techniques used to evaluate the tools{\textquoteright} performance, most papers primarily use student surveys or compare the automatic assessment tools to grades or feedback provided by human graders. However, because the evaluation dataset is frequently unavailable, it is more difficult to reproduce results and compare tools to a collection of common assignments.},
    language = {en},
    number = {1},
    urldate = {2024-02-19},
    journal = {ACM Transactions on Computing Education},
    author = {Messer, Marcus and Brown, Neil C. C. and K{\"o}lling, Michael and Shi, Miaojing},
    month = mar,
    year = {2024},
    pages = {1--43},
    file = {Volledige Tekst:/home/niko/Zotero/storage/M73JUWKZ/Messer e.a. - 2024 - Automated Grading and Feedback Tools for Programmi.pdf:application/pdf},
}

@misc{ronacher_jinja_nodate,
    title = {Jinja},
    url = {https://jinja.palletsprojects.com/en/3.1.x/},
    publisher = {Pallets Projects},
    author = {Ronacher, Armin and Lord, David},
}
