@inproceedings{agrawalSurveyGradingFormat2022,
  title = {A Survey on Grading Format of Automated Grading Tools for Programming Assignments},
  author = {Agrawal, Aditi and Reed, Benjamin},
  date = {2022-11},
  eprint = {2212.01714},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {7506--7514},
  doi = {10.21125/iceri.2022.1912},
  url = {http://arxiv.org/abs/2212.01714},
  urldate = {2023-09-13},
  abstract = {The prevalence of online platforms and studies has generated the demand for automated grading tools, and as a result, there are plenty in the market. Such tools are developed to grade coding assignments quickly, accurately, and effortlessly. Since there are varieties of tools available to cater to the diverse options of programming languages and concepts, it is overwhelming for any instructor to decide which one suits one's requirements. There are several surveys studying the tools and giving insights into how they function and what they support. However other than knowing the functionality, it is important for an instructor to know how the assignments are graded and what is the format of the test cases. This is crucial since the instructor has to design the grading format and therefore requires a learning curve. This survey studies and evaluates the automated grading tools based on their evaluation format. This in turn helps a reader in deciding which tool to choose and provides an insight into what are the assessment settings and approaches used in grading the coding assignment in any specific grading tool.},
  keywords = {Computer Science - Computers and Society},
  file = {/home/niko/Zotero/storage/ZYT2ZQ6B/Agrawal en Reed - 2022 - A survey on grading format of automated grading to.pdf;/home/niko/Zotero/storage/5H9PYVBA/2212.html}
}

@article{ala-mutkaSurveyAutomatedAssessment2005,
  title = {A {{Survey}} of {{Automated Assessment Approaches}} for {{Programming Assignments}}},
  author = {Ala-Mutka, Kirsti M.},
  date = {2005-06-01},
  journaltitle = {Computer Science Education},
  volume = {15},
  number = {2},
  pages = {83--102},
  publisher = {{Routledge}},
  issn = {0899-3408},
  doi = {10.1080/08993400500150747},
  url = {https://doi.org/10.1080/08993400500150747},
  urldate = {2023-09-13},
  abstract = {Practical programming is one of the basic skills pursued in computer science education. On programming courses, the coursework consists of programming assignments that need to be assessed from different points of view. Since the submitted assignments are executable programs with a formal structure, some features can be assessed automatically. The basic requirement for automated assessment is the numerical measurability of assessment targets, but semiautomatic approaches can overcome this restriction. Recognizing automatically assessable features can help teachers to create educational models, where automatic tools let teachers concentrate their work on the learning issues that need student-teacher interaction the most. Several automatic tools for both static and dynamic assessment of computer programs have been reported in the literature. This article promotes these issues by surveying several automatic approaches for assessing programming assignments. Not all the existing tools will be covered, simply because of the vast number of them. The article concentrates on bringing forward different assessment techniques and approaches to give an interested reader starting points for finding further information in the area. Automatic assessment tools can be used to help teachers in grading tasks as well as to support students' working process with automatic feedback. Common advantages of automation are the speed, availability, consistency and objectivity of assessment. However, automatic tools emphasize the need for careful pedagogical design of the assignment and assessment settings. To effectively share the knowledge and good assessment solutions already developed, better interoperability and portability of the tools is needed.},
  file = {/home/niko/Zotero/storage/CJ9HXSVC/Ala-Mutka - 2005 - A Survey of Automated Assessment Approaches for Pr.pdf}
}

@book{ammannIntroductionSoftwareTesting2016,
  title = {Introduction to {{Software Testing}}},
  author = {Ammann, Paul and Offutt, Jeff},
  date = {2016-12-15},
  edition = {2},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781316771273},
  url = {https://www.cambridge.org/highereducation/books/introduction-to-software-testing/95E57CCADEA697EC8594F03729F47311},
  abstract = {This extensively classroom-tested text takes an innovative approach to explaining software testing that defines it as the process of applying a few precise, general-purpose criteria to a structure or model of the software. The book incorporates cutting-edge developments, including techniques to test modern types of software such as OO, web applications, and embedded software. This revised second edition significantly expands coverage of the basics, thoroughly discussing test automaton frameworks, and it adds new, improved examples and numerous exercises. The theory of coverage criteria is carefully and cleanly explained to help students understand concepts before delving into practical applications, while extensive use of the JUnit test framework gives students practical experience in a test framework popular in the industry. Exercises, meanwhile, feature specifically tailored tools that allow students to check their own work. The book's website also offers an instructor's manual, PowerPoint slides, testing tools for students, and example software programs in Java.},
  isbn = {978-1-107-17201-2},
  pagetotal = {364},
  keywords = {softwareengineering},
  file = {/home/niko/Zotero/storage/VN5QAMJC/Ammann en Offutt - 2016 - Introduction to Software Testing.pdf}
}

@book{bassSoftwareArchitecturePractice2021,
  title = {Software {{Architecture}} in {{Practice}}, 4th {{Edition}}},
  author = {Bass, Len and Clements, Paul and Kazman, Rick},
  date = {2021},
  edition = {4th edition},
  publisher = {{Addison-Wesley Professional}},
  abstract = {The Definitive, Practical, Proven Guide to Architecting Modern Software--Now Fully Updated Now with nine new chapters, Software Architecture in Practice, Fourth Edition, thoroughly explains what software architecture is, why it's important, and how to design, instantiate, analyze, evolve, and manage it in disciplined and effective ways. Three renowned software architects cover the entire lifecycle, presenting practical guidance, expert methods, and tested models for use in any project, no matter how complex. You'll learn how to use architecture to address accelerating growth in requirements, system size, and abstraction, and to manage emergent quality attributes as systems are dynamically combined in new ways. With insights for utilizing architecture to optimize key quality attributes--including performance, modifiability, security, availability, interoperability, testability, usability, deployability, and more--this guide explains how to manage and refine existing architectures, transform them to solve new problems, and build reusable architectures that become strategic business assets. Discover how architecture influences (and is influenced by) technical environments, project lifecycles, business profiles, and your own practices Leverage proven patterns, interfaces, and practices for optimizing quality through architecture Architect for mobility, the cloud, machine learning, and quantum computing Design for increasingly crucial attributes such as energy efficiency and safety Scale systems by discovering architecturally significant influences, using DevOps and deployment pipelines, and managing architecture debt Understand architecture's role in the organization, so you can deliver more value},
  isbn = {978-0-13-688567-2},
  langid = {english},
  annotation = {OCLC: 1251808773},
  file = {/home/niko/Zotero/storage/3AGGDVKE/Bass e.a. - 2021 - Software Architecture in Practice, 4th Edition.pdf}
}

@software{bayerMako2020,
  title = {Mako},
  author = {Bayer, Michael and Dairiki, Geoffrey T and Jenvey, Philip and Peckam, David and Ronacher, Armin and Bangert, Ben and Trofatter, Ben},
  date = {2020-03-01},
  url = {https://www.makotemplates.org/},
  version = {1.1.2}
}

@incollection{beckSimpleSmalltalkTesting1997,
  title = {Simple {{Smalltalk Testing}}},
  booktitle = {Kent {{Beck}}'s {{Guide}} to {{Better Smalltalk}}: {{A Sorted Collection}}},
  author = {Beck, Kent},
  date = {1997},
  pages = {277--288},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9780511574979},
  url = {https://www.cambridge.org/core/books/abs/kent-becks-guide-to-better-smalltalk/simple-smalltalk-testing/0D2F14E0129D5EF29E85D796A5B845FC},
  urldate = {2023-12-19},
  isbn = {978-0-511-57497-9}
}

@standard{ben-kikiYAMLAinMarkup2021,
  title = {{{YAML Ain}}’t {{Markup Language}} ({{YAML}}™) Version 1.2},
  author = {Ben-Kiki, Oren and Müller, Tina and family=Net, given=Ingy, prefix=döt, useprefix=true and Antoniou, Pantelis and Aro, Eemeli and Smith, Thomas and Evans, Clark C.},
  date = {2021-10-01},
  number = {1.2.2},
  url = {https://yaml.org/spec/1.2.2/}
}

@article{berssanetteActiveLearningContext2021,
  title = {Active {{Learning}} in the {{Context}} of the {{Teaching}}/{{Learning}} of {{Computer Programming}}: {{A Systematic Review}}},
  shorttitle = {Active {{Learning}} in the {{Context}} of the {{Teaching}}/{{Learning}} of {{Computer Programming}}},
  author = {Berssanette, João Henrique and family=Francisco, given=Antonio Carlos, prefix=de, useprefix=true},
  date = {2021},
  journaltitle = {Journal of Information Technology Education: Research},
  shortjournal = {JITE:Research},
  volume = {20},
  pages = {201--220},
  issn = {1547-9714, 1539-3585},
  doi = {10.28945/4767},
  url = {https://www.informingscience.org/Publications/4767},
  urldate = {2023-09-13},
  abstract = {Aim/Purpose: This paper presents the results of a systematic literature review that sought to identify the studies that relate the different pedagogical techniques by which active learning is developed in the context of the teaching/learning of computer programming, with the objective to characterize the approaches, the pedagogical techniques used, the application, the contributions, and difficulties of implementation reported by these studies. Background: The literature has shown that teachers in teaching programming have been less successful than they should and need to be, so dropout and failure rates for students remain high. In this sense, much has been discussed about the possibilities and limitations of using the active learning pedagogical techniques in this context. Methodology: For this review, an analysis from all studies mentioning active learning in the context of the teaching/learning of computer programming published between 2014 and 2019 was performed, retrieved in WOS, SCOPUS, ScienceDirect, and ACM Digital Library. The selection of studies was based on a set of criteria established to guide the selection process, including alignment with the research questions and evaluating the quality of studies. Contribution: This study contributes to an overview of the current scenario, characterizing the research studies that associate the different pedagogical techniques of active learning in the context of the teaching/learning of computer programming. Findings: The results showed that the studies’ approaches usually occur by intervention/pedagogical experiment or by the development of a tool, instrument or methodology. The lipped classroom methodology has obtained a notable prominence in research. The use of active learning pedagogical techniques results in greater acceptance or positive feedback from students, increasing their satisfaction or motivation to improve the learning experience, learning outcomes, or student performance. However, they require a greater effort/work by the teacher to plan and/or execute the teaching/learning process. It should be highlighted that the contributions observed for the teaching/learning process of computer programming derive from investigations mainly concentrated in the university context, aiming to observe if these contributions can be reproduced in other education levels. The contributions observed in the studies regarding the uses of pedagogical techniques of active learning in the context of computer programming indicate that their use can contribute significantly to the teaching/learning process, showing it to be a viable alternative and consistent with the reduction of the failures in the learning of programming. Recommendations for Practitioners: Considering that over the years the teaching/learning process of computer programming has been a challenge for students, based on the findings of this research, we recommend that teachers consider restructuring their traditional practices of teaching computer programming, making use of pedagogical techniques of active learning to obtain better learning results of their students. Recommendation for Researchers: We recommend that fellow scholars consider investigating how the difficulties inherent to teachers related to the teaching/learning process of programming may relate to difficulties concerning students and content, especially with regard to traditional teaching practices. Impact on Society: This study adds to previous systematic reviews of the literature, specifically studies that relate active learning to the context of teaching/learning of programming. It is hoped that the findings of this article can support other research that addresses the topic, enabling its development and deepening, through the developed basis from which active learning researchers can work. Future Research: Future studies may investigate the benefits of using different pedagogical techniques for active learning and the costs related to the higher cognitive burden imposed by these techniques for learning computer programming.},
  langid = {english},
  file = {/home/niko/Zotero/storage/D5PP5Z8K/Henrique Berssanette en Carlos De Francisco - 2021 - Active Learning in the Context of the TeachingLea.pdf}
}

@inproceedings{bettiniEnvironmentSelfassessingJava2004,
  title = {An Environment for Self-Assessing Java Programming Skills in Undergraduate First Programming Courses},
  booktitle = {{{IEEE International Conference}} on {{Advanced Learning Technologies}}, 2004. {{Proceedings}}.},
  author = {Bettini, Lorenzo and Crescenzi, Pilu and Innocenti, Gaia and Loreti, Michele and Cecchi, Leonardo},
  date = {2004},
  pages = {161--165},
  publisher = {{IEEE}},
  location = {{Joensuu, Finland}},
  doi = {10.1109/ICALT.2004.1357395},
  url = {http://ieeexplore.ieee.org/document/1357395/},
  urldate = {2023-09-13},
  eventtitle = {{{IEEE International Conference}} on {{Advanced Learning Technologies}}, 2004. {{Proceedings}}.},
  isbn = {978-0-7695-2181-7},
  file = {/home/niko/Zotero/storage/G63BTHVL/Bettini e.a. - 2004 - An environment for self-assessing java programming.pdf}
}

@article{bezURIOnlineJudge2014,
  title = {{{URI Online Judge Academic}}: {{A}} Tool for Algorithms and Programming Classes},
  author = {Bez, Jean Luca and Tonin, Neilor A and Rodegheri, Paulo R},
  date = {2014},
  journaltitle = {2014 9th International Conference on Computer Science \& Education},
  doi = {10.1109/iccse.2014.6926445},
  url = {http://dx.doi.org/10.1109/iccse.2014.6926445},
  file = {/home/niko/Zotero/storage/22676QG5/Bez e.a. - 2014 - URI Online Judge Academic A tool for algorithms a.pdf}
}

@inproceedings{bissyandePopularityInteroperabilityImpact2013,
  title = {Popularity, {{Interoperability}}, and {{Impact}} of {{Programming Languages}} in 100,000 {{Open Source Projects}}},
  booktitle = {2013 {{IEEE}} 37th {{Annual Computer Software}} and {{Applications Conference}}},
  author = {Bissyande, Tegawende F. and Thung, Ferdian and Lo, David and Jiang, Lingxiao and Reveillere, Laurent},
  date = {2013-07},
  pages = {303--312},
  publisher = {{IEEE}},
  location = {{Kyoto, Japan}},
  doi = {10.1109/COMPSAC.2013.55},
  url = {https://ieeexplore.ieee.org/document/6649842},
  urldate = {2022-03-22},
  eventtitle = {2013 {{IEEE}} 37th {{Annual Computer Software}} and {{Applications Conference}} ({{COMPSAC}})},
  isbn = {978-0-7695-4986-6},
  file = {/home/niko/Zotero/storage/YMG7KSD8/Bissyande e.a. - 2013 - Popularity, Interoperability, and Impact of Progra.pdf}
}

@article{blackDevelopingTheoryFormative2009,
  title = {Developing the Theory of Formative Assessment},
  author = {Black, Paul and Wiliam, Dylan},
  date = {2009-02},
  journaltitle = {Educational Assessment, Evaluation and Accountability},
  shortjournal = {Educ Asse Eval Acc},
  volume = {21},
  number = {1},
  pages = {5--31},
  issn = {1874-8597, 1874-8600},
  doi = {10.1007/s11092-008-9068-5},
  url = {http://link.springer.com/10.1007/s11092-008-9068-5},
  urldate = {2022-01-24},
  langid = {english},
  file = {/home/niko/Zotero/storage/I2DVDA4H/Black en Wiliam - 2009 - Developing the theory of formative assessment.pdf}
}

@article{bookerCrackingProblem332019,
  title = {Cracking the Problem with 33},
  author = {Booker, Andrew R.},
  date = {2019-07-19},
  journaltitle = {Research in Number Theory},
  shortjournal = {Res. number theory},
  volume = {5},
  number = {3},
  pages = {26},
  issn = {2363-9555},
  doi = {10.1007/s40993-019-0162-1},
  url = {https://doi.org/10.1007/s40993-019-0162-1},
  urldate = {2023-09-13},
  abstract = {Inspired by the Numberphile video “The uncracked problem with 33” by Browning and Brady Haran (https://youtu.be/wymmCdLdPvM), we investigate solutions to \$\$x\^{}3+y\^{}3+z\^{}3=k\$\$for a few small values of k. We find the first known solutions for \$\$k=33\$\$and \$\$k=795\$\$.},
  langid = {english},
  keywords = {Diophantine equations,Hasse principle,Sums of three cubes},
  file = {/home/niko/Zotero/storage/NCFFI3TE/Booker - 2019 - Cracking the problem with 33.pdf}
}

@inproceedings{caizaProgrammingAssignmentsAutomatic2013,
  title = {Programming Assignments Automatic Grading: Review of Tools and Implementations},
  booktitle = {{{INTED2013 Proceedings}}},
  author = {Caiza, Julio C. and family=Alamo, given=José María, prefix=del, useprefix=true},
  date = {2013},
  pages = {5691--5700},
  publisher = {{IATED}},
  location = {{Valencia, Spain}},
  url = {https://library.iated.org/view/CAIZA2013PRO},
  urldate = {2023-09-13},
  abstract = {Automatic grading of programming assignments is an important topic in academic research. It aims at improving the level of feedback given to students and optimizing the professor’s time. Its importance is more remarkable as the amount and complexity of assignments increases. Several studies have reported the development of software tools to support this process. They usually consider particular deployment scenarios and specific requirements of the interested institution. However, the quantity and diversity of these tools makes it difficult to get a quick and accurate idea of their features.  This paper reviews an ample set of tools for automatic grading of programming assignments. The review includes a description of every tool selected and their key features. Among others, the key features analyzed include the programming language used to build the tool, the programming languages supported for grading, the criteria applied in the evaluation process, the work mode (as a plugin, as an independent tool, etc.), the logical and deployment architectures, and the communications technology used. Then, implementations and operation results are described with quantitative and qualitative indicators to understand how successful the tools were. Quantitative indicators include number of courses, students, tasks, submissions considered for tests, and acceptance percentage after tests. Qualitative indicators include motivation, support, and skills improvement. A comparative analysis among the tools is shown, and as result a set of common gaps detected is provided. The lack of normalized evaluation criteria for assignments is identified as a key gap in the reviewed tools. Thus, an evaluation metrics frame to grade programming assignments is proposed. The results indicate that many of the analyzed features highly depend on the current technology infrastructure that supports the teaching process. Therefore, they are a limiting factor in reusing the tools in new implementation cases. Another fact is the inability to support new programming languages, which is limited by tools’ updates. On metrics for evaluation process, the set of analyzed tools showed much diversity and inflexibility.  Knowing which implementation features are always specific and particular independently of the project, and which others could be common will be helpful before the implementation and operation of a tool. Considering how much flexibility could be attained in the evaluation process will be helpful to design a new tool, which will be used not only in particular cases, and to define the automation level of the evaluation process.},
  eventtitle = {7th {{International Technology}}, {{Education}} and {{Development Conference}}},
  isbn = {978-84-616-2661-8},
  langid = {english},
  file = {/home/niko/Zotero/storage/XGYXDCLP/Caiza en Alamo - 2013 - PROGRAMMING ASSIGNMENTS AUTOMATIC GRADING REVIEW .pdf}
}

@article{campGenerationCSGrowth2017,
  title = {Generation {{CS}}: The Growth of Computer Science},
  shorttitle = {Generation {{CS}}},
  author = {Camp, Tracy and Adrion, W. Richards and Bizot, Betsy and Davidson, Susan and Hall, Mary and Hambrusch, Susanne and Walker, Ellen and Zweben, Stuart},
  date = {2017-05-16},
  journaltitle = {ACM Inroads},
  shortjournal = {ACM Inroads},
  volume = {8},
  number = {2},
  pages = {44--50},
  issn = {2153-2184, 2153-2192},
  doi = {10.1145/3084362},
  url = {https://dl.acm.org/doi/10.1145/3084362},
  urldate = {2022-01-26},
  abstract = {Across North America, universities and colleges are facing a significant increase in enrollment in both undergraduate computer science (CS) courses and programs. The current enrollment surge has exceeded previous CS booms, and there is a general sense that the current growth in enrollment is substantially different from that of the mid-1980s and late 1990s. For example, since the late 1990s, the U.S. Bureau of Labor data shows that the number of jobs where computing skills are needed is on an upward slope [1], illustrating the increased reliance our society has on computing. We also know that more disciplines are becoming increasingly reliant on large amounts of data, and that handling this data effectively depends on having good computational skills. This makes computer science courses at all levels of greater interest to students from other majors.},
  langid = {english},
  file = {/home/niko/Zotero/storage/JB9WN3G8/Camp e.a. - 2017 - Generation CS the growth of computer science.pdf}
}

@inproceedings{camposMultinationalCaseStudy2012,
  title = {A Multinational Case Study on Using Diverse Feedback Types Applied to Introductory Programming Learning},
  booktitle = {2012 {{Frontiers}} in {{Education Conference Proceedings}}},
  author = {Campos, Dirson S. and Mendes, Antonio J. and Marcelino, Maria J. and Ferreira, Deller J. and Alves, Lenice M.},
  date = {2012-10},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Seattle, WA, USA}},
  doi = {10.1109/FIE.2012.6462412},
  url = {http://ieeexplore.ieee.org/document/6462412/},
  urldate = {2023-01-23},
  eventtitle = {2012 {{IEEE Frontiers}} in {{Education Conference}} ({{FIE}})},
  isbn = {978-1-4673-1352-0 978-1-4673-1353-7 978-1-4673-1351-3},
  file = {/home/niko/Zotero/storage/PU6NMPWE/Campos e.a. - 2012 - A multinational case study on using diverse feedba.pdf}
}

@article{cheangAutomatedGradingProgramming2003,
  title = {On Automated Grading of Programming Assignments in an Academic Institution},
  author = {Cheang, Brenda and Kurnia, Andy and Lim, Andrew and Oon, Wee-Chong},
  date = {2003-09},
  journaltitle = {Computers \& Education},
  shortjournal = {Computers \& Education},
  volume = {41},
  number = {2},
  pages = {121--131},
  issn = {03601315},
  doi = {10.1016/S0360-1315(03)00030-7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0360131503000307},
  urldate = {2023-01-23},
  langid = {english},
  file = {/home/niko/Zotero/storage/8RY6BU3D/Cheang e.a. - 2003 - On automated grading of programming assignments in.pdf}
}

@inproceedings{claessenQuickCheckLightweightTool2000,
  title = {{{QuickCheck}}: A Lightweight Tool for Random Testing of {{Haskell}} Programs},
  shorttitle = {{{QuickCheck}}},
  booktitle = {Proceedings of the Fifth {{ACM SIGPLAN}} International Conference on {{Functional}} Programming},
  author = {Claessen, Koen and Hughes, John},
  date = {2000-09},
  pages = {268--279},
  publisher = {{ACM}},
  doi = {10.1145/351240.351266},
  url = {https://dl.acm.org/doi/10.1145/351240.351266},
  urldate = {2023-04-12},
  eventtitle = {{{ICFP00}}: {{International Conference}} on {{Functional Programming}}},
  isbn = {978-1-58113-202-1},
  langid = {english},
  file = {/home/niko/Zotero/storage/FEANIFPL/Claessen en Hughes - 2000 - QuickCheck a lightweight tool for random testing .pdf}
}

@online{cssplicepemlworkinggroupProgrammingExerciseMarkup2021,
  title = {Programming {{Exercise Markup Language}}},
  author = {{CS SPLICE PEML Working Group}},
  date = {2021-04-02},
  url = {https://cssplice.github.io/peml/},
  urldate = {2021-10-21}
}

@article{douceAutomaticTestbasedAssessment2005,
  title = {Automatic Test-Based Assessment of Programming: {{A}} Review},
  shorttitle = {Automatic Test-Based Assessment of Programming},
  author = {Douce, Christopher and Livingstone, David and Orwell, James},
  date = {2005-09},
  journaltitle = {Journal on Educational Resources in Computing},
  shortjournal = {J. Educ. Resour. Comput.},
  volume = {5},
  number = {3},
  pages = {4},
  issn = {1531-4278, 1531-4278},
  doi = {10.1145/1163405.1163409},
  url = {https://dl.acm.org/doi/10.1145/1163405.1163409},
  urldate = {2023-09-13},
  abstract = {Systems that automatically assess student programming assignments have been designed and used for over forty years. Systems that objectively test and mark student programming work were developed simultaneously with programming assessment in the computer science curriculum. This article reviews a number of influential automatic assessment systems, including descriptions of the earliest systems, and presents some of the most recent developments. The final sections explore a number of directions automated assessment systems may take, presenting current developments alongside a number of important emerging e-learning specifications.},
  langid = {english},
  file = {/home/niko/Zotero/storage/FS2ZW3RE/Douce e.a. - 2005 - Automatic test-based assessment of programming A .pdf}
}

@article{edwardsDevelopingCommonFormat2008a,
  title = {Developing a Common Format for Sharing Programming Assignments},
  author = {Edwards, Stephen H. and Börstler, Jürgen and Cassel, Lillian N. and Hall, Mark S. and Hollingsworth, Joseph},
  date = {2008-11-30},
  journaltitle = {ACM SIGCSE Bulletin},
  shortjournal = {SIGCSE Bull.},
  volume = {40},
  number = {4},
  pages = {167--182},
  issn = {0097-8418},
  doi = {10.1145/1473195.1473240},
  url = {https://dl.acm.org/doi/10.1145/1473195.1473240},
  urldate = {2023-09-13},
  abstract = {Computer science educators spend a lot of effort designing programming assignments, and many are willing to share the results of this investment. However, sharing of programming assignments occurs primarily in an ad hoc manner through informal channels. There are no widely used mechanisms that support instructors in finding and sharing such resources. Often, the additional work required to prepare and self-publish assignment resources in a way that others can then adapt or reuse is a significant inhibitor. Also, other instructors may have to spend an inordinate amount of time and effort to reshape a potential assignment into something that can be used in their own courses. This working group report proposes a common format for packaging assignments for sharing. This format is easy for instructors to create (requiring no specialized tools), is extensible and flexible enough to handle assignments written for any programming language at any level of proficiency, supports appropriate metadata, and is easily manipulated by software tools. As more and more instructors use automated grading tools to process student submissions, it is our hope that such an interchange format can lead to a community practice of sharing resources in a way that overcomes existing barriers to such reuse.},
  langid = {english},
  file = {/home/niko/Zotero/storage/UNLRTS4F/Edwards e.a. - 2008 - Developing a common format for sharing programming.pdf}
}

@inproceedings{edwardsUsingSoftwareTesting2004,
  title = {Using Software Testing to Move Students from Trial-and-Error to Reflection-in-Action},
  booktitle = {Proceedings of the 35th {{SIGCSE}} Technical Symposium on {{Computer}} Science Education  - {{SIGCSE}} '04},
  author = {Edwards, Stephen H.},
  date = {2004},
  pages = {26},
  publisher = {{ACM Press}},
  location = {{Norfolk, Virginia, USA}},
  doi = {10.1145/971300.971312},
  url = {http://portal.acm.org/citation.cfm?doid=971300.971312},
  urldate = {2022-03-22},
  eventtitle = {The 35th {{SIGCSE}} Technical Symposium},
  isbn = {978-1-58113-798-9},
  langid = {english},
  file = {/home/niko/Zotero/storage/URCE6QW6/Edwards - 2004 - Using software testing to move students from trial.pdf}
}

@article{ellsworthQuiverSystem2004,
  title = {The {{Quiver}} System},
  author = {Ellsworth, Christopher C. and Fenwick, James B. and Kurtz, Barry L.},
  date = {2004-03},
  journaltitle = {ACM SIGCSE Bulletin},
  shortjournal = {SIGCSE Bull.},
  volume = {36},
  number = {1},
  pages = {205--209},
  issn = {0097-8418},
  doi = {10.1145/1028174.971374},
  url = {https://dl.acm.org/doi/10.1145/1028174.971374},
  urldate = {2023-09-13},
  abstract = {The Quiver (QUIz VERification) System is an Internet server for building, maintaining, and administering programming quizzes. It is similar to the online judges used for programming contests but differs in that it targets the classroom use of programming quizzes as a teaching aid and evaluation tool. It can provide very detailed feedback regarding quiz behavior so that the student can debug her program. This system is developed as part of the grant "Intra-Curriculum Software Engineering Education" funded by the National Science Foundation (DUE 0127439).},
  langid = {english},
  file = {/home/niko/Zotero/storage/W29N25AL/Ellsworth e.a. - 2004 - The Quiver system.pdf}
}

@inproceedings{enstromFiveYearsKattis2011,
  title = {Five Years with Kattis — {{Using}} an Automated Assessment System in Teaching},
  booktitle = {2011 {{Frontiers}} in {{Education Conference}} ({{FIE}})},
  author = {Enstrom, Emma and Kreitz, Gunnar and Niemela, Fredrik and Soderman, Pehr and Kann, Viggo},
  date = {2011-10},
  pages = {T3J-1-T3J-6},
  publisher = {{IEEE}},
  location = {{Rapid City, SD, USA}},
  doi = {10.1109/FIE.2011.6142931},
  url = {http://ieeexplore.ieee.org/document/6142931/},
  urldate = {2023-09-14},
  eventtitle = {2011 {{Frontiers}} in {{Education Conference}} ({{FIE}})},
  isbn = {978-1-61284-469-5 978-1-61284-468-8 978-1-61284-467-1},
  file = {/home/niko/Zotero/storage/EWFVGRVC/Enstrom e.a. - 2011 - Five years with kattis &#x2014; Using an automated.pdf}
}

@inproceedings{fonteFlexibleDynamicSystem2013,
  title = {A {{Flexible Dynamic System}} for {{Automatic Grading}} of {{Programming Exercises}}},
  booktitle = {2nd {{Symposium}} on {{Languages}}, {{Applications}} and {{Technologies}}},
  author = {Fonte, Daniela and family=Cruz, given=Daniela, prefix=da, useprefix=false and Gançarski, Alda Lopes and Henriques, Pedro Rangel},
  editor = {Leal, José Paulo and Rocha, Ricardo and Simões, Alberto},
  date = {2013},
  series = {{{OpenAccess Series}} in {{Informatics}} ({{OASIcs}})},
  volume = {29},
  pages = {129--144},
  publisher = {{Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik}},
  location = {{Dagstuhl, Germany}},
  issn = {2190-6807},
  doi = {10.4230/OASIcs.SLATE.2013.129},
  url = {http://drops.dagstuhl.de/opus/volltexte/2013/4034},
  urldate = {2023-09-14},
  isbn = {978-3-939897-52-1},
  keywords = {Automatic Grading Systems,Domain Specific Languages,DSL,Dynamic Analysis},
  file = {/home/niko/Zotero/storage/8QAT7HRY/Fonte e.a. - 2013 - A Flexible Dynamic System for Automatic Grading of.pdf}
}

@inproceedings{gulwaniFeedbackGenerationPerformance2014,
  title = {Feedback Generation for Performance Problems in Introductory Programming Assignments},
  booktitle = {Proceedings of the 22nd {{ACM SIGSOFT International Symposium}} on {{Foundations}} of {{Software Engineering}}},
  author = {Gulwani, Sumit and Radiček, Ivan and Zuleger, Florian},
  date = {2014-11-11},
  pages = {41--51},
  publisher = {{ACM}},
  location = {{Hong Kong China}},
  doi = {10.1145/2635868.2635912},
  url = {https://dl.acm.org/doi/10.1145/2635868.2635912},
  urldate = {2022-03-28},
  eventtitle = {{{SIGSOFT}}/{{FSE}}'14: 22nd {{ACM SIGSOFT Symposium}} on the {{Foundations}} of {{Software Engineering}}},
  isbn = {978-1-4503-3056-5},
  langid = {english},
  file = {/home/niko/Zotero/storage/9BHQ997M/Gulwani e.a. - 2014 - Feedback generation for performance problems in in.pdf}
}

@inproceedings{gusukumaPedalInfrastructureAutomated2020,
  title = {Pedal: {{An Infrastructure}} for {{Automated Feedback Systems}}},
  shorttitle = {Pedal},
  booktitle = {Proceedings of the 51st {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Gusukuma, Luke and Bart, Austin Cory and Kafura, Dennis},
  date = {2020-02-26},
  pages = {1061--1067},
  publisher = {{ACM}},
  location = {{Portland OR USA}},
  doi = {10.1145/3328778.3366913},
  url = {https://dl.acm.org/doi/10.1145/3328778.3366913},
  urldate = {2022-01-24},
  eventtitle = {{{SIGCSE}} '20: {{The}} 51st {{ACM Technical Symposium}} on {{Computer Science Education}}},
  isbn = {978-1-4503-6793-6},
  langid = {english},
  file = {/home/niko/Zotero/storage/ZBND4YW6/Gusukuma e.a. - 2020 - Pedal An Infrastructure for Automated Feedback Sy.pdf}
}

@article{haoUnderstandingEffectiveDesign2021,
  title = {Towards Understanding the Effective Design of Automated Formative Feedback for Programming Assignments},
  author = {Hao, Qiang and Smith IV, David H. and Ding, Lu and Ko, Amy and Ottaway, Camille and Wilson, Jack and Arakawa, Kai H. and Turcan, Alistair and Poehlman, Timothy and Greer, Tyler},
  date = {2021-01-31},
  journaltitle = {Computer Science Education},
  shortjournal = {Computer Science Education},
  pages = {1--23},
  issn = {0899-3408, 1744-5175},
  doi = {10.1080/08993408.2020.1860408},
  url = {https://www.tandfonline.com/doi/full/10.1080/08993408.2020.1860408},
  urldate = {2021-11-15},
  langid = {english},
  file = {/home/niko/Zotero/storage/69X2JBZI/Hao e.a. - 2021 - Towards understanding the effective design of auto.pdf}
}

@article{hattiePowerFeedback2007,
  title = {The {{Power}} of {{Feedback}}},
  author = {Hattie, John and Timperley, Helen},
  date = {2007-03-01},
  journaltitle = {Review of Educational Research},
  volume = {77},
  number = {1},
  pages = {81--112},
  publisher = {{American Educational Research Association}},
  issn = {0034-6543},
  doi = {10.3102/003465430298487},
  url = {https://journals.sagepub.com/doi/full/10.3102/003465430298487},
  urldate = {2023-09-13},
  abstract = {Feedback is one of the most powerful influences on learning and achievement, but this impact can be either positive or negative. Its power is frequently mentioned in articles about learning and teaching, but surprisingly few recent studies have systematically investigated its meaning. This article provides a conceptual analysis of feedback and reviews the evidence related to its impact on learning and achievement. This evidence shows that although feedback is among the major influences, the type of feedback and the way it is given can be differentially effective. A model of feedback is then proposed that identifies the particular properties and circumstances that make it effective, and some typically thorny issues are discussed, including the timing of feedback and the effects of positive and negative feedback. Finally, this analysis is used to suggest ways in which feedback can be used to enhance its effectiveness in classrooms.},
  langid = {english},
  file = {/home/niko/Zotero/storage/67PLU6YB/Hattie en Timperley - 2007 - The Power of Feedback.pdf}
}

@book{hetzelCompleteGuideSoftware1988,
  title = {The Complete Guide to Software Testing},
  author = {Hetzel, Bill},
  date = {1988-04-01},
  edition = {2},
  publisher = {{QED Information Sciences}},
  location = {{USA}},
  url = {https://dl.acm.org/doi/book/10.5555/42384},
  abstract = {In this resource, the author first develops the concepts and principles of testing. Then he presents detailed discussions of testing techniques, methodologies and management perspectives to understand the material and adapt it to your environment.},
  isbn = {978-0-89435-242-3},
  pagetotal = {280},
  file = {/home/niko/Zotero/storage/EGQII4VK/Hetzel - 1988 - The complete guide to software testing.pdf}
}

@inproceedings{hidalgo-cespedesEvaluationOnlineJudge2023,
  title = {Evaluation of an {{Online Judge}} for {{Concurrent Programming Learning}}},
  booktitle = {2023 {{XLIX Latin American Computer Conference}} ({{CLEI}})},
  author = {Hidalgo-Céspedes, Jeisson},
  date = {2023-10-16},
  pages = {1--9},
  publisher = {{IEEE}},
  location = {{La Paz, Bolivia}},
  doi = {10.1109/CLEI60451.2023.10346201},
  url = {https://ieeexplore.ieee.org/document/10346201/},
  urldate = {2024-02-13},
  eventtitle = {2023 {{XLIX Latin American Computer Conference}} ({{CLEI}})},
  isbn = {9798350318876},
  file = {/home/niko/Zotero/storage/HJXFI2XW/Hidalgo-Céspedes - 2023 - Evaluation of an Online Judge for Concurrent Progr.pdf}
}

@article{higginsCourseMarkerCBASystem2003,
  title = {The {{CourseMarker CBA System}}: {{Improvements}} over {{Ceilidh}}},
  shorttitle = {The {{CourseMarker CBA System}}},
  author = {Higgins, Colin and Hegazy, Tarek and Symeonidis, Pavlos and Tsintsifas, Athanasios},
  date = {2003-09-01},
  journaltitle = {Education and Information Technologies},
  volume = {8},
  number = {3},
  pages = {287--304},
  issn = {1573-7608},
  doi = {10.1023/A:1026364126982},
  url = {https://link.springer.com/article/10.1023/A:1026364126982},
  urldate = {2023-09-13},
  abstract = {This document reports on the results of re-designing and re-implementing the Ceilidh courseware system. It highlights the limitations identified in the thirteen years of Ceilidh's use at the University of Nottingham. It also illustrates how most of these limitations have been resolved by re-designing Ceilidh's architecture and improving various aspects of the marking and administrating processes. The new system, entitled CourseMarker, offers enhanced functionality by adding useful features that have long been needed by Ceilidh's community. The paper concludes with an evaluation of the changes and a brief report on the experience of CourseMarker's use over the last three years. Finally, recent developments and future directions are discussed.},
  langid = {english},
  keywords = {automatic assessment of programming coursework,free response Computer Based Assessment (CBA)},
  file = {/home/niko/Zotero/storage/YJIZXLUK/Higgins e.a. - 2003 - The CourseMarker CBA System Improvements over Cei.pdf}
}

@article{howdenTheoreticalEmpiricalStudies1978,
  title = {Theoretical and {{Empirical Studies}} of {{Program Testing}}},
  author = {Howden, W.E.},
  date = {1978-07},
  journaltitle = {IEEE Transactions on Software Engineering},
  shortjournal = {IIEEE Trans. Software Eng.},
  volume = {SE-4},
  number = {4},
  pages = {293--298},
  issn = {0098-5589},
  doi = {10.1109/TSE.1978.231514},
  url = {http://ieeexplore.ieee.org/document/1702537/},
  urldate = {2024-02-27},
  file = {/home/niko/Zotero/storage/CSRP8DVB/Howden - 1978 - Theoretical and Empirical Studies of Program Testi.pdf}
}

@misc{ICPCFactSheet2020,
  title = {{{ICPC Fact Sheet}}},
  date = {2020-07-20},
  url = {https://icpc.global/worldfinals/pdf/Factsheet.pdf},
  langid = {english},
  organization = {{ICPC}},
  file = {/home/niko/Zotero/storage/2P3NIWM3/2020 - ICPC Fact Sheet.pdf}
}

@inproceedings{ihantolaReviewRecentSystems2010,
  title = {Review of Recent Systems for Automatic Assessment of Programming Assignments},
  booktitle = {Proceedings of the 10th {{Koli Calling International Conference}} on {{Computing Education Research}}},
  author = {Ihantola, Petri and Ahoniemi, Tuukka and Karavirta, Ville and Seppälä, Otto},
  date = {2010-10-28},
  pages = {86--93},
  publisher = {{ACM}},
  location = {{Koli Finland}},
  doi = {10.1145/1930464.1930480},
  url = {https://dl.acm.org/doi/10.1145/1930464.1930480},
  urldate = {2023-09-13},
  eventtitle = {Koli {{Calling}} '10: 10th {{Koli Calling International Conference}} on {{Computing Education Research}}},
  isbn = {978-1-4503-0520-4},
  langid = {english},
  file = {/home/niko/Zotero/storage/YVY9MMX3/Ihantola e.a. - 2010 - Review of recent systems for automatic assessment .pdf}
}

@book{isoISOIECIEEE1998,
  title = {{{ISO}}/{{IEC}}/{{IEEE}} 9945:2009: Information},
  author = {{ISO}},
  date = {1998-09-01},
  publisher = {{pub-ISO}},
  location = {{pub-ISO:adr}},
  url = {http://webstore.ansi.org/ansidocstore/product.asp?sku=ISO%2FIEC+14882%2D1998;                  http://webstore.ansi.org/ansidocstore/product.asp?sku=ISO%2FIEC+14882%3A1998;                  http://www.iso.ch/cate/d25845.html;                  https://webstore.ansi.org/},
  isbn = {????},
  lccn = {????},
  pagetotal = {732}
}

@article{keuningSystematicLiteratureReview2018,
  title = {A {{Systematic Literature Review}} of {{Automated Feedback Generation}} for {{Programming Exercises}}},
  author = {Keuning, Hieke and Jeuring, Johan and Heeren, Bastiaan},
  date = {2018-09-28},
  journaltitle = {ACM Transactions on Computing Education},
  shortjournal = {ACM Trans. Comput. Educ.},
  volume = {19},
  number = {1},
  pages = {1--43},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3231711},
  url = {https://doi.org/10.1145/3231711},
  abstract = {Formative feedback, aimed at helping students to improve their work, is an important factor in learning. Many tools that offer programming exercises provide automated feedback on student solutions. We have performed a systematic literature review to find out what kind of feedback is provided, which techniques are used to generate the feedback, how adaptable the feedback is, and how these tools are evaluated. We have designed a labelling to classify the tools, and use Narciss’ feedback content categories to classify feedback messages. We report on the results of coding a total of 101 tools. We have found that feedback mostly focuses on identifying mistakes and less on fixing problems and taking a next step. Furthermore, teachers cannot easily adapt tools to their own needs. However, the diversity of feedback types has increased over the past decades and new techniques are being applied to generate feedback that is increasingly helpful for students.},
  keywords = {automated feedback,learning programming,programming tools,Systematic literature review},
  file = {/home/niko/Zotero/storage/WIQ3UQZ7/Keuning e.a. - 2018 - A Systematic Literature Review of Automated Feedba.pdf}
}

@thesis{khorramTestingFrameworkExecutable2022,
  type = {Theses},
  title = {A Testing Framework for Executable Domain-Specific Languages},
  author = {Khorram, Faezeh},
  date = {2022-12},
  institution = {{Ecole nationale supérieure Mines-Télécom Atlantique}},
  url = {https://theses.hal.science/tel-03977604},
  issue = {2022IMTA0332},
  keywords = {Amplification des tests,Débogage des tests,Executable Domain Specific Language (xDSL),Ingénierie dirigée par les modèles (IDM),Langage de modélisation dédié (LMD),Mesure de la qualité des tests,Model testing,Model-Driven Engineering (MDE),Test amplification,Test debugging,Test quality measurement,Tests de modèles}
}

@article{kosowskiApplicationOnlineJudge2007,
  title = {Application of an {{Online Judge}} \& {{Contester System}} in {{Academic Tuition}}},
  author = {Kosowski, Adrian and Małafiejski, Michał and Noiński, Tomasz},
  date = {2007},
  journaltitle = {Lecture Notes in Computer Science},
  pages = {343--354},
  doi = {10.1007/978-3-540-78139-4_31},
  url = {http://dx.doi.org/10.1007/978-3-540-78139-4_31},
  file = {/home/niko/Zotero/storage/34X7MDMQ/Kosowski e.a. - 2007 - Application of an Online Judge & Contester System .pdf}
}

@article{leOperationalizingContinuumWellDefined2013,
  title = {Operationalizing the {{Continuum}} between {{Well-Defined}} and {{Ill-Defined Problems}} for {{Educational Technology}}},
  author = {Le, Nguyen-Thinh and Loll, Frank and Pinkwart, Niels},
  date = {2013-07},
  journaltitle = {IEEE Trans. Learn. Technol.},
  volume = {6},
  number = {3},
  pages = {258--270},
  issn = {1939-1382},
  doi = {10.1109/TLT.2013.16},
  url = {http://dx.doi.org/10.1109/TLT.2013.16},
  abstract = {One of the most effective ways to learn is through problem solving. Recently, researchers have started to develop educational systems which are intended to support solving ill-defined problems. Most researchers agree that there is no sharp distinction but rather a continuum between well-definedness and ill-definedness. However, positioning a problem within this continuum is not always easy, which may lead to difficulties in choosing an appropriate educational technology approach. We propose a classification of the degree of ill-definedness of educational problems based on the existence of solution strategies, the implementation variability for each solution strategy, and the verifiability of solutions. The classification divides educational problems into five classes: 1) one single solution, 2) one solution strategy with different implementation variants, 3) a known number of typical solution strategies, 4) a great variety of solution strategies beyond the anticipation of a teacher where solution correctness can be verified automatically, and 5) problems whose solution correctness cannot be verified automatically. The benefits of this problem classification are twofold. First, it helps researchers choose or develop an appropriate modeling technique for educational systems. Second, it offers the learning technology community a communication means to talk about sorts of more or less ill-defined educational problems more precisely.},
  keywords = {adaptive educational technology,Artificial intelligence,Cities and towns,classification,CSCL,Educational technology,Ill-defined domains,ill-defined problems,Investment,ITS,Problem-solving,Programming profession},
  file = {/home/niko/Zotero/storage/DWAZVUDU/Le e.a. - 2013 - Operationalizing the Continuum between Well-Define.pdf}
}

@article{luckSecureOnlineSubmission1999,
  title = {A Secure On-Line Submission System},
  author = {Luck, Michael and Joy, Mike},
  date = {1999-07-01},
  journaltitle = {Software: Practice and Experience},
  volume = {29},
  number = {8},
  pages = {721--740},
  issn = {1097-024X},
  doi = {10.1002/(SICI)1097-024X(19990710)29:8<721::AID-SPE257>3.0.CO;2-0},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-024X%2819990710%2929%3A8%3C721%3A%3AAID-SPE257%3E3.0.CO%3B2-0},
  urldate = {2023-09-13},
  abstract = {As student numbers on computer science courses continue to increase, the corresponding demands placed on teaching staff in terms of assessment grow ever stronger. In particular, the submission and assessment of practical work on large programming courses can present very significant problems. In response to this, we have developed a networked suite of software utilities that allow on-line submission, testing and marking of coursework. It has been developed and used over the course of five years, and has evolved into a mature tool that has greatly reduced the administrative time spent managing the processes of submission and assessment. In this paper, we describe the software and its implementation, and discuss the issues involved in its construction. Copyright © 1999 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {assessment,course management,coursework,security,submission,testing},
  file = {/home/niko/Zotero/storage/CI7CXFHU/Luck en Joy - 1999 - A secure on-line submission system.pdf}
}

@inproceedings{luxton-reillyIntroductoryProgrammingSystematic2018,
  title = {Introductory Programming: A Systematic Literature Review},
  shorttitle = {Introductory Programming},
  booktitle = {Proceedings {{Companion}} of the 23rd {{Annual ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Luxton-Reilly, Andrew and {Simon} and Albluwi, Ibrahim and Becker, Brett A. and Giannakos, Michail and Kumar, Amruth N. and Ott, Linda and Paterson, James and Scott, Michael James and Sheard, Judy and Szabo, Claudia},
  date = {2018-07-02},
  pages = {55--106},
  publisher = {{ACM}},
  location = {{Larnaca Cyprus}},
  doi = {10.1145/3293881.3295779},
  url = {https://dl.acm.org/doi/10.1145/3293881.3295779},
  urldate = {2022-03-22},
  eventtitle = {{{ITiCSE}} '18: 23rd {{Annual ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  isbn = {978-1-4503-6223-8},
  langid = {english},
  file = {/home/niko/Zotero/storage/UJBPQN7P/Luxton-Reilly e.a. - 2018 - Introductory programming a systematic literature .pdf}
}

@article{maertensDolosLanguageagnosticPlagiarism2022,
  title = {Dolos: {{Language-agnostic}} Plagiarism Detection in Source Code},
  shorttitle = {Dolos},
  author = {Maertens, Rien and Van Petegem, Charlotte and Strijbol, Niko and Baeyens, Toon and Jacobs, Arne Carla and Dawyndt, Peter and Mesuere, Bart},
  date = {2022},
  journaltitle = {Journal of Computer Assisted Learning},
  volume = {38},
  number = {4},
  pages = {1046--1061},
  issn = {1365-2729},
  doi = {10.1111/jcal.12662},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jcal.12662},
  urldate = {2023-09-13},
  abstract = {Background Learning to code is increasingly embedded in secondary and higher education curricula, where solving programming exercises plays an important role in the learning process and in formative and summative assessment. Unfortunately, students admit that copying code from each other is a common practice and teachers indicate they rarely use plagiarism detection tools. Objectives We want to lower the barrier for teachers to detect plagiarism by introducing a new source code plagiarism detection tool (Dolos) that is powered by state-of-the art similarity detection algorithms, offers interactive visualizations, and uses generic parser models to support a broad range of programming languages. Methods Dolos is compared with state-of-the-art plagiarism detection tools in a benchmark based on a standardized dataset. We describe our experience with integrating Dolos in a programming course with a strong focus on online learning and the impact of transitioning to remote assessment during the COVID-19 pandemic. Results and Conclusions Dolos outperforms other plagiarism detection tools in detecting potential cases of plagiarism and is a valuable tool for preventing and detecting plagiarism in online learning environments. It is available under the permissive MIT open-source license at https://dolos.ugent.be. Implications Dolos lowers barriers for teachers to discover, prove and prevent plagiarism in programming courses. This helps to enable a shift towards open and online learning and assessment environments, and opens up interesting avenues for more effective learning and better assessment.},
  langid = {english},
  keywords = {academic dishonesty,cheating,data visualization,online learning,plagiarism,programming language,remote assessment,source code},
  file = {/home/niko/Zotero/storage/YUHC9WB4/Maertens e.a. - 2022 - Dolos Language-agnostic plagiarism detection in s.pdf}
}

@article{messerAutomatedGradingFeedback2024,
  title = {Automated {{Grading}} and {{Feedback Tools}} for {{Programming Education}}: {{A Systematic Review}}},
  shorttitle = {Automated {{Grading}} and {{Feedback Tools}} for {{Programming Education}}},
  author = {Messer, Marcus and Brown, Neil C. C. and Kölling, Michael and Shi, Miaojing},
  date = {2024-03-31},
  journaltitle = {ACM Transactions on Computing Education},
  shortjournal = {ACM Trans. Comput. Educ.},
  volume = {24},
  number = {1},
  pages = {1--43},
  issn = {1946-6226},
  doi = {10.1145/3636515},
  url = {https://dl.acm.org/doi/10.1145/3636515},
  urldate = {2024-02-19},
  abstract = {We conducted a systematic literature review on automated grading and feedback tools for programming education. We analysed 121 research papers from 2017 to 2021 inclusive and categorised them based on skills assessed, approach, language paradigm, degree of automation, and evaluation techniques. Most papers assess the correctness of assignments in object-oriented languages. Typically, these tools use a dynamic technique, primarily unit testing, to provide grades and feedback to the students or static analysis techniques to compare a submission with a reference solution or with a set of correct student submissions. However, these techniques’ feedback is often limited to whether the unit tests have passed or failed, the expected and actual output, or how they differ from the reference solution. Furthermore, few tools assess the maintainability, readability, or documentation of the source code, with most using static analysis techniques, such as code quality metrics, in conjunction with grading correctness. Additionally, we found that most tools offered fully automated assessment to allow for near-instantaneous feedback and multiple resubmissions, which can increase student satisfaction and provide them with more opportunities to succeed. In terms of techniques used to evaluate the tools’ performance, most papers primarily use student surveys or compare the automatic assessment tools to grades or feedback provided by human graders. However, because the evaluation dataset is frequently unavailable, it is more difficult to reproduce results and compare tools to a collection of common assignments.},
  langid = {english},
  file = {/home/niko/Zotero/storage/M73JUWKZ/Messer e.a. - 2024 - Automated Grading and Feedback Tools for Programmi.pdf}
}

@book{meszarosXUnitTestPatterns2007,
  title = {{{xUnit Test Patterns}}: {{Refactoring Test Code}}},
  author = {Meszaros, Gerard},
  date = {2007-05-21},
  publisher = {{Pearson Education}},
  url = {https://play.google.com/store/books/details?id=-izOiCEIABQC},
  abstract = {Automated testing is a cornerstone of agile development. An effective testing strategy will deliver new functionality more aggressively, accelerate user feedback, and improve quality. However, for many developers, creating effective automated tests is a unique and unfamiliar challenge. xUnit Test Patterns is the definitive guide to writing automated tests using xUnit, the most popular unit testing framework in use today. Agile coach and test automation expert Gerard Meszaros describes 68 proven patterns for making tests easier to write, understand, and maintain. He then shows you how to make them more robust and repeatable--and far more cost-effective. Loaded with information, this book feels like three books in one. The first part is a detailed tutorial on test automation that covers everything from test strategy to in-depth test coding. The second part, a catalog of 18 frequently encountered "test smells," provides trouble-shooting guidelines to help you determine the root cause of problems and the most applicable patterns. The third part contains detailed descriptions of each pattern, including refactoring instructions illustrated by extensive code samples in multiple programming languages.},
  isbn = {978-0-13-279746-7},
  pagetotal = {944}
}

@inproceedings{mishraProgrammingExerciseMarkup2023,
  title = {The {{Programming Exercise Markup Language}}: {{Towards Reducing}} the {{Effort Needed}} to {{Use Automated Grading Tools}}},
  shorttitle = {The {{Programming Exercise Markup Language}}},
  booktitle = {Proceedings of the 54th {{ACM Technical Symposium}} on {{Computer Science Education V}}. 1},
  author = {Mishra, Divyansh S. and Edwards, Stephen H.},
  date = {2023-03-02},
  pages = {395--401},
  publisher = {{ACM}},
  location = {{Toronto ON Canada}},
  doi = {10.1145/3545945.3569734},
  url = {https://dl.acm.org/doi/10.1145/3545945.3569734},
  urldate = {2023-09-13},
  eventtitle = {{{SIGCSE}} 2023: {{The}} 54th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  isbn = {978-1-4503-9431-4},
  langid = {english},
  file = {/home/niko/Zotero/storage/9AIV6N65/Mishra en Edwards - 2023 - The Programming Exercise Markup Language Towards .pdf}
}

@article{murphyAnalysisIntroductoryProgramming2017,
  title = {An {{Analysis}} of {{Introductory Programming Courses}} at {{UK Universities}}},
  author = {Murphy, Ellen and Crick, Tom and Davenport, James H.},
  date = {2017-04-01},
  journaltitle = {The Art, Science, and Engineering of Programming},
  volume = {1},
  number = {2},
  pages = {18:1-18:23},
  issn = {2473-7321},
  doi = {10.22152/programming-journal.org/2017/1/18},
  url = {https://programming-journal.org/2017/1/18/},
  urldate = {2023-09-13},
  abstract = {Context: In the context of exploring the art, science and engineering of programming, the question of which programming languages should ...},
  langid = {english},
  file = {/home/niko/Zotero/storage/9AZZBR2R/Murphy e.a. - 2017 - An Analysis of Introductory Programming Courses at.pdf}
}

@inproceedings{nayakAutomatedAssessmentTools2022,
  title = {Automated {{Assessment Tools}} for Grading of Programming {{Assignments}}: {{A}} Review},
  shorttitle = {Automated {{Assessment Tools}} for Grading of Programming {{Assignments}}},
  booktitle = {2022 {{International Conference}} on {{Computer Communication}} and {{Informatics}} ({{ICCCI}})},
  author = {Nayak, Sidhidatri and Agarwal, Reshu and Khatri, Sunil Kumar},
  date = {2022-01-25},
  pages = {1--4},
  publisher = {{IEEE}},
  location = {{Coimbatore, India}},
  doi = {10.1109/ICCCI54379.2022.9740769},
  url = {https://ieeexplore.ieee.org/document/9740769/},
  urldate = {2023-09-13},
  eventtitle = {2022 {{International Conference}} on {{Computer Communication}} and {{Informatics}} ({{ICCCI}})},
  isbn = {978-1-66548-035-2},
  file = {/home/niko/Zotero/storage/GRPPNQHT/Nayak e.a. - 2022 - Automated Assessment Tools for grading of programm.pdf}
}

@article{orrellFeedbackLearningAchievement2006,
  title = {Feedback on Learning Achievement: Rhetoric and Reality},
  shorttitle = {Feedback on Learning Achievement},
  author = {Orrell, Janice},
  date = {2006-10},
  journaltitle = {Teaching in Higher Education},
  shortjournal = {Teaching in Higher Education},
  volume = {11},
  number = {4},
  pages = {441--456},
  issn = {1356-2517, 1470-1294},
  doi = {10.1080/13562510600874235},
  url = {http://www.tandfonline.com/doi/abs/10.1080/13562510600874235},
  urldate = {2022-02-28},
  langid = {english},
  file = {/home/niko/Zotero/storage/NLZKMRQN/Orrell - 2006 - Feedback on learning achievement rhetoric and rea.pdf}
}

@incollection{ostrandBlackBoxTesting2002,
  title = {Black-{{Box Testing}}},
  booktitle = {Encyclopedia of {{Software Engineering}}},
  author = {Ostrand, Thomas},
  editor = {Marciniak, John J.},
  date = {2002-01-15},
  pages = {sof022},
  publisher = {{John Wiley \& Sons, Inc.}},
  location = {{Hoboken, NJ, USA}},
  doi = {10.1002/0471028959.sof022},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/0471028959.sof022},
  urldate = {2023-02-22},
  isbn = {978-0-471-02895-6},
  langid = {english}
}

@incollection{ostrandWhiteBoxTesting2002,
  title = {White-{{Box Testing}}},
  booktitle = {Encyclopedia of {{Software Engineering}}},
  author = {Ostrand, Thomas},
  editor = {Marciniak, John J.},
  date = {2002-01-15},
  pages = {sof378},
  publisher = {{John Wiley \& Sons, Inc.}},
  location = {{Hoboken, NJ, USA}},
  doi = {10.1002/0471028959.sof378},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/0471028959.sof378},
  urldate = {2023-02-22},
  isbn = {978-0-471-02895-6},
  langid = {english}
}

@inproceedings{paivaAnotherProgrammingExercises2020,
  title = {Yet {{Another Programming Exercises Interoperability Language}} ({{Short Paper}})},
  author = {Paiva, José Carlos and Queirós, Ricardo and Leal, José Paulo and Swacha, Jakub},
  date = {2020},
  url = {https://drops.dagstuhl.de/opus/volltexte/2020/13027/},
  eventtitle = {9th {{Symposium}} on {{Languages}}, {{Applications}} and {{Technologies}} ({{SLATE}} 2020)},
  file = {/home/niko/Zotero/storage/RST3RMBR/Paiva e.a. - 2020 - Yet Another Programming Exercises Interoperability.pdf}
}

@article{paivaAutomatedAssessmentComputer2022a,
  title = {Automated {{Assessment}} in {{Computer Science Education}}: {{A State-of-the-Art Review}}},
  shorttitle = {Automated {{Assessment}} in {{Computer Science Education}}},
  author = {Paiva, José Carlos and Leal, José Paulo and Figueira, Álvaro},
  date = {2022-09-30},
  journaltitle = {ACM Transactions on Computing Education},
  shortjournal = {ACM Trans. Comput. Educ.},
  volume = {22},
  number = {3},
  pages = {1--40},
  issn = {1946-6226, 1946-6226},
  doi = {10.1145/3513140},
  url = {https://dl.acm.org/doi/10.1145/3513140},
  urldate = {2023-09-13},
  abstract = {Practical programming competencies are critical to the success in computer science (CS) education and go-to-market of fresh graduates. Acquiring the required level of skills is a long journey of discovery, trial and error, and optimization seeking through a broad range of programming activities that learners must perform themselves. It is not reasonable to consider that teachers could evaluate all attempts that the average learner should develop multiplied by the number of students enrolled in a course, much less in a timely, deep, and fair fashion. Unsurprisingly, exploring the formal structure of programs to automate the assessment of certain features has long been a hot topic among CS education practitioners. Assessing a program is considerably more complex than asserting its functional correctness, as the proliferation of tools and techniques in the literature over the past decades indicates. Program efficiency, behavior, and readability, among many other features, assessed either statically or dynamically, are now also relevant for automatic evaluation. The outcome of an evaluation evolved from the primordial Boolean values to information about errors and tips on how to advance, possibly taking into account similar solutions. This work surveys the state of the art in the automated assessment of CS assignments, focusing on the supported types of exercises, security measures adopted, testing techniques used, type of feedback produced, and the information they offer the teacher to understand and optimize learning. A new era of automated assessment, capitalizing on static analysis techniques and containerization, has been identified. Furthermore, this review presents several other findings from the conducted review, discusses the current challenges of the field, and proposes some future research directions.},
  langid = {english},
  file = {/home/niko/Zotero/storage/QAVAJX47/Paiva e.a. - 2022 - Automated Assessment in Computer Science Education.pdf}
}

@unpublished{panSoftwareReliability1999,
  title = {Software Reliability},
  author = {Pan, Jiantao},
  date = {1999},
  url = {https://users.ece.cmu.edu/~koopman/des_s99/sw_reliability/presentation.pdf},
  file = {/home/niko/Zotero/storage/RR3AESMY/Pan - 1999 - Software reliability.pdf}
}

@misc{panSoftwareTesting1999,
  title = {Software {{Testing}}},
  author = {Pan, Jiantao},
  date = {1999},
  url = {https://users.ece.cmu.edu/~koopman/des_s99/sw_testing/},
  abstract = {Software testing is any activity aimed at evaluating an attribute or capability of a program or system and determining that it meets its required results. [Hetzel88] Although crucial to software quality and widely deployed by programmers and testers, software testing still remains an art, due to limited understanding of the principles of software. The difficulty in software testing stems from the complexity of software: we can not completely test a program with moderate complexity. Testing is more than just debugging. The purpose of testing can be quality assurance, verification and validation, or reliability estimation. Testing can be used as a generic metric as well. Correctness testing and reliability testing are two major areas of testing. Software testing is a trade-off between budget, time and quality.},
  langid = {english},
  organization = {{Dependable Embedded Systems}},
  file = {/home/niko/Zotero/storage/FCJ332S5/httpwww.ece.cmu.edu~koopmandes_s99sw_testing.pdf}
}

@inproceedings{papanceaOpenPlatformManaging2013,
  title = {An Open Platform for Managing Short Programming Exercises},
  booktitle = {{{ICER}} '13},
  author = {Papancea, Andrei and Spacco, Jaime and Hovemeyer, David},
  date = {2013-08-12},
  pages = {47--52},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/2493394.2493401},
  url = {https://doi.org/10.1145/2493394.2493401},
  urldate = {2021-08-13},
  abstract = {In this paper, we describe CloudCoder, an open platform for creating, assigning, and sharing short programming exercises for a variety of languages (currently C/C++, Java, Python and Ruby). Like other similar systems, CloudCoder is web-based, letting students write code directly in a web browser, click the "submit" button, and receive immediate feedback. Unlike other systems, which tend to be closed, or commercial, or both, CloudCoder is a completely open platform. The code for the system is open-source, and exercises written for CloudCoder may be shared to a central repository under permissive licenses such as Creative Commons BY-SA. Finally, CloudCoder collects detailed data that faculty can use for educational research. We also report on successful pilot studies of CloudCoder at several institutions, and outline research questions we hope to address in future work.},
  eventtitle = {Proceedings of the Ninth Annual International {{ACM}} Conference on {{International}} Computing Education Research},
  keywords = {cs1,data collection,novice programmers,student behavior},
  file = {/home/niko/Zotero/storage/7QIGZ4Z4/Papancea e.a. - 2013 - An open platform for managing short programming ex.pdf}
}

@article{petitJutgeOrgCharacteristics2018,
  title = {Jutge.Org: {{Characteristics}} and {{Experiences}}},
  author = {Petit, Jordi and Roura, Salvador and Carmona, Josep and Cortadella, Jordi and Duch, Jordi and Gimnez, Omer and Mani, Anaga and Mas, Jan and Rodrguez-Carbonell, Enric and Rubio, Enric and Pedro, Enric de San and Venkataramani, Divya},
  date = {2018-07},
  journaltitle = {IEEE Trans. Learn. Technol.},
  volume = {11},
  number = {3},
  pages = {321--333},
  issn = {1939-1382},
  doi = {10.1109/TLT.2017.2723389},
  url = {http://dx.doi.org/10.1109/TLT.2017.2723389},
  abstract = {Jutge.org is an open educational online programming judge designed for students and instructors, featuring a repository of problems that is well organized by courses, topics, and difficulty. Internally, Jutge.org uses a secure and efficient architecture and integrates modern verification techniques, formal methods, static code analysis, and data mining. Jutge.org has exhaustively been used during the last decade at the Universitat Politècnica de Catalunya to strengthen the learning-by-doing approach in several courses. This paper presents the main characteristics of Jutge.org and shows its use and impact on a wide range of courses covering basic programming, data structures, algorithms, artificial intelligence, functional programming, and circuit design.},
  keywords = {Algorithm design and analysis,computer programming,Computers,Data mining,Education,educational data mining,educational games,Electronic mail,Innovative online learning systems,learning analytics,online programming judges,Programming profession},
  file = {/home/niko/Zotero/storage/C7JTPVW8/Petit e.a. - 2018 - Jutge.org Characteristics and Experiences.pdf}
}

@inproceedings{pevelerComparingJailedSandboxes2019,
  title = {Comparing {{Jailed Sandboxes}} vs {{Containers Within}} an {{Autograding System}}},
  booktitle = {Proceedings of the 50th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Peveler, Matthew and Maicus, Evan and Cutler, Barbara},
  date = {2019-02-22},
  pages = {139--145},
  publisher = {{ACM}},
  location = {{Minneapolis MN USA}},
  doi = {10.1145/3287324.3287507},
  url = {https://dl.acm.org/doi/10.1145/3287324.3287507},
  urldate = {2023-09-14},
  eventtitle = {{{SIGCSE}} '19: {{The}} 50th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  isbn = {978-1-4503-5890-3},
  langid = {english},
  file = {/home/niko/Zotero/storage/R3RQCELJ/Peveler e.a. - 2019 - Comparing Jailed Sandboxes vs Containers Within an.pdf}
}

@inproceedings{pieterseAutomatedAssessmentProgramming2013,
  title = {Automated {{Assessment}} of {{Programming Assignments}}},
  booktitle = {Proceedings of the 3rd {{Computer Science Education Research Conference}} on {{Computer Science Education Research}}},
  author = {Pieterse, Vreda},
  date = {2013-04-04},
  pages = {45--56},
  publisher = {{Open Universiteit Heerlen}},
  location = {{Arnhem, Nederland}},
  url = {https://dl.acm.org/doi/10.5555/2541917.2541921},
  urldate = {2023-09-13},
  abstract = {This is a position paper in which I argue that massive open online programming courses can benefit by the application of automated assessment of programming assignments. I gathered success factors and identified concerns related to automatic assessment through the analysis of experiences other researchers have reported when designing and using automated assessment of programming assignments and interpret their potential applicability in the context of massive open online courses (MOOCs). In this paper I explain the design of our own assessment software and discuss our experience of using it in relation to the above-mentioned factors and concerns. My reflection on this experience can inform MOOC designers when having to make decisions regarding the use of automatic assessment of programming assignments.},
  eventtitle = {{{CSERC}} '13},
  keywords = {Assessment software,automatic assessment,MOOC},
  file = {/home/niko/Zotero/storage/GDG623TW/Pieterse - 2013 - Automated Assessment of Programming Assignments.pdf}
}

@inproceedings{pirttinenCrowdsourcingProgrammingAssignments2018,
  title = {Crowdsourcing Programming Assignments with {{CrowdSorcerer}}},
  booktitle = {Proceedings of the 23rd {{Annual ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Pirttinen, Nea and Kangas, Vilma and Nikkarinen, Irene and Nygren, Henrik and Leinonen, Juho and Hellas, Arto},
  date = {2018-07-02},
  pages = {326--331},
  publisher = {{ACM}},
  location = {{Larnaca Cyprus}},
  doi = {10.1145/3197091.3197117},
  url = {https://dl.acm.org/doi/10.1145/3197091.3197117},
  urldate = {2021-11-18},
  eventtitle = {{{ITiCSE}} '18: 23rd {{Annual ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  isbn = {978-1-4503-5707-4},
  langid = {english},
  file = {/home/niko/Zotero/storage/YDCT83ZD/Pirttinen e.a. - 2018 - Crowdsourcing programming assignments with CrowdSo.pdf}
}

@misc{ProblemPackageFormat2022,
  title = {Problem {{Package Format Specification}}},
  date = {2022-03-07},
  url = {https://www.kattis.com/problem-package-format/},
  urldate = {2022-07-26},
  langid = {english},
  organization = {{Kattis}}
}

@article{queirosBabeLOExtensibleConverter2013,
  title = {{{BabeLO}}—{{An Extensible Converter}} of {{Programming Exercises Formats}}},
  author = {Queirós, Ricardo and Leal, Jose Paulo},
  date = {2013-01},
  journaltitle = {IEEE Trans. Learn. Technol.},
  volume = {6},
  number = {1},
  pages = {38--45},
  issn = {1939-1382},
  doi = {10.1109/TLT.2012.21},
  url = {http://dx.doi.org/10.1109/TLT.2012.21},
  abstract = {In the last two decades, there was a proliferation of programming exercise formats that hinders interoperability in automatic assessment. In the lack of a widely accepted standard, a pragmatic solution is to convert content among the existing formats. BabeLO is a programming exercise converter providing services to a network of heterogeneous e-learning systems such as contest management systems, programming exercise authoring tools, evaluation engines and repositories of learning objects. Its main feature is the use of a pivotal format to achieve greater extensibility. This approach simplifies the extension to other formats, just requiring the conversion to and from the pivotal format. This paper starts with an analysis of programming exercise formats representative of the existing diversity. This analysis sets the context for the proposed approach to exercise conversion and to the description of the pivotal data format. The abstract service definition is the basis for the design of BabeLO, its components and web service interface. This paper includes a report on the use of BabeLO in two concrete scenarios: to relocate exercises to a different repository, and to use an evaluation engine in a network of heterogeneous systems.},
  keywords = {Computer aided instruction,Distance learning,e-learning,Electronic learning,Interoperability,Mobile communication,Programming,programming exercise formats,REST,Web and internet services,web services},
  file = {/home/niko/Zotero/storage/LXDJUCM5/Queirós en Leal - 2013 - BabeLO—An Extensible Converter of Programming Exer.pdf}
}

@inproceedings{queirosPexilProgrammingExercises2011,
  title = {Pexil: {{Programming}} Exercises Interoperability Language},
  author = {Queirós, Ricardo and Leal, José Paulo},
  date = {2011},
  pages = {37--48},
  url = {https://recipp.ipp.pt/handle/10400.22/4748},
  eventtitle = {Conferência {{Nacional XATA}}: {{XML}}, Aplicações e Tecnologias Associadas, 9.},
  file = {/home/niko/Zotero/storage/6PWBLJFX/Queirós en Leal - 2011 - Pexil Programming exercises interoperability lang.pdf}
}

@inproceedings{queirosProgrammingExercisesEvaluation2012,
  title = {Programming {{Exercises Evaluation Systems-An Interoperability Survey}}},
  author = {Queirós, Ricardo and Leal, José Paulo and Gupta, S and Dubey, S},
  date = {2012},
  pages = {83--90},
  url = {https://pdfs.semanticscholar.org/4a3d/2e146a24bffc75dce649b33412ca95bd700d.pdf},
  eventtitle = {{{CSEDU}} (1)},
  file = {/home/niko/Zotero/storage/4UARFNA2/Queirós e.a. - 2012 - Programming Exercises Evaluation Systems-An Intero.pdf}
}

@article{revillaCompetitiveLearningInformatics2008,
  title = {Competitive Learning in Informatics: {{The UVa}} Online Judge Experience},
  author = {Revilla, Miguel A and Manzoor, Shahriar and Liu, Rujia},
  date = {2008},
  journaltitle = {Olympiads in Informatics},
  volume = {2},
  number = {10},
  pages = {131--148},
  publisher = {{Institute of Mathematics and Informatics}},
  url = {https://ioinformatics.org/journals/olympiads_in_informatics/pdf/INFOL035.pdf},
  file = {/home/niko/Zotero/storage/J3T3BP6X/Revilla e.a. - 2008 - Competitive learning in informatics The UVa onlin.pdf}
}

@inproceedings{romliAutomaticProgrammingAssessment2010,
  title = {Automatic Programming Assessment and Test Data Generation a Review on Its Approaches},
  booktitle = {2010 {{International Symposium}} on {{Information Technology}}},
  author = {Romli, Rohaida and Sulaiman, Shahida and Zamli, Kamal Zuhairi},
  date = {2010-06},
  pages = {1186--1192},
  publisher = {{IEEE}},
  location = {{Kuala Lumpur, Malaysia}},
  doi = {10.1109/ITSIM.2010.5561488},
  url = {http://ieeexplore.ieee.org/document/5561488/},
  urldate = {2023-09-13},
  eventtitle = {2010 {{International Symposium}} on {{Information Technology}} ({{ITSim}} 2010)},
  isbn = {978-1-4244-6715-0},
  file = {/home/niko/Zotero/storage/CXZIIIUC/Romli e.a. - 2010 - Automatic programming assessment and test data gen.pdf}
}

@software{ronacherJinja,
  title = {Jinja},
  author = {Ronacher, Armin and Lord, David},
  url = {https://jinja.palletsprojects.com/en/3.1.x/},
  organization = {{Pallets Projects}}
}

@article{runesonSurveyUnitTesting2006,
  title = {A Survey of Unit Testing Practices},
  author = {Runeson, Per},
  date = {2006-07},
  journaltitle = {IEEE Software},
  shortjournal = {IEEE Softw.},
  volume = {23},
  number = {4},
  pages = {22--29},
  issn = {0740-7459},
  doi = {10.1109/MS.2006.91},
  url = {http://ieeexplore.ieee.org/document/1657935/},
  urldate = {2023-09-13},
  file = {/home/niko/Zotero/storage/GJHX6T3J/Runeson - 2006 - A survey of unit testing practices.pdf}
}

@inproceedings{sarsaSpeedingAutomatedAssessment2022,
  title = {Speeding {{Up Automated Assessment}} of {{Programming Exercises}}},
  booktitle = {The {{United Kingdom}} and {{Ireland Computing Education Research}} ({{UKICER}}) {{Conference}}},
  author = {Sarsa, Sami and Leinonen, Juho and Koutcheme, Charles and Hellas, Arto},
  date = {2022-09},
  pages = {1--7},
  publisher = {{ACM}},
  location = {{Dublin Ireland}},
  doi = {10.1145/3555009.3555013},
  url = {https://dl.acm.org/doi/10.1145/3555009.3555013},
  urldate = {2023-09-14},
  eventtitle = {{{UKICER2022}}: {{The United Kingdom}} and {{Ireland Computing Education Research Conference}}},
  isbn = {978-1-4503-9742-1},
  langid = {english},
  file = {/home/niko/Zotero/storage/WSK8HXPP/Sarsa e.a. - 2022 - Speeding Up Automated Assessment of Programming Ex.pdf}
}

@inproceedings{saxExaminingEnrollmentGrowth2017,
  title = {Examining the {{Enrollment Growth}}: {{Non-CS Majors}} in {{CS1 Courses}}},
  shorttitle = {Examining the {{Enrollment Growth}}},
  booktitle = {Proceedings of the 2017 {{ACM SIGCSE Technical Symposium}} on {{Computer Science Education}}},
  author = {Sax, Linda J. and Lehman, Kathleen J. and Zavala, Christina},
  date = {2017-03-08},
  pages = {513--518},
  publisher = {{ACM}},
  location = {{Seattle Washington USA}},
  doi = {10.1145/3017680.3017781},
  url = {https://dl.acm.org/doi/10.1145/3017680.3017781},
  urldate = {2022-01-26},
  eventtitle = {{{SIGCSE}} '17: {{The}} 48th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  isbn = {978-1-4503-4698-6},
  langid = {english},
  file = {/home/niko/Zotero/storage/RQDSVEAX/Sax e.a. - 2017 - Examining the Enrollment Growth Non-CS Majors in .pdf}
}

@standard{schlueterTAP14TestAnything2022,
  title = {{{TAP14}} - {{The Test Anything Protocol}} V14},
  author = {Schlueter, Isaac Z. and Layman, Matt and Timmermans, Leon and Kinoshita, Bruno P. and Granum, Chad},
  date = {2022},
  url = {https://testanything.org/tap-version-14-specification.html},
  version = {v14}
}

@article{shuteFocusFormativeFeedback2008,
  title = {Focus on {{Formative Feedback}}},
  author = {Shute, Valerie J},
  date = {2008-03-01},
  journaltitle = {Rev. Educ. Res.},
  volume = {78},
  number = {1},
  pages = {153--189},
  publisher = {{American Educational Research Association}},
  issn = {0034-6543},
  doi = {10.3102/0034654307313795},
  url = {https://doi.org/10.3102/0034654307313795},
  abstract = {This article reviews the corpus of research on feedback, with a focus on formative feedback?defined as information communicated to the learner that is intended to modify his or her thinking or behavior to improve learning. According to researchers, formative feedback should be nonevaluative, supportive, timely, and specific. Formative feedback is usually presented as information to a learner in response to some action on the learner?s part. It comes in a variety of types (e.g., verification of response accuracy, explanation of the correct answer, hints, worked examples) and can be administered at various times during the learning process (e.g., immediately following an answer, after some time has elapsed). Finally, several variables have been shown to interact with formative feedback?s success at promoting learning (e.g., individual characteristics of the learner and aspects of the task). All of these issues are discussed. This review concludes with guidelines for generating formative feedback.},
  file = {/home/niko/Zotero/storage/HPHECAAL/Shute - 2008 - Focus on Formative Feedback.pdf}
}

@inproceedings{simoesNatureProgrammingExercises2020,
  title = {On the Nature of Programming Exercises},
  author = {Simões, Alberto and Queirós, Ricardo},
  date = {2020},
  publisher = {{Schloss Dagstuhl - Leibniz-Zentrum für Informatik}},
  doi = {10.4230/OASICS.ICPEC.2020.24},
  url = {https://drops.dagstuhl.de/opus/volltexte/2020/12311/},
  abstract = {There are countless reasons cited in scientific studies to explain the difficulties in programming learning. The reasons range from the subject’s complexity, the ineffective teaching and study methods, to psychological aspects such as demotivation. Still, learning programming often boils down to practice on exercise solving. Hence, it is essential to understand that the nature of a programming exercise is an important factor for the success and consistent learning. This paper explores different approaches on the creation of a programming exercise, starting with realizing how it is currently formalized, presented and evaluated. From there, authors suggest variations that seek to broaden the way an exercise is solved and, with this diversity, increase student engagement and learning outcome. The several types of exercises presented can use gamification techniques fostering student motivation. To contextualize the student with his peers, we finish presenting metrics that can be obtained by existing automatic assessment tools.},
  file = {/home/niko/Zotero/storage/E558JEJN/Simões en Queirós - 2020 - On the nature of programming exercises.pdf}
}

@inproceedings{souzaSystematicLiteratureReview2016,
  title = {A {{Systematic Literature Review}} of {{Assessment Tools}} for {{Programming Assignments}}},
  booktitle = {2016 {{IEEE}} 29th {{International Conference}} on {{Software Engineering Education}} and {{Training}} ({{CSEET}})},
  author = {Souza, Draylson M. and Felizardo, Katia Romero and Barbosa, Ellen Francine},
  date = {2016-04},
  pages = {147--156},
  publisher = {{IEEE}},
  location = {{Dallas, TX, USA}},
  issn = {2377-570X},
  doi = {10.1109/CSEET.2016.48},
  url = {https://ieeexplore.ieee.org/abstract/document/7474479},
  abstract = {The benefits of using assessment tools for programming assignments have been widely discussed in computing education. However, as both researchers and instructors are unaware of the characteristics of existing tools, they are either not used or are reimplemented. This paper presents the results of a study conducted to collect and evaluate evidence about tools that assist in the assessment of programming assignments. To achieve our goal, we performed a systematic literature review since it provides an objective procedure for identifying the quantity of existing research related to a research question. The results identified subjects in the development of new assessment tools that researchers could better investigate and characteristics of assessment tools that could help instructors make selections for their programming courses.},
  eventtitle = {2016 {{IEEE}} 29th {{International Conference}} on {{Software Engineering Education}} and {{Training}} ({{CSEET}})},
  keywords = {Assessment tools,Bibliographies,Data mining,Databases,Education,Mapping study,Programming assignments,Programming profession,Systematics},
  file = {/home/niko/Zotero/storage/E3XDQ474/Souza e.a. - 2016 - A Systematic Literature Review of Assessment Tools.pdf;/home/niko/Zotero/storage/9UUKNN44/7474479.html}
}

@inproceedings{staubitzPracticalProgrammingExercises2015,
  title = {Towards Practical Programming Exercises and Automated Assessment in {{Massive Open Online Courses}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Teaching}}, {{Assessment}}, and {{Learning}} for {{Engineering}} ({{TALE}})},
  author = {Staubitz, Thomas and Klement, Hauke and Renz, Jan and Teusner, Ralf and Meinel, Christoph},
  date = {2015-12},
  pages = {23--30},
  publisher = {{IEEE}},
  location = {{Zhuhai, China}},
  doi = {10.1109/TALE.2015.7386010},
  url = {https://ieeexplore.ieee.org/abstract/document/7386010},
  abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon presenting the prospect of free high class education to everybody. They bear a tremendous potential for teaching programming to a large and diverse audience. The typical MOOC components, such as video lectures, reading material, and easily assessable quizzes, however, are not sufficient for proper programming education. To learn programming, participants need an option to work on practical programming exercises and to solve actual programming tasks. It is crucial that the participants receive proper feedback on their work in a timely manner. Without a tool for automated assessment of programming assignments, the teaching teams would be restricted to offer optional ungraded exercises only. The paper at hand sketches scenarios how practical programming exercises could be provided and examines the landscape of potentially helpful tools in this context. Automated assessment has a long record in the history of computer science education. We give an overview of existing tools in this field and also explore the question what can and/or should be assessed.},
  eventtitle = {2015 {{IEEE International Conference}} on {{Teaching}}, {{Assessment}}, and {{Learning}} for {{Engineering}} ({{TALE}})},
  keywords = {Assessment,Automated Assessment,Browsers,Context,Education,Games,Massive Open Online Courses,MOOC,Programming,Programming profession,Servers},
  file = {/home/niko/Zotero/storage/ECWP7FH4/Staubitz e.a. - 2015 - Towards practical programming exercises and automa.pdf;/home/niko/Zotero/storage/PTGJCP2Q/7386010.html}
}

@inproceedings{staubitzRepositoryOpenAutogradable2017,
  title = {Towards a Repository for Open Auto-Gradable Programming Exercises},
  booktitle = {2017 {{IEEE}} 6th {{International Conference}} on {{Teaching}}, {{Assessment}}, and {{Learning}} for {{Engineering}} ({{TALE}})},
  author = {Staubitz, Thomas and Teusner, Ralf and Meinel, Christoph},
  date = {2017-12},
  pages = {66--73},
  publisher = {{IEEE}},
  location = {{Hong Kong}},
  doi = {10.1109/TALE.2017.8252306},
  url = {http://ieeexplore.ieee.org/document/8252306/},
  urldate = {2022-01-26},
  eventtitle = {2017 {{IEEE}} 6th {{International Conference}} on {{Teaching}}, {{Assessment}} and {{Learning}} for {{Engineering}} ({{TALE}})},
  isbn = {978-1-5386-0900-2},
  file = {/home/niko/Zotero/storage/JVK7VLX5/Staubitz e.a. - 2017 - Towards a repository for open auto-gradable progra.pdf}
}

@article{strickrothProFormAXMLbasedExchange2015,
  title = {{{ProFormA}}: {{An XML-based}} Exchange Format for Programming Tasks},
  author = {Strickroth, Sven and Striewe, Michael and Müller, Oliver and Priss, Uta and Becker, Sebastian and Rod, Oliver and Garmann, Robert and Bott, Oliver J. and Pinkwart, Niels},
  date = {2015},
  journaltitle = {eleed},
  volume = {11},
  number = {1},
  issn = {1860-7470},
  url = {http://nbn-resolving.de/urn:nbn:de:0009-5-41389},
  abstract = {Unterstützungssysteme für die Programmierausbildung sind weit verbreitet, doch gängige Standards für den Austausch von allgemeinen (Lern-) Inhalten und Tests erfüllen nicht die speziellen Anforderungen von Programmieraufgaben wie z. B. den Umgang mit komplexen Einreichungen aus mehreren Dateien oder die Kombination verschiedener (automatischer) Bewertungsverfahren. Dadurch können Aufgaben nicht zwischen Systemen ausgetauscht werden, was aufgrund des hohen Aufwands für die Entwicklung guter Aufgaben jedoch wünschenswert wäre. In diesem Beitrag wird ein erweiterbares XML-basiertes Format zum Austausch von Programmieraufgaben vorgestellt, das bereits von mehreren Systemen prototypisch genutzt wird. Die Spezifikation des Austauschformats ist online verfügbar [PFMA].},
  keywords = {Austauschformat,Automatische Bewertung,data Format,Datenformat,e-learning,exchange Format,Grader,grading support Software,learning object,learning objects,Lernobjekt,Programmieraufgaben,Programmierausbildung,programming education,programming Task,task package},
  file = {/home/niko/Zotero/storage/J53NDCZY/4138.html}
}

@article{strieweArchitectureModularGrading2016,
  title = {An Architecture for Modular Grading and Feedback Generation for Complex Exercises},
  author = {Striewe, Michael},
  date = {2016-11},
  journaltitle = {Science of Computer Programming},
  shortjournal = {Science of Computer Programming},
  volume = {129},
  pages = {35--47},
  issn = {01676423},
  doi = {10.1016/j.scico.2016.02.009},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167642316300260},
  urldate = {2022-01-24},
  langid = {english},
  file = {/home/niko/Zotero/storage/SLGGTHR9/Striewe - 2016 - An architecture for modular grading and feedback g.pdf}
}

@article{strijbolTESTedEducationalTesting2023,
  title = {{{TESTed}}—{{An}} Educational Testing Framework with Language-Agnostic Test Suites for Programming Exercises},
  author = {Strijbol, Niko and Van Petegem, Charlotte and Maertens, Rien and Sels, Boris and Scholliers, Christophe and Dawyndt, Peter and Mesuere, Bart},
  date = {2023-05-01},
  journaltitle = {SoftwareX},
  shortjournal = {SoftwareX},
  volume = {22},
  pages = {101404},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2023.101404},
  url = {https://www.sciencedirect.com/science/article/pii/S2352711023001000},
  urldate = {2023-09-13},
  abstract = {In educational contexts, automated assessment tools (AAT) are commonly used to provide formative feedback on programming exercises. However, designing exercises for AAT remains a laborious task or imposes limitations on the exercises. Most AAT use either output comparison, where the generated output is compared against an expected output, or unit testing, where the tool has access to the code of the submission under test. While output comparison has the advantage of being programming language independent, the testing capabilities are limited to the output. Conversely, unit testing can generate more granular feedback, but is tightly coupled with the programming language of the submission. In this paper, we introduce TESTed, which enables the best of both worlds: combining the granular feedback of unit testing with the programming language independence of output comparison. Educators can save time by designing exercises that can be used across programming languages. Finally, we report on using TESTed in educational practice.},
  keywords = {Automated assessment tools,Educational software testing,Feedback,Programming},
  file = {/home/niko/Zotero/storage/ZYESDB7L/Strijbol e.a. - 2023 - TESTed—An educational testing framework with langu.pdf;/home/niko/Zotero/storage/8B42R5K3/S2352711023001000.html}
}

@unpublished{sutherlandSumsThreeCubes2019,
  title = {Sums of Three Cubes},
  author = {Sutherland, Andrew V. and Booker, Andrew},
  date = {2019-09-07},
  url = {https://math.mit.edu/~drew/Waterloo2019.pdf},
  eventtitle = {Computational {{Mathematics Colloquium}}},
  venue = {{Waterloo}},
  file = {/home/niko/Zotero/storage/E2KP7E9B/Sutherland en Booker - 2019 - Sums of three cubes.pdf}
}

@incollection{swachaSIPEDomainSpecificLanguage2018,
  title = {{{SIPE}}: {{A Domain-Specific Language}} for {{Specifying Interactive Programming Exercises}}},
  shorttitle = {{{SIPE}}},
  booktitle = {Towards a {{Synergistic Combination}} of {{Research}} and {{Practice}} in {{Software Engineering}}},
  author = {Swacha, Jakub},
  editor = {Kosiuczenko, Piotr and Madeyski, Lech},
  date = {2018},
  volume = {733},
  pages = {15--29},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-65208-5_2},
  url = {http://link.springer.com/10.1007/978-3-319-65208-5_2},
  urldate = {2022-07-26},
  isbn = {978-3-319-65207-8 978-3-319-65208-5},
  file = {/home/niko/Zotero/storage/JCYCFP5Y/Swacha - 2018 - SIPE A Domain-Specific Language for Specifying In.pdf}
}

@inproceedings{tangDataDrivenTestCase2016,
  title = {Data-{{Driven Test Case Generation}} for {{Automated Programming Assessment}}},
  booktitle = {Proceedings of the 2016 {{ACM Conference}} on {{Innovation}} and {{Technology}} in {{Computer Science Education}}},
  author = {Tang, Terry and Smith, Rebecca and Rixner, Scott and Warren, Joe},
  date = {2016-07-11},
  pages = {260--265},
  publisher = {{ACM}},
  location = {{Arequipa Peru}},
  doi = {10.1145/2899415.2899423},
  url = {https://dl.acm.org/doi/10.1145/2899415.2899423},
  urldate = {2022-03-28},
  eventtitle = {{{ITiCSE}} '16: {{Innovation}} and {{Technology}} in {{Computer Science Education Conference}} 2016},
  isbn = {978-1-4503-4231-5},
  langid = {english},
  file = {/home/niko/Zotero/storage/ZRR3SKM2/Tang e.a. - 2016 - Data-Driven Test Case Generation for Automated Pro.pdf}
}

@article{timmisRethinkingAssessmentDigital2016,
  title = {Rethinking Assessment in a Digital Age: Opportunities, Challenges and Risks},
  shorttitle = {Rethinking Assessment in a Digital Age},
  author = {Timmis, Sue and Broadfoot, Patricia and Sutherland, Rosamund and Oldfield, Alison},
  date = {2016},
  journaltitle = {British Educational Research Journal},
  volume = {42},
  number = {3},
  pages = {454--476},
  issn = {1469-3518},
  doi = {10.1002/berj.3215},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/berj.3215},
  urldate = {2023-09-13},
  abstract = {While it is frequently argued that assessment sits at the heart of the learning process, in practice assessment often remains narrowly focused on qualifications and reporting achievements, driven by institutional and societal aspirations and tensions such as accountability and economic well being. Yet, the need for assessment to account for the knowledge, skills, dispositions and attitudes necessary to equip young people for a changing and increasingly digital world is also increasingly acknowledged. Based on our recent research review, this article critically examines the role of technology enhanced assessment (or TEA). We argue that while technology offers many potentially creative opportunities for innovation and for rethinking assessment purposes, there are also numerous risks and challenges. In particular we highlight ethical concerns over social exclusion and new forms of digital dividedness and the increasing risks associated with big data and the rise of learning analytics. Finally, we note that much research and innovation happens in silos, where policy, research and practice on assessment, technology enhanced assessment and ethical and political concerns are not linked up. We conclude that there needs to be a much more wide-ranging, critical and nuanced discussion in educational and policy circles so that debates about the potential of technology can be linked to improving assessment in the light of the range of social and political challenges that such progress presents. We end with some critical questions for policy, practice and research communities, which we offer as a starting point for future thinking and ways forward.},
  langid = {english},
  keywords = {collaboration,digital literacies,e-assessment,ethics,formative/summative,inclusion,learning analytics},
  file = {/home/niko/Zotero/storage/NVAUKC4J/Timmis e.a. - 2016 - Rethinking assessment in a digital age opportunit.pdf}
}

@article{truongLearningProgramWeb2005,
  title = {Learning to Program through the Web},
  author = {Truong, Nghi and Bancroft, Peter and Roe, Paul},
  date = {2005-09},
  journaltitle = {ACM SIGCSE Bulletin},
  shortjournal = {SIGCSE Bull.},
  volume = {37},
  number = {3},
  pages = {9--13},
  issn = {0097-8418},
  doi = {10.1145/1151954.1067452},
  url = {https://dl.acm.org/doi/10.1145/1151954.1067452},
  urldate = {2023-09-13},
  abstract = {Computer-based tutoring systems which assist students in solving introductory programming problems have significant potential for improving the quality of programming education and reducing the instructor's work load. The innovative Environment for Learning to Program (ELP) provides an interactive web-based environment for teaching programming to first year Information Technology students at Queensland University of Technology (QUT). ELP allows students to undertake programming exercises by "filling in the gaps" of a partial computer program presented in a web page and to receive guidance in getting their programs to compile and run. Feedback on quality and correctness is provided through a program analysis framework. Students are given the opportunity to produce working programs at the early stages of their course without the need to familiarize themselves with a complex program development environment.},
  langid = {english},
  file = {/home/niko/Zotero/storage/DVLWSWX9/Truong e.a. - 2005 - Learning to program through the web.pdf}
}

@article{ullahEffectAutomaticAssessment2018,
  title = {The Effect of Automatic Assessment on Novice Programming: {{Strengths}} and Limitations of Existing Systems},
  shorttitle = {The Effect of Automatic Assessment on Novice Programming},
  author = {Ullah, Zahid and Lajis, Adidah and Jamjoom, Mona and Altalhi, Abdulrahman and Al-Ghamdi, Abdullah and Saleem, Farrukh},
  date = {2018},
  journaltitle = {Computer Applications in Engineering Education},
  volume = {26},
  number = {6},
  pages = {2328--2341},
  issn = {1099-0542},
  doi = {10.1002/cae.21974},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cae.21974},
  urldate = {2023-09-13},
  abstract = {Computer programming is always of high concern for students in introductory programming courses. High rates of failure occur every semester due to lack of adequate skills in programming. No student can become a programmer overnight because such learning requires proper guidance as well as consistent practice with the programming exercises. The role of instructors in the development of students' learning skills is crucial in order to provide feedback on their errors and improve their knowledge accordingly. On the other hand, due to the large number of students, instructors are also overloading themselves to focus on each individual student's errors. To address these issues, researchers have developed numerous Automatic Assessment (AA) systems that not only evaluate the students' programs but also provide instant feedback on their errors as well as abridge the workload of the instructors. Due to the large pool of existing systems, it is difficult to cover each and every system in one study. Therefore, this paper provides a comprehensive overview of some of the existing systems based on the three-analysis approaches: dynamic, static, and hybrid. Moreover, this paper aims to discuss the strengths and limitations of these systems and suggests some potential recommendations regarding the AA specifications for novice programming, which may help in standardizing these systems.},
  langid = {english},
  keywords = {automatic assessment,dynamic,novice programming,static,system},
  file = {/home/niko/Zotero/storage/9RUURTJI/Ullah e.a. - 2018 - The effect of automatic assessment on novice progr.pdf}
}

@article{vanpetegemDodonaLearnCode2023,
  title = {Dodona: {{Learn}} to Code with a Virtual Co-Teacher That Supports Active Learning},
  shorttitle = {Dodona},
  author = {Van Petegem, Charlotte and Maertens, Rien and Strijbol, Niko and Van Renterghem, Jorg and Van Der Jeugt, Felix and De Wever, Bram and Dawyndt, Peter and Mesuere, Bart},
  date = {2023-12},
  journaltitle = {SoftwareX},
  shortjournal = {SoftwareX},
  volume = {24},
  pages = {101578},
  issn = {23527110},
  doi = {10.1016/j.softx.2023.101578},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2352711023002741},
  urldate = {2024-02-27},
  langid = {english},
  file = {/home/niko/Zotero/storage/RF4QRLIR/Van Petegem e.a. - 2023 - Dodona Learn to code with a virtual co-teacher th.pdf}
}

@article{verhoeffProgrammingTaskPackages2008,
  title = {Programming {{Task Packages}}: {{Peach Exchange}}},
  author = {Verhoeff, Tom},
  date = {2008},
  journaltitle = {Olympiads in Informatics},
  pages = {192},
  publisher = {{Citeseer}},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.595.4399&rep=rep1&type=pdf},
  file = {/home/niko/Zotero/storage/CB8KBWZV/Verhoeff - 2008 - Programming Task Packages Peach Exchange.pdf}
}

@online{wardJSONLines2021,
  title = {{{JSON Lines}}},
  author = {Ward, Ian},
  date = {2021-08-18},
  url = {https://jsonlines.org/},
  urldate = {2021-09-08}
}

@article{wasikSurveyOnlineJudge2018,
  title = {A {{Survey}} on {{Online Judge Systems}} and {{Their Applications}}},
  author = {Wasik, Szymon and Antczak, Maciej and Badura, Jan and Laskowski, Artur and Sternal, Tomasz},
  date = {2018-01-04},
  journaltitle = {ACM Comput. Surv.},
  volume = {51},
  number = {1},
  pages = {1--34},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  issn = {0360-0300},
  doi = {10.1145/3143560},
  url = {https://doi.org/10.1145/3143560},
  abstract = {Online judges are systems designed for the reliable evaluation of algorithm source code submitted by users, which is next compiled and tested in a homogeneous environment. Online judges are becoming popular in various applications. Thus, we would like to review the state of the art for these systems. We classify them according to their principal objectives into systems supporting organization of competitive programming contests, enhancing education and recruitment processes, facilitating the solving of data mining challenges, online compilers and development platforms integrated as components of other custom systems. Moreover, we introduce a formal definition of an online judge system and summarize the common evaluation methodology supported by such systems. Finally, we briefly discuss an Optil.io platform as an example of an online judge system, which has been proposed for the solving of complex optimization problems. We also analyze the competition results conducted using this platform. The competition proved that online judge systems, strengthened by crowdsourcing concepts, can be successfully applied to accurately and efficiently solve complex industrial- and science-driven challenges.},
  keywords = {challenge,contest,crowdsourcing,evaluation as a service,Online judge},
  file = {/home/niko/Zotero/storage/QCASRZ6P/Wasik e.a. - 2018 - A Survey on Online Judge Systems and Their Applica.pdf}
}

@online{wastlAdventCode2020,
  title = {Advent of {{Code}}},
  author = {Wastl, Eric},
  date = {2020},
  url = {https://adventofcode.com/}
}

@inproceedings{wilcoxTestingStrategiesAutomated2016,
  title = {Testing {{Strategies}} for the {{Automated Grading}} of {{Student Programs}}},
  booktitle = {Proceedings of the 47th {{ACM Technical Symposium}} on {{Computing Science Education}}},
  author = {Wilcox, Chris},
  date = {2016-02-17},
  pages = {437--442},
  publisher = {{ACM}},
  location = {{Memphis Tennessee USA}},
  doi = {10.1145/2839509.2844616},
  url = {https://dl.acm.org/doi/10.1145/2839509.2844616},
  urldate = {2023-09-13},
  abstract = {Enrollments in introductory computer science courses are growing rapidly, thereby taxing scarce teaching resources and motivating the increased use of automated tools for program grading. Such tools commonly rely on regression testing methods from industry. However, the goals of automated grading differ from those of testing for software production. In academia, a primary motivation for testing is to provide timely and accurate feedback to students so that they can understand and fix defects in their programs. Testing strategies for program grading are therefore distinct from those of traditional software testing. This paper enumerates and describes a number of testing strategies that improve the quality of feedback for different types of programming assignments.},
  eventtitle = {{{SIGCSE}} '16: {{The}} 47th {{ACM Technical Symposium}} on {{Computing Science Education}}},
  isbn = {978-1-4503-3685-7},
  langid = {english},
  file = {/home/niko/Zotero/storage/H7JUI635/Wilcox - 2016 - Testing Strategies for the Automated Grading of St.pdf}
}

@article{wilkinsonFAIRGuidingPrinciples2016,
  title = {The {{FAIR Guiding Principles}} for Scientific Data Management and Stewardship},
  author = {Wilkinson, Mark D. and Dumontier, Michel and family=Aalbersberg, given=IJsbrand Jan, given-i={{IJ}}J and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and family=Silva Santos, given=Luiz Bonino, prefix=da, useprefix=true and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and family=Hoen, given=Peter A. C., prefix=’t, useprefix=true and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and family=Schaik, given=Rene, prefix=van, useprefix=true and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and family=Lei, given=Johan, prefix=van der, useprefix=true and family=Mulligen, given=Erik, prefix=van, useprefix=true and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
  date = {2016-03-15},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {3},
  number = {1},
  pages = {160018},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.18},
  url = {https://www.nature.com/articles/sdata201618},
  urldate = {2023-09-13},
  abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
  issue = {1},
  langid = {english},
  keywords = {Publication characteristics,Research data},
  file = {/home/niko/Zotero/storage/VLNMR78N/Wilkinson e.a. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf}
}

@report{williamsJavaScriptObjectNotation2015,
  type = {Request for Comments},
  title = {{{JavaScript Object Notation}} ({{JSON}}) {{Text Sequences}}},
  author = {Williams, Nicolás},
  date = {2015-02},
  number = {RFC 7464},
  institution = {{Internet Engineering Task Force}},
  doi = {10.17487/RFC7464},
  url = {https://datatracker.ietf.org/doc/rfc7464},
  urldate = {2024-02-27},
  abstract = {This document describes the JavaScript Object Notation (JSON) text sequence format and associated media type "application/json-seq". A JSON text sequence consists of any number of JSON texts, all encoded in UTF-8, each prefixed by an ASCII Record Separator (0x1E), and each ending with an ASCII Line Feed character (0x0A).},
  pagetotal = {8},
  file = {/home/niko/Zotero/storage/XMASER4R/Williams - 2015 - JavaScript Object Notation (JSON) Text Sequences.pdf}
}

@book{wintersSoftwareEngineeringGoogle2020,
  title = {Software {{Engineering}} at {{Google}}: {{Lessons Learned}} from {{Programming Over Time}}},
  shorttitle = {Software {{Engineering}} at {{Google}}},
  author = {Winters, Titus and Manshreck, Tom and Wright, Hyrum},
  date = {2020-02-28},
  eprint = {V3TTDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{O'Reilly Media}},
  url = {https://www.oreilly.com/library/view/software-engineering-at/9781492082781/},
  abstract = {Today, software engineers need to know not only how to program effectively but also how to develop proper engineering practices to make their codebase sustainable and healthy. This book emphasizes this difference between programming and software engineering.How can software engineers manage a living codebase that evolves and responds to changing requirements and demands over the length of its life? Based on their experience at Google, software engineers Titus Winters and Hyrum Wright, along with technical writer Tom Manshreck, present a candid and insightful look at how some of the world’s leading practitioners construct and maintain software. This book covers Google’s unique engineering culture, processes, and tools and how these aspects contribute to the effectiveness of an engineering organization.You’ll explore three fundamental principles that software organizations should keep in mind when designing, architecting, writing, and maintaining code:How time affects the sustainability of software and how to make your code resilient over timeHow scale affects the viability of software practices within an engineering organizationWhat trade-offs a typical engineer needs to make when evaluating design and development decisions},
  isbn = {978-1-4920-8276-7},
  langid = {english},
  pagetotal = {602},
  keywords = {Computers / Software Development & Engineering / Project Management,Computers / Software Development & Engineering / Quality Assurance & Testing,Computers / Software Development & Engineering / Systems Analysis & Design,Computers / Software Development & Engineering / Tools,Computers / Systems Architecture / General},
  file = {/home/niko/Zotero/storage/5URZL92K/Winters e.a. - 2020 - Software Engineering at Google Lessons Learned fr.pdf}
}

@report{wrightJSONSchemaMedia2022,
  type = {Internet-Draft},
  title = {{{JSON Schema}}: {{A Media Type}} for {{Describing JSON Documents}}},
  author = {Wright, Austin and Andrews, Henry and Hutton, Ben and Dennis, Greg},
  date = {2022-06-10},
  number = {draft-bhutton-json-schema-01},
  institution = {{Internet Engineering Task Force}},
  url = {https://datatracker.ietf.org/doc/draft-bhutton-json-schema/01/},
  abstract = {JSON Schema defines the media type "application/schema+json", a JSON- based format for describing the structure of JSON data. JSON Schema asserts what a JSON document must look like, ways to extract information from it, and how to interact with it. The "application/ schema-instance+json" media type provides additional feature-rich integration with "application/schema+json" beyond what can be offered for "application/json" documents.},
  pagetotal = {78},
  annotation = {Backup Publisher: Internet Engineering Task Force},
  file = {/home/niko/Zotero/storage/SX7HXQ3T/Wright e.a. - 2022 - JSON Schema A Media Type for Describing JSON Docu.pdf}
}

@software{zakasESLint,
  title = {{{ESLint}}},
  author = {Zakas, Nicholas C. and Mills, Brandon and Djermanovic, Milos},
  url = {https://eslint.org/},
  urldate = {2017-06-17}
}

@inproceedings{zavalaUseSemanticBasedAIG2018,
  title = {On the {{Use}} of {{Semantic-Based AIG}} to {{Automatically Generate Programming Exercises}}},
  booktitle = {Proceedings of the 49th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  author = {Zavala, Laura and Mendoza, Benito},
  date = {2018-02-21},
  pages = {14--19},
  publisher = {{ACM}},
  location = {{Baltimore Maryland USA}},
  doi = {10.1145/3159450.3159608},
  url = {https://dl.acm.org/doi/10.1145/3159450.3159608},
  urldate = {2021-11-18},
  eventtitle = {{{SIGCSE}} '18: {{The}} 49th {{ACM Technical Symposium}} on {{Computer Science Education}}},
  isbn = {978-1-4503-5103-4},
  langid = {english},
  file = {/home/niko/Zotero/storage/NVJH26HY/Zavala en Mendoza - 2018 - On the Use of Semantic-Based AIG to Automatically .pdf}
}
