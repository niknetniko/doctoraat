\documentclass[main]{subfiles}

\begin{document}

\chapter*{Summary}\label{ch:summary}

% TODO bold text

Learning to program is hard, and many students find programming courses hard.
As the idiom tells us, practice makes perfect.
This is no different in programming education: it is generally accepted that the best way to learn programming is through experience.
However, to actually learn something from these experiences, qualitative and timely feedback is crucial.

Yet providing this feedback on many exercises for many students is labour-intensive and time-consuming.
\marginnote{Long is relative of course, but appropriate considering programming education also first appeared in the early 1960s.}
This is why there is a long history (since at least the early 1960s) of using automation to provide feedback automatically.
The process of providing this feedback is called automated assessment.

In most cases, automated assessment for programming education involves software testing.
The code written by the students for a certain exercise (we call this a submission) is tested for at least correctness.
Often, the feedback is more detailed than just a global correct or wrong.

Our department also created a platform for automated assessment: Dodona.
One key feature in Dodona is the separation between the platform itself and the framework responsible for assessing submissions (the judge).
This means Dodona can support almost any programming language.

While working on Dodona, we observed some shortcomings in existing educational tools that help with programming education.
A more detailed look at the context and Dodona is given in \cref{ch:introduction}.
In summary, this dissertation attempts to overcome five of these observed shortcomings.

\Cref{ch:tested1} addresses the duplication work that is necessary when wanting to use a programming exercise in multiple programming languages.
A lot of exercises are suitable for this in concept.
However, to actually use them, one must first copy the exercise, then manually convert the test suite to whatever format used by the judge in the target language, and finally change the configuration files and task descriptions.
As a solution to this, we introduce \textbf{TESTed}, an educational software testing framework.
Its defining feature is the ability to
create programming‐language‐agnostic exercises.
This means that the same exercise (with one test suite) can be solved in multiple programming languages, with support for automated assessment.

With the TESTed prototype in hand, we then took a step back to look at what is required to go from a prototype to a viable option for creating programming exercises.
We wanted TESTed to be the default option for creating programming exercises for Dodona.
As such, we want TESTed to be suitable for educators in both higher and secondary education.
As an answer to this, we introduce TESTed-DSL in \cref{ch:tested-dsl}: a domain-specific language for authoring programming exercises with support for automated assessment across programming languages.
A domain-specific language is a format or language specifically designed for a narrow application, in this case a format designed specifically for programming exercises.
It turns out that by paying special attention to the ergonomics of TESTed-DSL, it is also suitable for exercises that are not intended to be used in multiple
programming languages.

Young children often learn programming by using a visual programming language.
A visual programming language lets users create programs by manipulating program elements graphically, rather than textually.
The most popular is Scratch.
In Scratch, users create a program by dragging blocks around and clicking them together (not unlike puzzle pieces).
Since Scratch works with blocks, it is also called a block-based language.
A more detailed introduction to Scratch can be found in \cref{ch:scratch-the-programming-environment}.

Since Dodona supports multiple programming languages, we initially created a judge (the testing framework) for Scratch within Dodona.
However, Scratch is not just a programming language, it is also a programming environment.
It thus became clear that the needs for a platform that supports Scratch were too different from what we can do in Dodona.
For this reason, we partnered with CodeCosmos, a industrial/commercial partner.
As they are an educational publisher whose products include Scratch exercises, they already have a platform for working with Scratch.

\Cref{ch:itch} presents Itch, our testing framework for Scratch.
It supports both static tests (meaning a test only looks at the blocks of the program, without executing it) and dynamic tests (where the program is executed with some inputs and the results are observed).
The combination of both means Itch can test a wide variety of Scratch programs.
In Scratch is very game-like and exploratory and encourages children to experiment and use their fantasy.
This does introduce challenges when attempting to test Scratch programs.
For example, if the instructions are ``Draw a house'', how can we verify if the program is correct.
We thus do have to place some limits on what types of exercises Itch can test.

When a testing framework like Itch gives feedback to students, either everything is correct, but more often than not, some test cases fail.
Then begins the debugging process: the students have to figure out what the cause of the failed test is.
This is notoriously difficult, since the location of the cause in the program is often not obvious.
However, there are tools to help with this, with the main tools being debuggers.
For textual programming languages, there are a lot of debuggers and a lot of research into debuggers.
As an example, Dodona supports a debugger for Python.

However, for Scratch and block-based languages in general, this is not the case.
Therefore, we introduce a new debugger for Scratch in \cref{ch:blink}: Blink.
Blink supports stepping through the code (i.e.\ going one step at a time when running the program), pausing and resuming the execution of a program, breakpoints (special blocks that automatically pause the execution when they are executed), and time travelling.
A time-travelling debugger allows the programmer to go backwards in the execution, by recording program execution.
Every step of the program is saved, so we can go back step-by-step.
Since Scratch is used mainly by a young audience, we took special care to make the debugger intuitive.
Initial tests in the classroom show that students find the debugger intuitive, especially the time travelling.

In the previous paragraph, we said the debugger allows going one step at a time in the program.
However, we did not detail what a step means in the context of Scratch.
In Scratch, a project consists of different sprites (which are drawn on the screen).
Each sprite has its own code, a set of scripts (a script is a set of connected blocks).
Every script from every sprite can be run concurrently in Scratch.
Consequently, we believe a traditional step in a debugger (advanced one block in a single script from one sprite) is not ideal.
We want the step feature to advance a single block in every running script across all sprites.

However, due to the way Scratch works internally (the execution model), advancing a single block in every script is not possible.
Scratch uses an almost-cooperative threading model, which means it executes multiple blocks in the same script, then jumps to the next script, and so on.
This happens fast, so it looks like all scripts execute in parallel, but this is thus not the case.
We also found this threading model to be the cause of some unintuitive behaviour.

In \cref{ch:scratch-execution-model}, we investigate if we can modify the execution model in such a way that we can implement the stepping functionality as described above, without negatively affecting performance of behaviour in existing Scratch projects when executed normally.
Since Scratch is so widely used, we cannot introduce changes that would cause half of existing projects to stop working.
To properly evaluate this, we also look into what a typical Scratch project looks like.
It turns out that most Scratch projects are simple and small.

Finally, \cref{ch:conclusions-and-opportunities} concludes this dissertation by summarizing the work we did and presented in the various chapters and reflecting on what future endeavours might involve.

\end{document}
