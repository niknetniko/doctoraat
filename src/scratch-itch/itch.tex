%! suppress = FileNotFound
\documentclass[../main]{subfiles}

\begin{document}

\chapter{A testing framework for Scratch}\label{ch:itch}

\dictum[Larry Flon \\ \textit{On research in structured programming}]{There does not now, nor will there ever, exist a programming language in which it is the least bit hard to write bad programs.}

Block-based languages like Scratch are popular tools for introducing computer science concepts to students~\autocite{bauLearnableProgrammingBlocks2017}.
The intuitive interface and focus on visuals make Scratch an engaging and accessible programming environment.
Due to this visual nature, syntactical programming errors are eliminated and students can quickly create games, stories, or other projects.
This approach gives students a lot of flexibility to express their creativity.
However, functional errors will still occur~\autocite{zellerWhyProgramsFail2009a}.
The process of teaching to code is often slowed down by the delay in providing feedback on and solutions to these errors.

When done manually, assessment of submissions for Scratch exercises is time-consuming and impractical, especially in large classes, where educators often lack the time to give individual feedback to each student.
That is why it is important to equip students with tools that can provide immediate feedback and thus enhance their independent learning skills.
In this chapter, we introduce Itch, a testing framework for Scratch, that can act as an automated assessment tool.

Itch provides flexible testing capabilities: it supports both static and dynamic testing of Scratch projects.
It provides tools to make common scenarios easy to test, allowing the educators to focus on testing the interesting parts of an exercise.

We also reflect on Itch's use in an educational context and discuss what testing of Scratch exercises should look like.
On the one hand, Scratch strives to allow maximal creative expression for students, while on the other hand, testable exercises need a well-defined goal and reasonable limits.

\section{Related work}\label{sec:related-work}

There are few testing frameworks for Scratch.
In this section, we look at the few existing ones, but also consider some other tools with similar aims.
We begin with the linter-like tools that perform static analysis.

The first one is Hairball~\autocite{boeHairballLintinspiredStatic2013}.
Hairball analyses the blocks of a provided Scratch project, with multiple rules and analyzers available.
Dr. Scratch~\autocite{moreno-leonDrScratchWeb2015} allows analysing a Scratch project to provide various insights.
For example, Dr. Scratch uses Hairball to assign a ``computational thinking score'' to the project, although the creators of Scratch are not a fan of this approach~\autocite{resnickCodingCrossroads2020}, see \cref{subsec:how-to-evaluate-scratch-exercises}.

Scrape was a tool that visualized the use of blocks in a Scratch project.
This is useful to determine which blocks are used, and which are not.
This tool only works reliably with Scratch 1, but was used by the Scratch team to analyse uploaded Scratch projects~\autocite{brennan2012new}.

QualityHound~\autocite{techapalokulQualityHoundOnline2017} is a linter that detects code smells like ``duplicate code'' or ``broad variable scope''.
In total, twelve code smells are detected.
LitterBox~\autocite{fraserLitterBoxLinterScratch2021} is a newer linter that shares some goals with QualityHound.
For example, it will also detect code smells.
LitterBox supports significantly more patterns, and also finds potential bugs~\autocite{fradrichCommonBugsScratch2020}, by looking for code that seems suspicious (for example, comparing two literal values).
Subsequent research has expanded LitterBox to find ``code perfumes''~\autocite{obermullerCodePerfumesReporting2021}, which provides positive feedback to students, for example, by noting good use of loops.

LitterBox can also translate code to LeILa, an intermediate language of the Bastet framework~\autocite{stahlbauerVerifiedScratchProgram2020}.
Bastet uses this intermediate language to enable more traditional and advanced analysis and verification of Scratch programs.
Examples of what the authors envision are automated test generation, data-flow analysis, unbounded model checking on predicate abstraction, and concolic testing.

\marginnote{Unfortunaly, we were not aware of \textsc{itch} when deciding to name our testing framework Itch.}
\textsc{itch}~\autocite{johnsonITCHIndividualTesting2016} is the first automatic testing framework to the knowledge of the authors.
It translates a very limited subset of Scratch programs to Python.
\textsc{itch} uses the Scratch say and ask functionality to perform input/output-based testing on Scratch projects.
Of course, being limited to input/ouput, only a subset of the functionality of Scratch can be used.

Finally, Whisker~\autocite{stahlbauerTestingScratchPrograms2019} is a full automated testing framework for Scratch, and the only most similar to Itch.
While manually written test suites (also in JavaScript) are possible, Whisker focuses on automated testing~\autocite{deinerAutomatedTestGeneration2023}.
For example, Whisker (and subsequent research), supports property-based testing, search-based testing~\autocite{deinerSearchBasedTestingScratch2020}, and model-based testing~\autocite{gotzModelbasedTestingScratch2022}.

\section{Using the framework}\label{sec:itch-using-the-framework}

\begin{figure}
    \begin{wide}
        \includegraphics[width=\linewidth]{itch-grow-and-shrink-code}
    \end{wide}
    \caption{
        The \emph{Grow and shrink} exercise.
        A correct implementation of the exercise for the sprite \texttt{Nano} is seen here.
    }
    \label{fig:itch-grow-shrink-code}
\end{figure}

To illustrate Itch, we will use one exercise as a running example: the \emph{Grow and shrink} exercise (\cref{fig:itch-grow-shrink-code}).
In this exercise, there are three sprites: each sprite must grow if the ``g'' key is pressed.
Additionally, the sprites must shrink if the ``k'' key is pressed.
To test this exercise, we design a test suite that will verify the behaviour of the sprites (\cref{lst:itch-grow-and-shrink}).
It will:

\begin{enumerate}[noitemsep]
    \item Save the existing size of the sprites.
    \item Press the key that we are testing.
    \item Verify if the new size of the sprite is larger or smaller than the previously saved size.
    \item Save the new size as the existing size for the next test.
\end{enumerate}

\begin{listing}
    \begin{minted}{javascript}
function duringExecution(e) {
  const rt = e.vm.runtime;
  // Save the original sizes of the sprites.
  const oldSizes = {
    "Giga": rt.getSpriteTargetByName("Giga").size,
    "Pico": rt.getSpriteTargetByName("Pico").size,
    "Nano": rt.getSpriteTargetByName("Nano").size
  }
  e.scheduler
    // Execute 4 events after each other.
    .forEach([1, 2, 3, 4], (prev) => {
      // Press the "g" key
      return prev.pressKey('g').log(() => {
        e.out.group("Test if sprites get bigger", () => {
          for (const sprite in oldSizes) {
            // Check if the new size is more than the old size.
            const newSize = rt.getSpriteTargetByName(sprite).size;
            e.out
              .test(`${sprite} got bigger`)
              .expect(newSize > oldSizes[sprite])
              .toBe(true);
            // Save the new size as the old one.
            oldSizes[sprite] = newSize
          }
        })
      });
    }).forEach([1, 2, 3, 4], (prev) => {
    return prev.pressKey('k').log(() => {
      e.out.group("Test if sprites get smaller", () => {
        for (const sprite in oldSizes) {
          const newSize = rt.getSpriteTargetByName(sprite).size;
          e.out
            .test(`${sprite} got smaller`)
            .expect(newSize < oldSizes[sprite])
            .toBe(true);
          oldSizes[sprite] = newSize
        }
      })
    });
  })
    .end();
}
    \end{minted}
    \caption{The complete test suite for the \emph{Grow and shrink} exercise in Itch.}
    \label{lst:itch-grow-and-shrink}
\end{listing}

Since this is a dynamic test suite (we do not look at the blocks), only one of the phases of the test suite is used (see \cref{sec:itch-test-suites}).
As a result of running this test suite, feedback is generated.
The structure of the test suite (\cref{subsec:structure-of-a-test-suite2}) is reflected in the output (\cref{sec:format-of-the-generated-feedback}).
It also contains the groups and the tests.


% TODO
%\section{Design of the framework}\label{sec:itch-architecture}
%
%Itch inserts itself into the Scratch Virtu

\section{Test suites}\label{sec:itch-test-suites}

Test suites for Itch are written in JavaScript.
A test suite for Itch is split into three phases:

\begin{enumerate}
    \item The \term{before execution} phase, which is run before the execution of the Scratch project.
    \item The \term{during execution} phase, where the test suite controls the Scratch project and simulates user interaction.
    \item The \term{after execution} phase, where tests are run on the log, which was collected during the previous phase.
\end{enumerate}

All phases are optional, but a test suite without any phases will not test anything.
However, it is perfectly valid to not have a before execution, or only a before execution, depending on the types of tests you want to run.
They are implemented with ``magic'' functions: these have a fixed signature (name and arguments) and will be called in the relevant phases (\cref{lst:itch-test-suite-skeleton}).

\begin{listing}
    \begin{minted}{javascript}
/** @param {Evaluation} e */
function beforeExecution(e) {
    // Tests go here
}

/** @param {Evaluation} e */
function duringExecution(e) {
    // Tests go here
}

/** @param {Evaluation} e */
function afterExecution(e) {
    // Tests go here
}
    \end{minted}
    \caption[]{
        A skeleton of a test suite for Itch that shows the three phases.
        Each phase is implemented as a separate function that will be called at the appropriate time by Itch.
        The argument to these functions is an instance of the \mintinline{javascript}{Evaluation} class, which provides various methods to help with testing, such as the test structure, assertion functions, etc.
    }
    \label{lst:itch-test-suite-skeleton}
\end{listing}

Broadly, the tests can also be split according to their type: there are \term{static tests} and \term{dynamic tests}.
Static tests do not require execution of the Scratch project.
They are generally easier to write and faster to execute, but are severely limited in what they can test.
Assessing whether a project uses a certain block (e.g.\ a loop block) somewhere in the project is typically done with static tests.
Assessing whether a preprogrammed sprite (e.g.\ blocks that are provided in the starter project) was not modified is also done with static tests.
Static tests can be done completely in the before execution phase.

Checking more high-level goals, such as ``Does the sprite move when clicked?'', are more challenging with static tests.
At least, without severely limiting the accepted solutions.
For example, there are multiple ways to implement a sprite that moves when clicked, and a good test will want to accept all implementations.
For these kinds of behavioural tests, dynamic tests can be used.
These require the project to execute.
For these, the during and after execution phases are needed.
In the during execution phase, user interaction is simulated and the behaviour is captured.
This captured behaviour can then be inspected in the after execution phase to see if the actual behaviour matches with the required behaviour.

\subsection{Structure of a test suite}\label{subsec:structure-of-a-test-suite2}

A test suite consists of a hierarchical structure of groups and tests, which can be nested.
A test is a check on some property of the exercise.
It can be correct or wrong, and can contain feedback for both cases.
Additionally, a test also has a name and can include additional information, such as diffs, messages, etc.

Structure is added by grouping the tests into groups.
Groups can be nested, so groups inside groups etc.\ is possible.
While there is no hard limit, the recommendation is to not go deeper than three levels in most cases.
Groups are used for more than just structure.
They also support a notion of visibility, with three modes:

\begin{itemize}[noitemsep]
    \item \emph{Visible}: the group is expanded (all children are visible).
    \item \emph{Hidden}: the group is completely hidden, unless one of the tests in the group fails.
    \item \emph{Summary}: the group is collapsed by default and a summary is shown unless one of the tests fails (in which case the group is expanded).
\end{itemize}

\begin{listing}
    \centering
    \begin{minted}{javascript}
        e.group.group('Tests for sprite A', () => {
          e.group
            .test('Sprite A does stuff right')
            .feedback({
              correct: 'Good job, sprite A does get stuff right!',
              wrong: 'Oh no, sprite A does not get it right.',
            })
           .expect('some value')
           .toBe('another value');
        });
    \end{minted}
    \caption{An example showing how the test suites are structured using groups and tests.}\label{lst:itch-test-suite-structure}
\end{listing}

Groups and tests in the JavaScript test suites are inspired by the Jest\footnote{\url{https://jestjs.io/}} testing framework.
The two relevant methods, \mintinline{javascript}{group} and \mintinline{javascript}{test} are available on the \mintinline{javascript}{Evaluation.group} property passed to the test suite.
\Cref{lst:itch-test-suite-structure} shows an example of this, containing a single test.
\marginnote{Backwards compatibility is one of the downsides of using software in production.}
The double \mintinline{javascript}{group.group} is not a typo, but needed for backwards compatibility with older test suites.
The test, as written in the example, will always fail, since it expects the string \mintinline{javascript}{"some value"} to be equal to \mintinline{javascript}{"another value"}.
The \mintinline{javascript}{expect}/\mintinline{javascript}{toBe} notation specifically will be familiar to Jest users.

Groups can be given just a name, as in the example, but it is also possible to provide more structured data.
For example, it is possible to link a group to a certain sprite.
This information is also provided in the generated feedback, which means the platform responsible for showing the feedback can, for example, show an image of the sprite with the group.

More details on how this structure is reflected in the generated feedback can be found in \cref{sec:format-of-the-generated-feedback}.
More metadata includes the visibility, a summary (used if the group's visibility is set to summary), some tags (which allows to tag groups with arbitrary strings), and an option to ignore wrong tests.
This last option means that if a test fails, it will be ignored completely and will not be outputted in the generated feedback.
This can be useful in cases where there are multiple possibilities: this allows trying each possibility until a passed test is found.

\subsection{Before execution}\label{subsec:before-execution}

The before execution phase allows for executing static tests.
Itch provides access to representations of two projects: the submission, created by the students, and the starter project, which is the project the students started with.

Providing both of these allows an easy way to assess whether the students modified some sprites or blocks in a sprite.
Itch provides helpers to ensure that students only modified certain sprites, or only certain code within sprites.
While this does limit the students in their ability to creatively modify the project, it makes behavioural tests for complex projects easier.
By limiting where the students are allowed to modify blocks, later tests can rely on certain functionality or sprites being available and working.
For example, if the project contains blocks that check if a sprite touches another sprite, these can be relied on.

This functionality of checking a set of predefined blocks and sprites is exposed with the function \mintinline{javascript}{Itch.checkPredefinedBlocks} to test suite authors.
For example:

\begin{minted}{javascript}
    Itch.checkPredefinedBlocks({
      spriteConfig: {
        SpriteA: script(whenIReceive('Start'), setEffectTo('brightness', 0)),
        SpriteB: {
          pattern: script(whenIReceive('Start'), setEffectTo('ghost', 0)),
          allowedBlocks: [forever()],
          allowAdditionalScripts: true,
        },
      },
      debug: false,
    }, e);
\end{minted}

The example above contains the test for two sprites.
All other sprites must be unchanged.

For the sprite \texttt{SpriteA}, students are allowed to change, add, or remove blocks in the script starting with the two blocks \scratchinline{\blockinit{when I receive \selectmenu{Start}}} and \scratchinline{\blocklook{set \selectmenu{ghost} effect to \ovalnum{0}}}.
Students are allowed to change blocks after these two predefined blocks.

The second sprite, \texttt{SpriteB}, allows modifications to scripts starting with the same blocks, but it uses the full version of the config object.
With the full version, it is also possible to also specify if additional scripts are allowed and limit the blocks they can use.
In this example, only the \scratchinline{\blockinfloop{forever}{\blockspace[0.2]}} block can be used (so this is not very useful test).
Finally, additional scripts (thus new ones created by the students) are also allowed.
These are free of restrictions: the check for allowed blocks does not apply.

\begin{listing}
    \begin{wide}
        \begin{subfigure}{0.49\linewidth}
            \begin{scratch}[scale=0.8]
                \blockinit{when I receive \selectmenu{Start}}
                \blocklook{set \selectmenu{ghost} effect to \ovalnum{0}}
                \blockrepeat{repeat \ovalnum{15}}
                {
                    \blocklook{change size by \ovalnum{3}}
                    \blockmove{change y by \ovalnum{-2}}
                }
                \blockrepeat{repeat \ovalnum{15}}
                {
                    \blocklook{change \selectmenu{ghost} effect by \ovalnum{5}}
                    \blockmove{change size by \ovalnum{3}}
                }
                \blocklook{hide}

            \end{scratch}
            \caption{A script in Scratch.}
        \end{subfigure}
        \begin{subfigure}{0.5\linewidth}
            \begin{minted}{javascript}
            script(
              whenIReceive('Start'),
              setEffectTo(ghost(), 0),
              repeat(15, script(
                changeSizeBy(3),
                changeYBy(-2))
              ),
              repeat(20,script(
                changeEffectBy(ghost(), 5),
                changeSizeBy(3))
              ),
              hide(),
            );
            \end{minted}
            \caption{The equivalent in JavaScript.}
        \end{subfigure}
    \end{wide}
    \caption{An example of how a Scratch program can be represented using the abstractions provided by Itch.}\label{lst:itch-block-abstraction}
\end{listing}

Itch also includes an abstraction to represent Scratch blocks in JavaScript, as used in the example above.
For each Scratch block, a corresponding function exists (see an example in \cref{lst:itch-block-abstraction}).

The functions representing blocks can also be used to construct block patterns.
Two additional are provided for patterns.
The first is \mintinline{javascript}{anything()}, which can be used in any location (as a block or value) and matches any block or value.
The reverse, \mintinline{javascript}{nothing()}, matches no block or value.
It can be useful to ensure that a script terminates (i.e.\ that there are no more blocks afterwards).
Additionally, an array of blocks or patterns can also be used in most places.
This represents a choice: it will match any of the patterns in the array.

For example, the pattern \mintinline{javascript}{repeat([15, 30], script(changeSizeBy(any()), never()))}, will match a \texttt{repeat} block that repeats 15 or 30 times, with a body with exactly one block, the \texttt{change size by} block, whose argument can be anything.

Since scripts form a tree of blocks, there are also helpers to match and test against a script of blocks.
This supports error messages for each block (meaning they each show up as a failed assertion in the output).

\subsection{During execution}\label{subsec:during-execution}

\begin{listing}
    \begin{minted}{javascript}
        /** @param {Evaluation} e */
        function duringExecution(e) {
          e.scheduler
           .greenFlag(true)
           .wait(800)
           .pressKey('s')
           .end();
        }
    \end{minted}
    \caption{An example of the during execution phase where the scheduler is used to first press the green flag, wait \qty{800}{\milli\second}, press the ``s'' key, and finally end execution.}\label{lst:itch-scheduler-example}
\end{listing}

The during execution phase is actually run just before the project is executed by Itch.
The main purpose of this phase is to use the \mintinline{javascript}{e.scheduler} (an instance of the \mintinline{javascript}{Scheduler} class) to schedule the execution of the project.
Using the scheduler, the test suite must specify how the project should be executed.
This includes starting execution, stopping execution, manipulating the virtual machine, and simulating user interaction, like clicking, key presses, input, and so on.
\Cref{lst:itch-scheduler-example} shows a minimal example of a schedule where the green flag is pressed, some time must pass, and finally the ``s'' key is pressed.

The scheduler receives a set of actions to perform.
Each next action is executed after the previous one has been completed.
Because Scratch is a highly concurrent language, the scheduler also supports this.
First, most actions support a synchronous and asynchronous variant.
In the asynchronous variant, the action is executed and immediately finished.
For example, the action to press the green flag is almost instant: the green flag is pressed in the virtual machine, and the action is complete.

The synchronous actions will only finish after all activated scripts in Scratch have terminated.
For example, the action to press the green flag will wait on all scripts with the hat block \scratchinline{\blockinit{when \greenflag clicked}} are done executing.
Of course, there are scenarios where this is not possible.
If one of the scripts contains an infinite loop, the next scheduled action would never be performed, as the script will never end.

Since the project that is run comes from students with unknown code, synchronous actions also support a timeout.
After this time has passed, a failed assertion will be added to the generated feedback, and the scheduler will continue.

Every action in the scheduler returns the last scheduled action: this return value can be used to schedule a next action after the previous one.
To create a non-linear schedule (e.g.\ multiple actions are performed simultaneously), there are a few options.
First, the return value of one of the previous actions can be used multiple times to schedule new actions.
All of these will be run in parallel.

% TODO: visualise this?

The other option is to use the method \mintinline{javascript}{forEach}: this is an implementation of the ``fold'' function on the events.
By deciding what event is used as the accumulator, either a linear (by returning the new action) or non-linear schedule (by returning the existing action) can be created.

While most actions are equivalent to their counter-parts in Scratch (like clicking a sprite, pressing a key, etc.), the wait action has more features.
In addition to waiting a set amount of time (like in the example), the wait action can also wait on the fulfillment of a certain condition.
The wait condition can be either waiting on a certain broadcast being sent, or a sprite fulfilling some condition.
The possible sprite conditions are moving, reaching a certain position, touching another sprite, no longer touching another sprite, touching the edge, and touching the mouse.
These conditions are added as needed, so with use, we envision more conditions being added.

A final special action is the \mintinline{javascript}{log} action.
This action saves the current state in the log (\cref{subsec:after-execution}) and executes a custom function at that time.
This action is intended to mark certain events in the log, but can also be used to execute a certain test during the execution of the project, instead of beforehand or afterwards.

\subsection{After execution}\label{subsec:after-execution}

\begin{listing}
    \begin{minted}{javascript}
        /** @param {Evaluation} e */
        function afterExecution(e) {
          // Get all click events on the Hat
          const clicks = e.log.events.filter((e) => e.type === 'click' && e.data.target === 'Hat');
          for (const cl of clicks) {
            const target = cl.data.target;
            const costumeNrBefore = cl.previous.target(target).currentCostume;
            const costumeNrAfter = cl.next.target(target).currentCostume;

            // Check that the costume cycles.
            const correctCostumeNr = (costumeNrBefore + 1) % 1;
            e.group.test('Click on Hat')
              .expect(costumeNrAfter)
              .toBe(correctCostumeNr);
          }
        }
    \end{minted}
    \caption{An after execution phase, where the log is used to check if the costume of the sprite \texttt{Hat} changes after each click (there are two costumes and the costumes need to cycle).}\label{lst:itch-hat-costum-change}
\end{listing}

Itch uses the schedule from the during execution phase to execute the submission.
During the execution, a log is constructed of the execution.
This is done by hand (using the \mintinline{javascript}{log} scheduler action) and automatically at interesting points.
The log consists of snapshots (which are taken every time something changes in the virtual machine) and events (which denote interesting snapshots).
For example, every action in the scheduler is saved as an event, meaning there is a snapshot before the action and after the action has been completed.

For example in \cref{lst:itch-hat-costum-change}, the action to click a sprite (which was scheduled in the previous phase) has a corresponding event in the log.
That event gives access to a snapshot from before the sprite was clicked and after the sprite was clicked (in this case, the scheduled action was synchronous).
In the actual test suite, the previous phase did not schedule one click, but a bunch of clicks.
Each of these events provides before and after snapshots, which are then used to determine if the costume changes as expected when the sprite was clicked.
As the example shows, the test suite is not concerned with the actual implementation in Scratch: the behaviour is tested.

\section{Evaluating projects}\label{sec:itch-evaluating-projects}

The evaluation of a submission goes through the following process:

\begin{enumerate}
    \item The submission, the starter project, and the test suite are made available (see later, as this depends on how Itch is run).
    \item Itch loads both projects, and runs the before execution phase.
    \item If the before execution phase does not result in an error, Itch initialises the virtual machine, inserts hooks for the log, and loads the submission into the virtual machine.
    \item The during execution phase is run, and the scheduled actions are captured from the test suite.
    \item Itch starts the virtual machine and executes the scheduled actions.
          While executing, the logs are captured.
    \item If the execution did not result in an error, Itch shuts down the virtual machine, and runs the after execution phase.
    \item All feedback is sent to the output.
\end{enumerate}

Scratch is built using browser technologies.
For the full capabilities, it has to be run in the browser.
While the virtual machine is pure JavaScript and could thus run without a browser, the renderer is not: it uses the HTML canvas and WebGL technologies.
The renderer is used to calculate things like sprite collisions and checking if sprites touch certain colours.
While it is theoretically possible to create a renderer that does not use WebGL, this would be a big undertaking and imply a big maintenance burden.
The re-implemented renderer will have to be kept up to date with the upstream one and replicate all behaviour exactly.

For these reasons, there are two ways to run Itch:

\begin{itemize}
    \item As a library in the browser.
          This is useful for contexts where you already have a browser, e.g.\ running along the Scratch environment on the device of the student.
    \item As a command line tool.
          This is for cases where Itch runs as a service in the backend, e.g.\ to check submissions after students are done.
\end{itemize}

\subsection{Running Itch as a library}\label{subsec:running-itch-as-a-library}

\begin{listing}
    \begin{minted}{typescript}
        export interface EvalConfig {
          /** The submission sb3 data. */
          submission: ArrayBuffer;
          /** The starter project sb3 file. */
          template: ArrayBuffer;
          /** If the output should be partial or full. */
          fullFormat: boolean;
          /* The canvas for the renderer. */
          canvas: HTMLCanvasElement;
          /** The test suite to use. */
          testplan: string | TestplanSource;
          /** Callback for the results. */
          callback: OutputHandler;
          /** The language of the exercise. */
          language: string;
        }

        /** Run the judge. */
        export async function run(config: EvalConfig): Promise<void>;
    \end{minted}
    \caption{The exposed interface to run Itch. It consists of one function and a configuration object.}\label{lst:itch-library-interface}
\end{listing}

Itch consists of two JavaScript packages, of which the core package implements the testing framework itself.
This package can be loaded into the browser and run.
The exposed interface to run Itch is limited to one function and a configuration object (\cref{lst:itch-library-interface}).
Most of the options are self-explanatory, and the output format option is explained in \cref{sec:format-of-the-generated-feedback}.

\subsection{Running Itch as a command line tool}\label{subsec:running-itch-as-a-command-line-tool}

\begin{figure}
    \begin{wide}
        \includestandalone[width=\linewidth]{itch-sequence-diagram}
    \end{wide}
    \caption{Sequence diagram showing the process of evaluating a project with Itch. When run as a library, there is no itch core or Puppeteer.}
    \label{fig:itch-sequence-diagram}
\end{figure}

When there is no browser available, Itch provides a command line interface.
\marginnote{A headless browser is a full browser, but without user interface.}
In this mode, Itch will run a headless browser, load the projects and test suites, run the judge, and finally collect the results from the browser.
\Cref{fig:itch-sequence-diagram} shows the complete process.

First, the command line interface (\texttt{itch-runner}) launches a Puppeteer instance.
There is support for supplying an existing Puppeteer instance, which can be useful on servers.
Then, the evaluation is started.
The Puppeteer instance runs a script, which first launches \texttt{itch-core}.
The script calls Itch as it would be used as a library: the \mintinline{typescript}{run(config)} function is called.
This will first load the Scratch projects, using the virtual machine.
The phases are then executed, with the before and during execution phase going first.
The during execution phase results in a schedule, which is then run: the virtual machine is now active and runs the projects with the scheduled actions.
Finally, the after execution phase is run, with the log from the execution before.


\section{Format of the generated feedback}\label{sec:format-of-the-generated-feedback}

The format of the generated feedback is in structure very similar to the structure of the tests in the test suite (\cref{subsec:structure-of-a-test-suite}).
The three levels of the feedback are:

\begin{itemize}[nosep]
    \item \term{Judgement}: the top-level object of the feedback.
    \item \term{Group}: contains one or more tests or subgroups (equivalent to a group from the test suite). Each group has the same options as in the test suite (e.g.\ visibility, sprites).
    \item \term{Test}: one condition or requirement that is evaluated (equivalent to a test from the test suite).
\end{itemize}

When running Itch as a library, it is possible to provide a callback function that will be called when feedback is available.
There are two modes for this: the partial model or the full mode.
In the partial feedback mode, feedback is streamed to the callback: it is called whenever feedback is available.
In the full mode, the callback is called once at the end with a fully constructed feedback object that contains all feedback for the evaluation.

When running Itch on the command line, the feedback is outputted to the standard output stream (this is also possible when using Itch as a library).
Depending on the feedback mode, the format is slightly different.

\begin{listing}
    \begin{minted}{json}
        {"command": "start-judgement", "version": 2}
        {"command": "start-group", "name": "Check on existing code", "visibility": "summary"}
        {"command": "start-group", "name": "Stage", "sprite": "Stage", "visibility": "summary"}
        {"command": "start-test", "name": "Sprite exists"}
        {"command": "close-test", "feedback": "The sprite exists", "status": "correct"}
        {"command": "close-group"}
        {"command": "close-group"}
        {"command": "close-judgement"}
    \end{minted}
    \caption{Example of the output generated by Itch for a test suite with two nested groups, with one test. Note the similarity to \cref{lst:tested-output-example}.}\label{lst:itch-output-example-partial}
\end{listing}

The partial feedback format is very similar to the Dodona feedback format used by TESTed (\cref{subsec:dodona-output}).
An example of this feedback is given in \cref{lst:itch-output-example-partial}.
The format is newline-delimited JSON: JSON objects are separated by a newline, and each line is a valid JSON object.
The structure of the feedback is indicated by commands, with \texttt{start} commands to begin a new level in the hierarchy and \texttt{close} commands to finish a level.

In full feedback mode, the output is a single JSON object that represents a nested tree of the same feedback.

\section{Evaluation of the Itch framework}\label{sec:itch-evaluation}

In this section, we discuss Itch's use in educational practice, insights from creating test suites for Scratch exercises.

\subsection{Capabilities of the testing framework}\label{subsec:capabilities-of-the-testing-framework}

The initial development of Itch used a set of 13 Scratch exercises from the 2017 edition of the Flemish Programming Contest (\textdutch{Vlaamse Programmeerwedstrijd}).
The Flemish Programming contest is split into different categories, depending on age or education level.
The Scratch exercises were used in a special category for students aged 10 to 12.

These 13 exercises were used as a reference for the initial feature set and capabilities of Itch.
For 12 of the 13 exercises, a test suite was created that tested the submissions sufficiently that it would have been usable in the programming contest.
The remaining exercise was not testable due to its open-ended nature.
The problem statement of the exercises boils down to ``draw a house'', which results in a vast variety of houses.

\subsection{Itch in educational practice}\label{subsec:itch-in-educational-practice}

From a relatively early point in the development of Itch, it has been used in educational practice.
This was mainly done by our partner, CodeCosmos.
There are two different ways in which their programming exercises are used.

The first is as part of a ``teaching pack'', which is bought and used by schools.
These packs implement the ``attainment descriptors''\marginnote{Called \textenglish{eindtermen} in Dutch.}, which are documents that describe the learning objectives of the lessons and what skills students should possess after taking the courses.
Here, the teaching pack provides a full learning path for the students, with suitable exercises at each stage of the process.
The second way is as an extracurricular activity, where students either follow weekly lessons or join a ``coding camp'' of a few weeks in the summer.

In both cases, many of the same exercises are used, but the context in which they are used differs.
In total, there are 139 exercises with a test suite.
Some of these exercises are different levels of a single exercise: conceptually, there are 58 different exercises.
However, most of these levels are different exercises packaged as one.
Therefore, for our purposes, we can consider them as separate exercises.

In the period from March 3rd, 2023 until March 26th, 2024 (328 days), the Itch evaluated \num{28144} submissions.
Of these submissions, \num{2713} (\qty{9.64}{\percent}) are evaluated as being correct, which means \qty{90.36}{\percent} of evaluated submissions are incorrect.
This is in line with our expectations: we allow students to submit as much as they want (and even automatically submit every so often) until the submission is correct.

The submissions were made by \num{6496} unique users, with an average of \num{4.33} submissions per user.
The submissions have an average test count of \num{158}, while the average test count of the exercises \num{366} (with a minimum of \num{2} and a maximum of \num{1292}).

\subsection{How to evaluate Scratch exercises}\label{subsec:how-to-evaluate-scratch-exercises}

The creators of Scratch have a well-known vision on how they intend Scratch to be used.
In particular, they do not support strict static tests on exercises.
For example, \citeauthor{resnickCodingCrossroads2020} express this as follows in~\citetitle{resnickCodingCrossroads2020}, an article celebrating 10 years of Scratch~\autocite{resnickCodingCrossroads2020}:

\begin{quotation}
    Too often, researchers and educators are adopting automated assessment tools that evaluate student programming projects only by analyzing the code, without considering the project goals, content, design, interface, usability, or documentation.
    For example, many are using an online Scratch assessment tool that gives students a ``computational thinking score'' based on the assumption that code with more types of programming blocks is an indication of more advanced computational thinking.
    This form of assessment doesn't take into consideration what the student's program is intended to do, how well it accomplishes the student’s goals, whether the code works as intended, whether people are able to interact with it, or how the student’s thinking develops over a series of projects.
    We see greater potential in other research and evaluation approaches, such as those that document and analyze teachers’ facilitation practices and students’ learning trajectories over time.
\end{quotation}

In Itch, these kinds of automated assessment are made possible by the static tests in the before execution phase of the test suite.
While we share the sentiment of \citeauthor{resnickCodingCrossroads2020}, our experience with Scratch exercises has shown that such tests are necessary and often useful.
There are a few factors that contribute to this:

\begin{itemize}
    \item Exercises (especially in Scratch) that were not created with testability in mind are often very hard, if not impossible, to properly test without resorting to static analysis of the code.
    \item Scratch projects, especially complex ones, are technically challenging to test within an acceptable time frame (we cannot spend minutes evaluating a single submission), as feedback must be fast~\autocite{sarsaSpeedingAutomatedAssessment2022}.
    \item Educators want simple metrics to easily see if students have mastered some concept.
          For example, determining if a student has mastered the concepts of loops (or repetition in general) is challenging to do automatically.
          With a sufficient number of students and time constraints, educators fall back on analyzing blocks as a proxy for mastery.
\end{itemize}

For these reasons, we do not recommend using Itch (or any automated assessment framework, not even TESTed \cref{part:tested}) to automatically grade submissions.
As so eloquently stated by Edsger Dijkstra, ``Testing shows the presence, not the absence of bugs''.
Applied to educational software testing frameworks, this means that educators should be aware that a submission being marked as correct by the testing framework says nothing about its actual correctness, nor how good it is.
This does not mean that testing frameworks are useless: with a good test suite, an educator (and student) can be fairly certain that a submission is correct.
Similarly, a submission marked as wrong can also help pinpoint the problem to the student, without intervention from the educator.

\subsection{Creating test suites for Scratch exercises}\label{subsec:creating-test-suites-for-scratch-exercises}

In contrast to most testing frameworks, Itch does not use the programming language for the test suites as the programming language of a submission: test suites for Scratch exercises are written in JavaScript.
While this has advantages, as JavaScript is a general purpose programming language, while Scratch is much more limited, it also has disadvantages.

It is not uncommon for educators that use or create Scratch exercises to have no formal computer science background, nor experience with programming besides Scratch~\autocite{kimEnhancingTeachersICT2012,oliveiraIntroductionComputationalThinking2019}.
This is also the case at CodeCosmos, where teachers with an educational background design and create the exercises.
For the existing exercises, the educators designed the exercise and implemented the Scratch parts, while other people, with more experience with JavaScript, implemented the test suites.
However, it is our experience that it is faster if the person designing the exercise has knowledge of the testing framework and implements the test suite themselves.
In \cref{sec:poke:-a-testing-framework-written-in-scratch}, we explore an experiment showing what a testing framework for Scratch with test suites in Scratch looks like.

\section{Poke: writing test suites in Scratch}\label{sec:poke:-a-testing-framework-written-in-scratch}

As mentioned in the previous subsection, creating test suites in JavaScript for Scratch exercises can be challenging for educators without computer science background or experience.
To fill this gap, we have developed Poke: a prototype of a testing framework for Scratch implemented in Scratch itself.
This means that test suites are written with Scratch blocks, tests are executed in the Scratch environment, and the results are also shown in the Scratch environment.

For this prototype, our focus was on two research questions: ``Is it possible to create a testing framework for Scratch in Scratch?'' and ``If possible, which testing facilities should be present?''.
The answer to the first question is yes, and the remainder of this section discusses the details of Poke, along with answers for the second question.
These considerations include what blocks to provide, how tests should be run, etc.




%As mentioned previously, we are aware of one other testing framework for Scratch, called Whisker.
%Similarly to Itch, it originally supported only writing test suites in JavaScript.
%Again similarly to Itch, there is now an experimental extension to Whisker that allows writing test suites in Scratch itself.\footnote{\url{https://scratch.fim.uni-passau.de/whisker-scratch/}}.

\subsection{Introduction to Poke}\label{subsec:introduction-to-poke}

The user-facing part of the Poke software testing framework consists of three parts:

\begin{itemize}
    \item An additional button next to the green flag and stop button, which will run the tests.
    \item An extension to provide a set of blocks to write tests with.
    \item An additional tab in the Scratch environment that shows the test results once run.
\end{itemize}

%TODO: voorbeeldoefening uitleggen en screenshot tonen van de verschillende stukken

\subsection{Poke-provided blocks}\label{subsec:poke-provided-blocks}

Poke provides five categories of blocks: a hat block (\scratchinline{\blockpokehat{when \drawtesttube clicked}}, which starts the tests if the button is pressed), feedback blocks, user interaction blocks, observation blocks, and blocks to execute code in another sprite.

\subsubsection{Feedback blocks}

\begin{scratch}[scale=0.7]
    \blockpokegroup{\drawicon{\drawfeedback} test group \ovalnum{name}}{\blockspace[0.5]}
\end{scratch}

The structure of a test suite in Poke is identical to the structure in Itch (\cref{subsec:structure-of-a-test-suite2}): a test suite consists of groups, which can contain tests or other groups.
The block for creating groups is a C block that takes the name of the group as an argument.
The body of the block outputs its test results in the group.
Differing from Itch, the only property of a group is its name: for example, a group in Poke cannot be linked to a sprite at the moment.

\begin{wide}
    \begin{varwidth}{0.40\linewidth}
        \begin{scratch}[scale=0.7]
            \blockpoke{\drawicon{\drawfeedback} assert \boolpokeempty[3em] named \ovalnum{feedback}}
        \end{scratch}
    \end{varwidth}%
    \hspace{1em}%
    \begin{varwidth}{0.28\linewidth}
        \begin{scratch}[scale=0.7]
            \blockpoke{\drawicon{\drawfeedbackcorrect} correct: \ovalnum{feedback}}
        \end{scratch}
    \end{varwidth}%
    \hspace{1em}%
    \begin{varwidth}{0.25\linewidth}
        \begin{scratch}[scale=0.7]
            \blockpoke{\drawicon{\drawfeedbackwrong} wrong: \ovalnum{feedback}}
        \end{scratch}
    \end{varwidth}
\end{wide}

For the tests, there are three blocks, the main of which is the assertion block.
It takes a boolean value and a name.
The name is shown in the output, together with a status depending on the value of the boolean block.
There are also the correct and wrong blocks, which act as a test that always passes or always fails respectively.

\begin{scratch}[scale=0.7,else word={}]
    \blockpokedgroup{\drawicon{\drawfeedback} wait until \boolpokeempty[3em] or \ovalnum{} seconds}{\blockspace[0.5]}{\blockspace[0.5]}
\end{scratch}

A special block is the wait until or timeout block.
This block will wait until the condition evaluates to true or the specified number of seconds has passed.
If the condition evaluates to true within the time limit, the first slot is used, which will often contain a \scratchinline{\blockpoke{\drawicon{\drawfeedbackcorrect} correct: \ovalnum{}}} block.
Otherwise, the second slot is used, which will often contain a \scratchinline{\blockpoke{\drawicon{\drawfeedbackwrong} wrong: \ovalnum{}}} block.
The two slots can also contain other blocks.

\subsubsection{User interaction blocks}

% TODO: oval sprites...
\begin{varwidth}{0.20\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} click \greenflag}
    \end{scratch}
\end{varwidth}%
\hspace{1em}%
\begin{varwidth}{0.28\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} click \selectmenu{Sprite}}
    \end{scratch}
\end{varwidth}%
\hspace{1em}%
\begin{varwidth}{0.3\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} click \selectmenu{Sprite} and wait}
    \end{scratch}
\end{varwidth}

\begin{varwidth}{0.5\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} press \selectmenu{space} key}
    \end{scratch}
\end{varwidth}%
\hspace{1em}%
\begin{varwidth}{0.5\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} press \selectmenu{space} key and wait}
    \end{scratch}
\end{varwidth}%

\begin{varwidth}{0.5\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} move mouse to x: \ovalnum{} y: \ovalnum{}}
    \end{scratch}
\end{varwidth}%
\hspace{1em}%
\begin{varwidth}{0.5\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawinteract} answer \ovalnum{answer text}}
    \end{scratch}
\end{varwidth}%

The user interaction blocks will simulate user interaction, similar to the scheduler in Itch (\cref{subsec:during-execution}).
Currently, there are blocks to click the green flag, click a sprite, move the mouse, press a key, and answer a question.
The block to click a sprite and block to press a key also have a synchronous variant, which will wait until all activated scripts have finished, again similar to the synchronous/asynchronous actions in the scheduler from Itch.

\subsubsection{Observation blocks}

\begin{varwidth}{0.5\linewidth}
    \setscratch{scale=0.7}\ovalpoke{\drawicon{\drawobserve} snapshot}
\end{varwidth}%
\hspace{1em}%
\begin{varwidth}{0.5\linewidth}
    \setscratch{scale=0.7}\ovalpoke{\drawicon{\drawobserve} \selectmenu{property} of \selectmenu{Sprite} in \ovalnum{snapshot variable}}
\end{varwidth}%

The observation blocks are very similar to sensing blocks from Scratch, as they allow the tests to save and query the environment.
A special sensing block (which also acts as a variable) reflects the current state of the virtual machine.
Test code can then save this state into a variable, making it available later.
Two more reporter blocks (one for sprite-specific properties and one for the stage) allow querying specific properties (of specific sprites) from the saved state (or the current state).

\subsubsection{Executing blocks in another sprite}

\begin{varwidth}{0.5\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpokegroup{\drawicon{\drawsquarearrow} with \selectmenu{Sprite} do}{\blockspace[0.5]}{}
    \end{scratch}
\end{varwidth}%
\hspace{1em}%
\begin{varwidth}{0.5\linewidth}
    \begin{scratch}[scale=0.7]
        \blockpoke{\drawicon{\drawsquarearrow} add sprites to \selectmenu{list} where \boolpokeempty[3em]}
    \end{scratch}
\end{varwidth}%

While the test blocks can be placed in any sprite, it is our experience that the most convenient place is a dedicated sprite with only test code.
However, this introduces an additional complication: how can the test sprite execute blocks on other sprites?
For example, the test sprite might want to move a certain sprite, which is not possible in vanilla Scratch.

To this end, Poke provides a C block, whose contents will be executed in the selected sprite.
Technically, this re-uses the broadcasting mechanism built into Scratch:

\begin{enumerate}
    \item Before executing a test, Poke will generate a unique broadcast for each C block.
    \item The contents of the C block are copied to the sprite that will execute them.
    \item These copied blocks are placed under a hat block that will trigger when the generated broadcast is sent.
    \item The original blocks are replaced with a send broadcast block.
\end{enumerate}

When the virtual machine executes this code, it will send the broadcast, after which it will trigger the blocks in the correct sprite.
This happens behind the scenes: the copied blocks are not visible to the user, and special care has been taken to ensure that there are no performance issues.
For example, the blocks are only copied once (or when they are changed).

\subsection{Feedback in the Scratch environment}\label{subsec:feedback-in-the-scratch-environment}

% TODO: update Scratch environment?
\begin{figure}
    \begin{wide}
        \includegraphics[width=\linewidth]{scratch-poke-feedback}
    \end{wide}
    \caption{
        Feedback for the \emph{Grow and shrink} exercise.
        Our solution contains an error: the sprite \texttt{Giga} does not implement the shrinking behaviour (with the ``k'' key).
        In the feedback, there are two test groups: one for checking that sprites grow and one for checking that sprites shrink.
        In each of these groups, the relevant key is pressed four times and each sprite is checked.
        In the ``grow'' group, everything is correct (indicated by the green checkmark).
        As expected, the second group reports that some tests have failed (indicated by the yellow triangle).
        Two of the subgroups are open: while the tests for \texttt{Nano} and \texttt{Pico} were correct, the one for \texttt{Giga} failed as expected (indicated by a red cross).
    }
    \label{fig:poke-feedback-result}
\end{figure}

For this prototype, showing the feedback to students was not a priority.
As such, the feedback is shown in a rudimentary interface, which shows the feedback in tree format (\cref{fig:poke-feedback-result}).
While usable, it is not the most intuitive layout, especially considering the target demographic of Scratch.

\subsection{Comparing Poke to Itch}\label{subsec:comparing-poke-to-itch}

To verify that Poke is usable as a testing framework, we compared it to the set of Scratch problems from the Flemish Programming Contest (\cref{subsec:capabilities-of-the-testing-framework}) that were testable by Itch.

Three of the exercises could not be tested with Poke, but this was expected.
Poke does not support extensions at the moment, and these exercises used the pen extension.
One of these three exercises would not be testable anyway for the same reason Itch could not test it: drawing a house is a very open-ended exercise.
The other exercises could be tested with Poke.

For a comparison, \cref{lst:itch-grow-and-shrink} contains the test suite for the \emph{Grow and shrink} exercise in Itch, while \cref{lst:poke-grow-and-shrink} contains the test suite used in Poke.

\begin{listing}
    \begin{wide}
    \begin{scratch}[scale=0.6]
        \blockpokehat{when \drawtesttube clicked}
        \blockpokegroup{\drawicon{\drawfeedback} test group \ovalnum{Test if sprites get bigger}}{
            \blockrepeat{repeat \ovalnum{4}}{
                \blockpokegroup{\drawicon{\drawfeedback} test group \ovalnum{Pressing the ``g'' key}}{
                    \blockvariable{set \selectmenu{snapshot-before} to \ovalpoke{\drawicon{\drawobserve} snapshot}}
                    \blockpoke{\drawicon{\drawinteract} press \selectmenu{g} key and wait}
                    \blockpoke{\drawicon{\drawfeedback} assert \booloperator{\boolsensing{\selectmenu{size} of \selectmenu{Giga}} > \ovalpoke{\drawicon{\drawobserve} \selectmenu{size} of \selectmenu{Giga} in \ovalvariable{snapshot-before}}} named \ovalnum{Gigga got bigger}}
                    \blockpoke{\drawicon{\drawfeedback} assert \booloperator{\boolsensing{\selectmenu{size} of \selectmenu{Nano}} > \ovalpoke{\drawicon{\drawobserve} \selectmenu{size} of \selectmenu{Nano} in \ovalvariable{snapshot-before}}} named \ovalnum{Nano got bigger}}
                    \blockpoke{\drawicon{\drawfeedback} assert \booloperator{\boolsensing{\selectmenu{size} of \selectmenu{Pico}} > \ovalpoke{\drawicon{\drawobserve} \selectmenu{size} of \selectmenu{Pico} in \ovalvariable{snapshot-before}}} named \ovalnum{Pico got bigger}}
                }
            }
        }
        \blockpokegroup{\drawicon{\drawfeedback} test group \ovalnum{Test if sprites get smaller}}{
            \blockrepeat{repeat \ovalnum{4}}{
                \blockpokegroup{\drawicon{\drawfeedback} test group \ovalnum{Pressing the ``k'' key}}{
                    \blockvariable{set \selectmenu{snapshot-before} to \ovalpoke{\drawicon{\drawobserve} snapshot}}
                    \blockpoke{\drawicon{\drawinteract} press \selectmenu{k} key and wait}
                    \blockpoke{\drawicon{\drawfeedback} assert \booloperator{\boolsensing{\selectmenu{size} of \selectmenu{Giga}} < \ovalpoke{\drawicon{\drawobserve} \selectmenu{size} of \selectmenu{Giga} in \ovalvariable{snapshot-before}}} named \ovalnum{Gigga got smaller}}
                    \blockpoke{\drawicon{\drawfeedback} assert \booloperator{\boolsensing{\selectmenu{size} of \selectmenu{Nano}} < \ovalpoke{\drawicon{\drawobserve} \selectmenu{size} of \selectmenu{Nano} in \ovalvariable{snapshot-before}}} named \ovalnum{Nano got smaller}}
                    \blockpoke{\drawicon{\drawfeedback} assert \booloperator{\boolsensing{\selectmenu{size} of \selectmenu{Pico}} < \ovalpoke{\drawicon{\drawobserve} \selectmenu{size} of \selectmenu{Pico} in \ovalvariable{snapshot-before}}} named \ovalnum{Pico got smaller}}
                }
            }
        }
    \end{scratch}
    \end{wide}
    \caption{The complete test suite for the \emph{Grow and shrink} exercise in Poke.}\label{lst:poke-grow-and-shrink}
\end{listing}

\subsection{Conclusion and future work}\label{subsec:conclusion-and-future-work}

Poke shows that it is possible to create a testing framework for Scratch implemented in Scratch.
While not as powerful as a JavaScript-based framework like Itch, it is much easier to use, especially for educators without experience in JavaScript.
In addition, besides some known limitations, Poke is able to test real-world exercises.

Poke is a prototype, which means that we intentionally did not consider some important aspects, especially for use in educational practice.
We identify three major areas where further work is needed.

\subsubsection{Support for Scratch features}
While normal for a prototype, Poke misses support for various Scratch features.
For example, there is no support for sound blocks.
The pen extension is also widely used and not supported at the moment.

\subsubsection{Representation of the feedback}
The manner in which feedback is shown to students must be improved.
Currently, the feedback is very text-heavy and dry, which does not integrate well with the game-like nature of Scratch.
In addition, we envision that a different representation might be needed for educators and for students.

\subsubsection{Organisational aspects of Poke}
We have currently not considered any of the organisational aspects that arise when attempting to use a testing framework in an educational setting.

The tests are currently included in the Scratch project itself.
While useful if students want to create and use their own tests, it is less ideal for educator-provided test suites.
For example, there is currently no way of preventing students from modyfying the test code.
There is also no support for updating the tests after the fact.
For example, in many settings, students receive a ``starter'' Scratch project in which some code is already present.
If the test suite is included in that project, there is no way of updating the test suite after the starter project has been distributed to students.

Poke also has no support for automatically running tests.
This would be required, for example, if the Scratch exercises are used as part of an online judge platform.

\section{Conclusion and future work}\label{sec:conclusion-and-future-work}

In this chapter, we have presented Itch (and Poke) as an educational testing framework for Scratch.
With the three phases of the test suites, Itch is able to perform static testing, emulate user interaction, and perform post-mortem testing.
Itch provides various helper functions to make testing common scenarios easier.

The combination of the three phases allows for a lot of flexibility in how an exercise can be tested: from fully static to completely dynamic.
However, while technically possible, it remains a challenge to design Scratch exercises that are both easy to test dynamically and open-ended enough to go well with the game-like and tinkering nature of Scratch.

Poke is a promising experiment for writing tests for Scratch with Scratch, but needs more work to be a viable alternative.

\end{document}
